{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 11 â€“ Deep Learning**"
   ]
  },
  {
   "attachments": {
    "Screen%20Shot%202018-04-24%20at%205.09.26%20PM.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main problem \n",
    " (1)vanishing gradients problem,related exploding gradients problem, which let the lower layers hard to be trained \n",
    "  b :gradient will become too small when GD down to the lower layer so the weights in lower layer are no changes well : vanishing gradients problems\n",
    "  a :gradient will become too large as algorithm down to the lower layers, then the weights change too significantly : exploding gradients problem \n",
    " different layers different learning speeds\n",
    " the problem comes from the initiate menthods and the sigmoid activation function \n",
    " cause if the inputs become too large or too small , the sigmoid comes to saturating witch means the dervative extremely close to 0\n",
    " ![Screen%20Shot%202018-04-24%20at%205.09.26%20PM.png](attachment:Screen%20Shot%202018-04-24%20at%205.09.26%20PM.png)\n",
    " (2)large networkd make train process become slow\n",
    " \n",
    " (3)overfitting problem \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_This notebook contains all the sample code and solutions to the exercises in chapter 11._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's make sure this notebook works well in both python 2 and 3, import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanishing/Exploding Gradients Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logit(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure sigmoid_saturation_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xd4FNX6wPHvSa+EFiIdlY70cikKoYk0aUZBqjQF5arA\nFUFQ2g8UkWLlchVBEFB6ExCBIFUMGkqQIhBCCSVAAklIP78/ZonZZAMJbLKb5P08zzzJzpyd8+5k\ns++emTPnKK01QgghhL1xsHUAQgghhCWSoIQQQtglSVBCCCHskiQoIYQQdkkSlBBCCLskCUoIIYRd\nkgQlHopSKlAp9bmt44CsxaKUOqaUmphLIaWtd6FSamMu1OOvlNJKqeK5UNdQpVSYUirFFsc0XSwD\nlFLRtoxB5Bwl90GJ9JRSvsAkoANQEogEjgEfaq23mcoUBRK11ndsFqhJVmJRSh0DVmqtJ+ZQDP7A\nTsBXax2RZr0Pxv9ZpBXrCgU+11rPTLPOBSgKXNU5+E+tlCoCXANGAiuBO1rrXEkQSikNBGitV6ZZ\n5w54a62v5UYMInc52ToAYZdWAR7AIOBvoATQAih2r4DW+qZtQsvInmJJT2sdlUv1JABXcqGq8hif\nGxu11uG5UN99aa3vAndtHYfIIVprWWRJXYDCgAbaPKBcIMa3+HuP/YD1GB8WoUA/jFbXxDRlNDAM\nWAfEAqeAlkAZYCsQAwQD9dLV1R04CsQDF4D3MLX+M4mlhKmOu8B5YGD6WCy8nidNz7liiuMPoFO6\nMi7ANNM+44GzwL+BCqbXlnZZaHrOQowPc4ChwFXAMd1+lwLrsxKH6bWa1WVa7296XDwbxy0UGA/8\nF7gNXAT+c59jNMDC66wATASOWSgbnebxRNPfoCdwBrgDrE0br6lc/zQxXwUWpYk1bb2hluoxrXsV\n44tVgunnkHTbtelvscJ0jM8CfWz9vydLxkWuQYn0ok3L80opt2w8bxHGt+tWQFeMD5ryFsqNB5YD\ntYEg0+/fAF8CdYHLGB/qACil6mN8kKwGagLvAmOBN+4Ty0KgItDGFEs/jA/S+/ECNgNtTbGtAlYr\npaqme439ME5vVTO9xlsYH/49TGVqYJwWfdNCHSsAH1Md916fF9AFWJLFOLpjJJLJpnpKWnox2Thu\nb2MkhHrAR8AMpVQTS/sEfgCeM/3eyFT3hUzKWlIBeAnoBjyL8ff+vzQxv4qRLL81xfwccMS0uaHp\n5xBTvfcem1FKdQM+B+YATwFzgS+VUp3TFX0f44tAbdPrWqCUKpeN1yJyg60zpCz2t2B82N4E4oD9\nwEzgX+nKBGJqtQBVML6VNk6zvSyQTMYW1PQ0j58yrRuZZp0/aVoCwPfAjnR1TwQuZhJLZdPzm6XZ\nXj59LFk8DgeA8abfK5n2+1wmZc3iTrN+IaYWlOnxamBxmsd9gCjALStxmB6HAqPvV38Wj1sosCxd\nmdNp67IQSwNTPRXS7TcrLag4wCfNuveAv9M8vohxnTOzujXwwgPq2QsssPA32HOf96ETRoteWlF2\ntkgLSmSgtV4FlAI6Y3ybbwocUEqNy+QpVYEUjBbRvX1cwGgNpXckze9XTT+PWlhXwvSzGsaHTlp7\ngNJKqUIW9l/NFMvBNLGczySWVEopT6XUDKXUcaXULVPPsAbAvW/VdU373Xm//WTBEqCrUsrD9Lg3\nsEprHZfFOLIqq8ftSLoyl/nn2FvbeW1+TS61LqVUCaA0sP0R68jsdVdPty71dWutk4Dr5NzrFg9J\nEpSwSGsdp7XeprWerLVuinEabqKpt9ijSExbzX3WZeW9eb/eatntyTYTCAAmYHQIqYOR5B719aa3\nCUgCupg+lNvwz+m93Ioj7bFJtLAtu58LKYBKt87ZQjlr1PWw0r8fbBmLyCL5g4isOo5xKsTSdakT\nGO+l+vdWKKXKYLTCHtVfQLN0657GOFVlqVv5vVgapYmlXBZieRr4Tmu9Smt9BON005Nptgeb9tsy\nk+cnmH463q8SrXU8xrWh3hjXY65gnKLMahz36rpvPWT/uD2K64CfUiptkqqTnR1oo5v4JaD1fYol\n8vCv+3h24hH2QRKUMKOUKqaU2qGU6qOUqqWUelwpFQC8A2zXWt9O/xyt9UmMXnjzlFKNlVJ1MC50\n3yX7LZn0PgFaKKUmKqUqK6V6A6OAGZYKm2LZAvxXKdXEFMtCHtwV+RTQTSlVTylVE6NVk5qMtdan\ngB+Br5VSPUzH5RmlVF9TkfMYr7WjUsrX1PkhM0uAdsBrGNeAUrIah0ko8IxSqvR9bszN1nF7RIEY\n92CNU0o9qZQaBLzwEPv5P+AtpdTbppjrKKVGpdkeCrRWSj1muh/Lko+Bvkqp15VSlZRSIzC+DOTE\n6xY5TBKUSC8a46L8m8AuIASja/VSjG/8mRmA8W0/EKO7+VKM60lxjxKM1voPjFNePTDdLGxa7jdy\nxADgHLAD2GCKJfQBVY3EuAF1N8Z1twOm39PqZ9rXpxgttYUYvfLQWl8CPsD4kL36gPh2Y7QWqmN+\nei+rcbyP0QnlDEbrJYOHPG4PRWv9F8btA0Mxru20xXjPZHc/XwGvY/TUO4bxRaNGmiKjMFqwF4A/\nM9nHWmAERu/E4xjv4+Fa6w3ZjUfYnowkIXKE6Zv9ZaCXqdOFEEJki4wkIaxCKdUK8MbokVcCoyUR\ngfEtWAghss2qp/iUUm8opYKUUvFKqYX3KddfKXVIKXVbKXXR1K1WkmXe5gxMxUhQGzDuK2mutY6x\naVRCiDzLqqf4lFLdMbqctgPctdYDMik3DOMc82+AL8Y1ixVa6w+tFowQQog8zaqtFq31agClVAOM\n8dUyK/dVmoeXlFLfk3n3XSGEEAWQvZxWa47RWywDpdRQjN5BuLu71y9btmxuxvVAKSkpODhIZ8gH\nkeOUNRcuXEBrTblyMizcg+T2e+pq3FWcHZwp6lI01+q0Bnv83zt16lSE1tr3QeVsnqCUUgMxhnIZ\nbGm71no+MB+gQYMGOigoyFIxmwkMDMTf39/WYdg9OU5Z4+/vT2RkJMHBwbYOxe7l5nvq/Z3vM+XX\nKbz3zHtMbTU1V+q0Fnv831NKnc9KOZsmKKVUV2A6xtQOEQ8qL4QQue2Lg18w5dcpDKo7iCktp9g6\nnALFZglKKfUc8D+go9b66IPKCyFEblsRsoIRm0fQuXJn5nWah/loTiKnWTVBmbqKO2GMl+Vomk8o\nyTRacNpyrTCmA+imtT6YcU9CCGF7kXGRPFP+GZa/sBwnB5tfESlwrH3lbDzGmGfvYsxzcxcYr5Qq\np5SKTjMh2ASMIWJ+Mq2PVkpttnIsQgjxUBKTjcHOh9Qfwo5+O/Bw9njAM0ROsGqC0lpP1FqrdMtE\nrXWY1tpLax1mKtdSa+1kWndvaW/NWIQQ4mGcvXWWql9U5eczPwPg6PCgAdRFTrGvvodCCGFDV6Ov\n8uziZ4mMi6RsIfu6paUgkpOqQggB3Im/Q4elHbh85zI7+u+gmm81W4dU4EmCEkIUeAnJCXT/sTuH\nrxxmXc91NC7T2NYhCSRBCSEEDsqBJ4s8Se+avelYuaOtwxEmkqCEEAWW1pqo+CgKuxVmXqd5tg5H\npCOdJIQQBdZHez+izrw6hN8Jt3UowgJJUEKIAunbP79l7PaxNCvXDD8vP1uHIyyQBCWEKHA2ntrI\nkA1DaPtEW77t8i0OSj4K7ZH8VYQQBcrBSwd5ccWL1C1Zl1UvrsLF0cXWIYlMSIISQhQolYpWIqBG\nAJte3oS3q7etwxH3Ib34hBAFwpXoKxR2K0wR9yIs6rrI1uGILJAWlBAi37t59yatv2tNz5U9bR2K\nyAZJUEKIfC02MZbOyzrz982/eavxW7YOR2SDnOITQuRbSSlJvLTyJfZf2M+KgBX4V/C3dUgiGyRB\nCSHyrdE/j2bjqY182eFLelTvYetwRDZJghJC5FtD6w+lvE95hjUcZutQxEOQBCWEyHcOXjpIw1IN\nqe5bneq+1W0djnhI0klCCJGvLD+2nMZfN2bBnwtsHYp4RJKghBD5xi9nf6Hfmn48U/4Zetfqbetw\nxCOSBCWEyBcOXT5Etx+6UbV4Vdb1XIebk5utQxKPSBKUECLPu3evUzH3Ymzps4XCboVtHZKwAukk\nIYTI8zycPZjfeT6VilailHcpW4cjrERaUEKIPOt2/G1+OfsLAJ0qd6JK8So2jkhYk1UTlFLqDaVU\nkFIqXim18AFl31ZKXVFK3VZKLVBKuVozFiFE/paQkkDX5V3pvKyzzIibT1m7BXUZmArct3+nUqod\n8C7QGigPPAFMsnIsQoh8KjklmWl/TWNn6E7+1/l/lPQuaeuQRA5QWmvr71SpqUAZrfWATLYvBUK1\n1uNMj1sBS7XWj91vv97e3rp+/fpm61588UWGDx9ObGwsHTp0yPCcAQMGMGDAACIiInjhhRcybB82\nbBgvvfQSFy5coG/fvhm2jxo1is6dO3Py5EleffXVDNs7d+7MqFGjCA4O5q23Mg5EOW3aNJo2bcq+\nffsYN25chu1z5syhTp06/PLLL0ydOjXD9v/+979UqVKFDRs28Mknn2TYvnjxYsqWLcsPP/zAV199\nlWH7ypUrKV68OAsXLmThwoUZtv/00094eHjw5Zdf8uOPP2bYHhgYCMDMmTPZuHGj2TZ3d3c2b94M\nwJQpU9i+fbvZ9mLFirFq1SoAevfuzaVLl8y2lylThiVLlgDw1ltvERwcbLa9cuXKzJ8/H4ChQ4dy\n6tQps+116tRhzpw5APTp04eLFy+abW/SpAnTp08HoEePHty4ccNse+vWrZkwYQIA7du35+7du2bb\nO3XqxOjRowHw9/cnvZx47wUHB5OUlESDBg0e+N4bP348bdq0KXDvPY0mtFooYY+FMbPtTGK3x973\nvTd27Fj2799vtr0gvffatGlD4cLmnUYe9XPvUd97u3btOqS1bpBhQzq26iRRA1iX5vFhwE8pVUxr\nbfaXVEoNBYYCODs7ExkZabajU6dOERgYSFxcXIZtACdOnCAwMJCoqCiL20NCQggMDOTatWsWtx89\nehRvb2/CwsIsbr979y6BgYH8/fffFrf/8ccfJCQkcOzYMYvbg4KCiIyM5PDhwxa3//bbb4SHh3P0\n6FGL2/fv38+ZM2cICQmxuH3v3r34+Phw4sQJi9t//fVX3NzcOHXqlMXt9z4kzpw5k2H7vdcOcO7c\nuQzbU1JSUrcnJCRk2O7s7Jy6/eLFixm2X758OXX75cuXM2y/ePFi6varV69m2B4WFpa6/fr169y+\nfdts+7lz51K337x5k/j4eLPtZ86cSd1u6djkxHsvKSkJrTWRkZEPfO8dPnwYJyenAvfeu13iNmGP\nhdHNrxv1E+rz3bnv7vves3T8CtJ7Lzk5OUOZh/nc09qBlBRPkpM92Lr1AqdPH+Ls2XDCwmqQkuKK\n1m6kpLiSkuLGRx9BkSKhXLrkSkjIUFJS3EhJcUNrV1JSXIFnMtRpia1aUGeA17XWW0yPnYEE4HGt\ndWhm+23QoIEOCgqyeryPIjAw0OI3HGFOjlPW+Pv7ExkZmeEbvfiH1pr1J9fjHe5Nq5atbB2O3QsM\nDKRFC39iYuDGDbh585/l3uPISLh9G+7cMRZLv8fGWjMqZdctqGigUJrHPqafd2wQixAiD/jp9E9U\nKFyB6r7V6VK1C4FXAm0dkk3FxcHVq3DliuUlIsJIPuHhTYmOhsTER6/T2/ufxcsLPDzA3f2fJf3j\nzNZ16pS1+myVoEKA2sC9E8+1gavpT+8JIQTAnrA99PixB/4V/Nnce7Otw8lxCQlw8SKEhRnL+fP/\n/B4WBuHhEBWV1b25AEZiKFrUWIoVM/+9cGEj6RQqZP4z7e+enuDwCN3qTp06RVhYGG3atMnyc6ya\noJRSTqZ9OgKOSik3IElrnZSu6HfAQqXU90A4MAFYaM1YhBD5w7Frx+i8rDPlfcqzuNtiW4djNVFR\ncPo0nDpl/Dx9Gs6c+ScBPejqi5MTPPaYsfj5/fP7vce+vkbyOXFiH506NcXdPXdelyXLli1jwIAB\n1K1b13YJChgPfJDmcR9gklJqAXAcqK61DtNab1FKzQB2Au7AqnTPE0IIzkeep92Sdng4e7C1z1aK\nexS3dUjZdvUqHD1qLMeOwcmTRlK6fj3z5zg6QunSUK7cP0v58sbPsmWhVCkoUiRrLZobNxJslpzi\n4+MZPnw4y5cvJyEhgZSUlGw936oJSms9EZiYyWavdGVnAbOsWb8QIn+Z+utUYhJi2P3KbsoXLm/r\ncO4rKQmOH4egIDhy5J+klFkicneHihWhcmWoVMn4WbGikYhKlTJaSHnZ2bNn6dixI+fPn0/tRp/d\nTnl5/BAIIfKzzzp8xoh/jaCmX01bh2JGa+O60MGD/yyHDlnu6ebtDTVrwlNPGT+rVzeSUalSj3ZN\nx56tXbuWvn37Ehsba9ZqsmkLSgghHlViciIfBH7Af5r+hyLuRajlV8vWIZGUBMHBsGuXsRw4YLll\n9MQT0KAB1K5tJKNatYzTckrlfsy2kJiYyNtvv82CBQsy3HwM0oISQuRhWmsGbxjMd4e/o7ZfbV56\n6iWbxJGSYiSkX36BwEDYs8e4Fyit4sWhUaN/loYNjXUF1YULF+jUqROnT5+2mJxAEpQQIg9795d3\n+e7wd0z2n5zrySkiAn7+GbZsga1b4do18+1PPgktWhjL00/D448XnJbRg2zevJmePXsSExNDcnJy\npuXkFJ8QIk+atX8WM/bNYHiD4YxvPj5X6jx5EtasMZbffzfv2l22LDz7LLRqZSSl0qVzJaQ85/33\n32fmzJmZtprSkhaUECLPiUmI4fODn/NC9Rf4tP2nqBxqmmhtnLpbvdpYjh//Z5uLi5GInnvOWKpV\nkxZSVpw/fx6tNY6OjvdtPYEkKCFEHuTp4sm+Qfso7FYYRwdHq+//zBlYssRY/v77n/WFC8Pzz0O3\nbtC2rTFagsieRYsW8d577zF+/Hg2bNhAfHx8polITvEJIfKM3y/9zpIjS/ik3Sc85nXf2Xay7eZN\n+PFHWLwY9u37Z72fn5GQuncHf39wdrZqtQVS5cqV+eGHH6hTpw5HjhzJtJy0oIQQecKpG6fosLQD\n3i7ejG8+Hl9P30fep9ZGj7t582DlSmNMOzAGLO3eHfr2hdatjZEahHXt2rWLM2fOmK1zd3cnKSmJ\nRNNItZKghBB27/Kdyzy7+FkUiq19tj5ycrp922gpzZtnDCcExvWjtm2NpNStmzH6tsg5//nPf4iJ\niTFb5+vrS+vWrVm2bBmJiYlyik8IYd8i4yJp/317bty9QWD/QCoVq/TQ+zp9GmbNMpLTvc/GEiVg\n8GAYOtQYNkjkvF9//ZW//vrLbJ2npycfffQRPXv2ZPLkyUyePJno6Ohs7VcSlBAiV4VcCyEsKozV\nL66mfqn6D7WPgwfhgw9qsHv3P13D/f1h2DDo2tXokSdyz5gxYzK0nooWLUpAQAAAZcqUYf78+dne\nryQoIUSualauGaFvhuLj5vPgwmloDZs3w4wZxnBD4IuLi3EKb+RIY4w7kfv27duXoWOEl5cX06dP\nx/ERL/bl06EKhRD2RGvNGz+9wbygeQDZSk5aw08/GWPcdexoJCcfH+jVK4xz5+DrryU52dI777xD\nbLpRcn18fOjZs+cj71sSlBAix03eNZkvfv+C0MjQbD1vxw5o1sxITH/8ASVLwsyZxqR+Q4eepVSp\nnIlXZM1vv/3Gn3/+abbO09OT//u//3vk1hPIKT4hRA6bFzSPibsmMqDOAKa3np6l5+zbB+PHw86d\nxuPixWHsWOMaky1nhhXmxowZk6H15O3tTe/eva2yf0lQQogcs+r4KoZvGk7HSh2Z32n+A4cwCg2F\nd96BFSuMx4ULw3/+A//+t3QTtzdBQUEcPHjQbJ2XlxdTp07FyUqzLUqCEkLkmNDIUJqUbcKPAT/i\n7Jj5kA3R0fDhh8bpu/h4o5U0apSxFC6ciwGLLBszZgxxcXFm69zd3enXr5/V6pAEJYSwuuSUZBwd\nHBnVdBT//te/M01OKSnGPUxjx0J4uLHu5ZeNZFW2bC4GLLLlzz//ZP/+/WYjQ3h6ejJlyhScrTh2\nlHSSEEJYVWhkKDW/qsmesD0AmSanY8eMeZUGDDCSU8OGxrWn77+X5GTv3n33XYutp1deecWq9UiC\nEkJYzfWY67Rb0o7w6HCKuBWxWCYuDiZMgHr1YP9+o2feokXGNOpNmuRywCLbjhw5wu7duzO0niZN\nmoSLle+QllN8QgiriE6IpuPSjoRFhfFL31+oUaJGhjK7dhlDEJ06ZTweNgymTzfuaxJ5w9ixY4mP\njzdb5+rqyqBBg6xelyQoIcQjS0hOoMePPTgUfog1L62hWblmZtujoowOD998YzyuVg3+9z/jHieR\nd4SEhLBz506zQV89PT354IMPcHV1tXp9Vj3Fp5QqqpRao5SKUUqdV0q9nEk5pZSaqpS6pJSKUkoF\nKqUyft0SQuQZRd2LMr/TfJ6v8rzZ+l27oFYtIzm5uMCkSfDnn5Kc8qJx48ZlaD05OzszdOjQHKnP\n2i2oL4AEwA+oA2xSSh3WWoekKxcADASeBs4DU4HFQD0rxyOEyEFaa2ITY/F08WRp96Vm9znFxxs3\n237yiTFcUcOGxrWmatVsGLB4aFFRUWzYsMHs2pOHhwcTJkzAzc0tR+q0WgtKKeUJ9AAmaK2jtdZ7\ngHVAXwvFHwf2aK3Paq2TgSWAjKYlRB4zc99M6s+vz/WY62bJ6ehRaNTIuK/JwQHefx/27pXklJf5\n+Piwfft26tevj6enJ2C0noYNG5ZjdVqzBVUZSNJan0qz7jDgb6HscuBFpVRl4BzQH9hiaadKqaHA\nUAA/Pz8CAwOtGPKji46OtruY7JEcp6yJjIwkOTk5TxyrrVe28uHJD/H39efowaM4KAe0hlWryjB/\n/hMkJjpQunQs48adoHr12+zda9365T2VNdY8TkopZs6cSXBwMF9//TVt27blt99+s8q+LdJaW2UB\nngGupFs3BAi0UNYFmAtoIAkjST3+oDrq16+v7c3OnTttHUKeIMcpa1q0aKFr165t6zAeaNOpTdpx\nkqNuvai1jkuM01prfeuW1l27am2c0NN66FCt79zJuRjkPZU19nicgCCdhbxizRZUNFAo3Tof4I6F\nsu8DjYCywBWgD7BDKVVDax1robwQwk4cvHSQgBUB1H6sNqtfWo2rkyt//AEBAXD2rNFlfOFCY+JA\nIR6FNXvxnQKclFJp52+uDaTvIAFGB4rlWuuLWuskrfVCoAhyHUoIu1fepzztK7bnp5d/wtulEP/9\nLzRtaiSnevWMaTEkOQlrsFqC0lrHAKuByUopT6XU08DzGL3z0vsdCFBK+SmlHJRSfQFn4G9rxSOE\nsK7rMddJTE7Ez8uPlS+uxEv50bcvvPaa0WPv1VeNjhBPPGHrSEV+Ye2hjoYD7sA1YCkwTGsdopQq\np5SKVkqVM5X7CKMDRTAQCbwN9NBaR1o5HiGEFdy6e4tW37Wi31pjpOrz541W0/ffg4cHLFkC8+ZB\nDvU2FgWUVe+D0lrfBDI07rXWYYBXmsdxwOumRQhhx+4m3uX55c9zMuIkc9rNYe9e6NYNrl+HSpVg\n7VqZct0e+fv789RTT/HCCy/YOpSHJoPFCiEylZSSRM9VPdkbtpcl3ZdwPrA1LVsayaltW/jtt/yV\nnK5fv87w4cOpUKECrq6u+Pn50bp1a7Zt25al5wcGBqKUIiIiIocj/cfChQvxsjCb4+rVq5k+PWsz\nGNsrGYtPCJGpUVtHsf7kema3+Yz9X7/InDnG+jffNG7CtdLEqXajR48exMbG8s0331CxYkWuXbvG\nrl27uHHjRq7HkpCQ8EijgxctWtSK0diGtKCEEJnqV7sfExvPYuvUN5gzB5ydjUFe58zJf8kpMjKS\n3bt38+GHH9K6dWvKly9Pw4YNGT16ND179gRgyZIlNGzYEG9vb0qUKEFAQACXLl0CIDQ0lJYtWwLg\n6+uLUooBAwYAxum2N954w6y+AQMG0KlTp9TH/v7+DBs2jNGjR+Pr60sz02CFs2bNolatWnh6elK6\ndGkGDx5MZKRxuT4wMJBXXnmFmJgYlFIopZg4caLFOitUqMDUqVN59dVXKVSoEGXKlOHjjz82i+nU\nqVO0aNECNzc3qlWrxpYtW/Dy8mLhwoXWOcjZJAlKCJHB0atHAShJfda++zZbtkDx4rB9OwwebOPg\ncoiXlxdeXl6sX78+w2R89yQkJDBp0iQOHz7Mxo0biYiIoFevXgCULVuWVatWAcao3+Hh4cydOzdb\nMSxZsgStNbt37+a7774DwMHBgTlz5hASEsLSpUs5ePAgI0aMAKBp06bMmTMHDw8PwsPDCQ8PZ/To\n0Znuf/bs2dSsWZM//viDMWPG8M4777B//34AUlJS6NatG05OThw4cIAFCxbwwQcfZBgcNjfls+9A\nQohHtSJkBS+tfIkPa6/jizc7ExZmdIbYsiV/dyF3cnJi4cKFDBkyhPnz51O3bl2aNWtGQEAA//rX\nvwAYOHBgavknnniCr776imrVqnHx4kXKlCmTelqtRIkSFC9ePNsxPP7443zyySdm6956663U3ytU\nqMCMGTPo0qULixYtwsXFBR8fH5RSPPbYYw/c/7PPPpvaqhoxYgSffvop27dvp0mTJmzbto2TJ0/y\n888/U7p0acBIaM1sOOy8tKCEEKl2nttJnzV9eCruNT4c2ImwMGjc2JiKPT8np3t69OjB5cuX2bBh\nA+3bt2ffvn00btyYadOmAfDHH3/QpUsXypcvj7e3Nw0aNAAgLCzMKvXXr18/w7odO3bQtm1bypQp\ng7e3N927dychIYErV65ke/+1atUye1yqVCmuXbsGwIkTJyhVqlRqcgJo2LAhDg62SxOSoIQQAPwZ\n/iddlnfB7/wwTs3+glu3FF26GKf1HqIxkGe5ubnRtm1b3n//ffbt28egQYOYOHEiUVFRtGvXDg8P\nDxYvXszvv//Oli3GGNcJCQn33aeDg4PZNBUAiYmJGcrdGyX8nvPnz9OxY0eqVavGihUrOHToEAsW\nLMhSnZbLn0ERAAAgAElEQVQ4OzubPVZKmU0+aG8kQQkhUqdrdwz6Nxe/mU18vGLYMFi1yrgRtyCr\nXr06SUlJBAcHExERwbRp02jevDlVq1ZNbX3cc6/XXXJystl6X19fwsPDzdYdPnz4gXUHBQWRkJDA\n7NmzadKkCZUrV+by5csZ6kxf38OoWrUqly9fNtt/UFCQTROYJCghBJ7OXjxzfguRq6eitWLaNPji\nC3B0tHVkuefGjRu0atWKJUuWcOTIEc6dO8eKFSuYMWMGrVu3pnr16ri6uvL5559z9uxZNm3axIQJ\nE8z2Ub58eZRSbNq0ievXrxMdHQ1Aq1at2Lx5M+vXr+fkyZOMHDmSCxcuPDCmSpUqkZKSwpw5czh3\n7hzLli1jzr2+/iYVKlQgLi6Obdu2ERERQWzsw4233bZtW6pUqUL//v05fPgwBw4cYOTIkTg5OZnN\n9ZWbJEEJUYDdib/D3rB9jBkDP35WC6WMbuRjx4KNPpNsxsvLi8aNGzN37lxatGhBjRo1GDduHC+/\n/DI//PADvr6+LFq0iLVr11K9enUmTZrErFmzzPZRunRpJk2axHvvvYefn19qh4SBAwemLs2aNcPb\n25tu3bo9MKZatWoxd+5cZs2aRfXq1fn666+ZOXOmWZmmTZvy2muv0atXL3x9fZkxY8ZDvX4HBwfW\nrFlDfHw8jRo1on///owbNw6lVI7NmPtAWZmTw14WmQ8q75LjlDW5OR9UXGKcbvVtG+3UaL4GrZ2c\ntF6+PFeqtgp5T2XNoxyn4OBgDeigoCDrBaRtMx+UECKPSNEp9F05kB2z+sPRPri5wcqV0LGjrSMT\ntrRmzRo8PT2pVKkSoaGhjBw5ktq1a1OvXj2bxCMJSogCRmvNiA2jWTExAE52xcsLNmwAf39bRyZs\n7c6dO4wZM4YLFy5QpEgR/P39mT17ts2uQUmCEqKAWXV0E1+OagN/d6BIEc2WLYpGjWwdlbAH/fr1\no1+/frYOI5UkKCEKkLg4+HpMR/hbUby4Zvt2Rbp7N4WwG9KLT4gCYmPIdp7tEMvWLQpfX9i5U5KT\nsG/SghKiANh5+gBdumhSznhQogTs2AE1atg6KiHuT1pQQuRzh87/xbMd4kg504bivins3CnJSeQN\nkqCEyMdOX71As2evk/S3P8VLJLEr0CFfzYAr8jc5xSdEPpWQAC07RhB/qjnFfBP5NdCZatVsHZUQ\nWSctKCHyoaQk6N0bLh2qi0+RJAJ3SHISeY+0oITIZxKSkmjU8TiHf66Fjw/s+MWJp56ydVRCZJ+0\noITIR1JSNDU77uHwz7VwdU9k82aw0Sg1QjwyqyYopVRRpdQapVSMUuq8Uurl+5R9Qim1USl1RykV\noZR6uCF4hRAAaA2NA/Zy6md/nFwS2bzJmSZNbB2VEA/P2i2oL4AEwA/oDXyllMrQoVUp5QJsA3YA\njwFlgCVWjkWIAqXdwIP8vvppHJySWL/WiZYtbR2REI/GaglKKeUJ9AAmaK2jtdZ7gHVAXwvFBwCX\ntdaztNYxWus4rfURa8UiREHzweR4ti1shHJI5sflivbtC9hkTiJfsmYnicpAktb6VJp1hwF/C2Ub\nA6FKqc1AQ+AYMEJrfTR9QaXUUGAogJ+fH4GBgVYM+dFFR0fbXUz2SI5T1kRGRpKcnJytY7VmTSk+\n/bQySmnGjA2hWLGbFIRDLe+prMnLx8maCcoLuJ1u3W3A20LZMkBL4HlgO/AmsE4pVVVrnZC2oNZ6\nPjAfoEGDBtrfzuYECAwMxN5iskdynLKmcOHCREZGZvlYTfvqLJ9+VgGA+fMVgwcXnMH15D2VNXn5\nOFnzGlQ0UCjdOh/gjoWyd4E9WuvNpoQ0EygGyJ0aQmTRtysv8d6IMqAdmDA5hsGDbR2RENZlzQR1\nCnBSSlVKs642EGKh7BFAW7FuIQqUzYE3GNS7MCS7MGDYTSaN97R1SEJYndUSlNY6BlgNTFZKeSql\nnsY4hbfYQvElQGOlVBullCPwFhAB/GWteITIr4KORNO5kwM6wZP2PSL45vOi2GjCUyFylLW7mQ8H\n3IFrwFJgmNY6RClVTikVrZQqB6C1Pgn0AeYBt4AuwPPprz8JIcxdvAgd2zuSHFOEhi2usW5ZcRzk\ndnuRT1l1qCOt9U2gq4X1YRidKNKuW43R4hJCZMHNm9CuHVy77E7DxokE/lQCZ2dbRyVEzpHvXkLk\nAdHRmqeePsfx48ZcTls2OePhYeuohMhZkqCEsHOJiVCvzRnC/3oc7xK32LoViha1dVRC5DxJUELY\nsZQUeKbLaU7/VhHXQrf5bZcPpUvbOiohcockKCHslNbQ9ZW/+W1zJRxd77JzqwfVqsq/rCg45N0u\nhJ366CPY8F1FlGMia1ZDk8YyfZsoWCRBCWGH/vc/zdixoBR8t1jTuYO7rUMSItdJghLCzty4+wxD\nX00B4PPPoU8vFxtHJIRtSIISwo5ERNfg4pmPQTvy2qirDB9u64iEsB1JUELYiQNBdwk5Og2S3eja\n5zJffuxn65CEsClJUELYgZOnE2nR5i4k+ODx2CZWLiwl4+uJAk8SlBA2duUKdGjvSEJUUdz99vGk\n70QcHW0dlRC2J/1WhbChqCh47rkUzp5xoH59jZvbFKKjE20dlhB2QRKUEDYSFwf1W17gzOGyVKyU\nzObNjgQE3M1Q7pdffmHPnj3UrFmTGjVqULFiRZyc5F9X5H/yLhfCBpKS4JmOYZz5sxxuRW6yZYsP\nvr6Wy164cIEpU6bg6elJSkoK8fHxlC5dmqeeeoqGDRumJq4nn3xSEpfIV+TdLEQu0xo6vXyRoB3l\ncPK4w94dXjz5ROYXnfr27cuECRO4dOlS6rrz589z/vx5tmzZgqenJ8nJycTHx1OmTBmeeuopGjVq\nREBAAFWrVs2NlyREjpAEJUQuG/BGOFtXlEE532XTRkW9Ove/EdfJyYmPP/6YIUOGEBMTY7YtOTmZ\n27dvpz4ODQ0lNDSUn376icKFC0uCEnma9OITIhd9/DF892VJlGMSi5ff5dmWXg9+EvDSSy9RokSJ\nLJV1cnKiUaNGvP76648SqhA2JwlKiFzy2bxo3nnH+H3Jd0707p71SZ0cHByYNWsWnp6eDyzr4eHB\n6tWrcZC54EUeJ+9gIXLB9z/G8O/hxoCvn34KL7+c/X106dKF8uXL37eMs7Mzjz/+OI5yI5XIByRB\nCZHDtv6SQN/eTqAd6TPiDCNGPNx+lFLMmTPnvq2oxMREjh8/TpUqVdi2bdtDRiyEfZAEJUQO+j0o\nmU7PJ6GTXGnb8xTfzX3ykfbXpk0bqlSpct8yiYmJREZG0qVLF95++20SE+XGX5E3SYISIoecOgUt\n2sSSdNeDum1PsuX7yo88vt69VpSHh4fZejc3twxl7969y/z586lbty5nz559tIqFsAGrJiilVFGl\n1BqlVIxS6rxS6oFn2pVS25VSWiklXd5FvnHxIrRtC3ejvKnY8G8ObKyCtfosPPPMM9StWzf1sYeH\nB0OGDKFQoUIZbtSNjY3lr7/+olatWixdutQ6AQiRS6zdgvoCSAD8gN7AV0qpGpkVVkr1BpytHIMQ\nNnXjBrRsE09YGDRuDME7K+Ji5TkHZ8+ejbu7O66urrRr1465c+dy4sQJGjRokKF1lZKSQkxMDEOG\nDKFXr14Z7qUSwl5ZLUEppTyBHsAErXW01noPsA7om0l5H+AD4B1rxSCErUVFwb9a3OLvk66UrRjF\npk2QhZ7h2dawYUOefvppihYtysKFC1FKUbJkSfbu3cu7776Lu3vGKeJjY2NZu3YtVatWJTg42PpB\nCWFlSmttnR0pVRfYq7X2SLNuFOCvte5sofwXwN/AGuAc4Ky1TrJQbigwFMDPz6/+8uXLrRKvtURH\nR+PllbWbLQuygnCc7t51ZPjIJwk9UQrnYmF8+8UZSvtl76LTW2+9RXJyMp999tkDy0ZFRREfH2/x\nBt7jx48zfvx4oqOjLXaScHV1ZeDAgQQEBKDy6MRTBeE9ZQ32eJxatmx5SGvd4IEFtdZWWYBngCvp\n1g0BAi2UbQAEYwy1VAHQgNOD6qhfv762Nzt37rR1CHlCfj9OsbFaN2x2W4PWTkUu6z//uvlQ+2nR\nooWuXbu2VWKKjIzUnTt31p6entr0P2a2eHp66pYtW+rr169bpb7clt/fU9Zij8cJCNJZyCvWvAYV\nDRRKt84HuJN2hVLKAfgSeFNbaDEJkdckJEDX7on8vtcbB++r7NgOdaoWsXVY+Pj4sG7dutRef+lb\nSjExMezZs4fKlSuzc+dOG0UpROasmaBOAU5KqUpp1tUGQtKVK4TRgvpBKXUF+N20/qJS6hkrxiNE\njktKgl694Octznj6xLF64x2eqVvS1mGlUkoxePBggoKCePLJJzNcm0pMTOTWrVt07NiRd955h6Qk\n+c4o7IfVEpTWOgZYDUxWSnkqpZ4GngcWpysaBZQC6piWDqb19YHfrBWPEDktORn69Etk9Wrw8YHd\nO93o0ryircOyqFq1ahw9epQ+ffpk6OUHxj1TX3zxBfXr1yc0NDT3AxTCAmt3Mx8OuAPXgKXAMK11\niFKqnFIqWilVznQK8sq9Bbhueu5VrXWCleMRIkdoDUNfS+aHZc7gcocf1kaR5tYku+Tm5sb8+fNZ\ntmwZhQoVyjBeX2xsLMeOHaNmzZr8+OOPNopSiH9YNUFprW9qrbtqrT211uW01ktN68O01l5a6zAL\nzwnVWiu5HiXyCq3hzTc1C752BKe7vPPFbtr5+9g6rCx7/vnnOX78OPXq1bN4z1R0dDSvvPIK/fr1\nIzY21kZRCiFDHeUr/v7+vPHGG7YOI1/TGv79b81nnylwjGfA9PV8NLjDg59oZ0qXLs3+/fsZPXp0\npvdMrVixgmrVqnHkyBEbRCiEJCiuX7/O8OHDqVChAq6urvj5+dG6dessjwQdHByMUoqIiIgcjvQf\nCxcutHhfw+rVq5k+fXquxVHQGMkJPv/cSE7Pv7+QBaNetHVYD83R0ZFJkyaxbds2fH19cUk33EVc\nXBxhYWE0btyYTz/99N4tIkLkmgKfoHr06MHBgwf55ptvOHXqFBs3bqR9+/bcuHEj12NJSHi0S3BF\nixbF29vbStGItLSGN96Azz8HV1fNv2fvZM2EIXn2Jte0mjVrxsmTJ2ndurXFqTzu3r3L2LFjadeu\nnU3+L0QBlpWbpexlsfaNurdu3dKA3rZtW6ZlFi9erBs0aKC9vLy0r6+vfuGFF/TFixe11lqfO3cu\nw82P/fv311obN1y+/vrrZvvq37+/7tixY+rjFi1a6Ndee02PGjVKFy9eXDdo0EBrrfUnn3yia9as\nqT08PHSpUqX0oEGD9K1bt7TWxk136ev84IMPLNZZvnx5PWXKFD106FDt7e2tS5curWfMmGEW08mT\nJ3Xz5s21q6urrlq1qt68ebP29PTU33777UMd08zY482CWZWcrPWwYVqD1q6uKXrz5pyry5o36mZX\nSkqK/vLLL7WHh4fFG3tdXFx0sWLF9K5du2wSX3p5+T2Vm+zxOGGDG3XzHC8vL7y8vFi/fj1xcXEW\nyyQkJDBp0iQOHz7Mxo0biYiIoFevXgCULVuWSZMmARASEkJ4eDhz587NVgxLlixBa83u3bv57rvv\nAGN67zlz5hASEsLSpUs5ePAgI0yz3DVt2jT1xsvw8HDCw8MZPXp0pvufPXs2NWvW5I8//mDMmDG8\n88477N+/HzAuiHfr1g0nJycOHDjAggUL+OCDD4iPj8/Wa8jPUlLg9dfhq68Apzjqj5zCc8/ZOqqc\noZRi2LBhHDx4kMcffzzDtamEhARu3LjBc889x9ixY+WeKZHzspLF7GXJiaGOVq5cqYsUKaJdXV11\n48aN9ahRo/SBAwcyLf/XX39pQF+4cEFrrfXs2bM1kGG4mKy2oGrWrPnAGDdv3qxdXFx0cnKy1lrr\nb7/9Vnt6emYoZ6kF1bNnT7MyFStW1FOmTNFaa71lyxbt6OiY2iLUWuu9e/dqQFpQWuukJK1fecVo\nOeEUq0sO66+v3LmSo3XasgWVVmxsrH7llVcybU15eHjounXr6vPnz9ssxrz4nrIFezxOSAsqa3r0\n6MHly5fZsGED7du3Z9++fTRu3Jhp06YB8Mcff9ClSxfKly+Pt7c3DRoY4xuGhWXoMf9Q6tevn2Hd\njh07aNu2LWXKlMHb25vu3buTkJDAlStXsr3/WrVqmT0uVaoU165dA+DEiROUKlWK0qVLp25v2LAh\nDtaauCgPS0iAnj3h229BucRS+JV+7J46AT8vP1uHlivc3d1ZsGABixcvxtvb2+I9U0eOHKFGjRqs\nXr3aRlGK/E4+iTBuYGzbti3vv/8++/btY9CgQUycOJGoqCjatWuHh4cHixcv5vfff2fLli3Agzs0\nODg4ZOj1ZGlU6fQXpc+fP0/Hjh2pVq0aK1as4NChQyxYsCBLdVri7Gw+3ZZSipSUlGzvpyCJjYUu\nXWDlSnByj8XtlS7smDSOJ4s+2nTteVH37t05duwYtWrVynDPVHJyMtHR0fTt25eBAwdy9+5dG0Up\n8itJUBZUr16dpKQkgoODiYiIYNq0aTRv3pyqVaumtj7uuTeDaXJystl6X19fwsPDzdYdPnz4gXUH\nBQWRkJDA7NmzadKkCZUrV+by5ctmZVxcXDLU9zCqVq3K5cuXzfYfFBRUoBPY7dvw3HOwZQsULw7b\ntieyY/wU6pa082EiclC5cuU4ePAgb775Zqb3TC1evJh169bZIDqRnxXoBHXjxg1atWrFkiVLOHLk\nCOfOnWPFihXMmDGD1q1bU716dVxdXfn88885e/YsmzZtYsKECWb78PPzQynFpk2buH79OtHR0QC0\natWKzZs3s379ek6ePMnIkSO5cOHCA2OqVKkSKSkpzJkzh3PnzrFs2TLmzJljVqZChQrExcWxbds2\nIiIiHvpu/7Zt21KlShX69+/P4cOHOXDgACNHjsTJySlfdJ/OrogIaNUKdu8GH987/LIzHv8mPjQu\n09jWodmck5MT06ZNY/PmzRQrVszsniknJyfq1q1LQECADSMU+VGBTlBeXl40btyYuXPn0qJFC2rU\nqMG4ceN4+eWX+eGHH/D19WXRokWsXbuW6tWrM2nSJGbNmmW2D19fXyZNmsR7772Hn59f6kgOAwcO\nTF2aNWuGt7c33bp1e2BMtWrVYu7cucyaNYvq1avz9ddfM3PmTLMyTZs25bXXXqNXr174+voyY8aM\nh3r9Dg4OrFmzhvj4eBo1akT//v0ZN24cSinc3Nweap95VVgYNG8Ohw5BoceuEfVyTf522GjrsOxO\nixYtOHnyJC1atEg9Pe3h4cGaNWsyXKcS4pFlpSeFvSwyYWHOCw4O1oAOCgqy6n7t+TgFB2tdsqTR\nW8+3whXNqMf0e9vfs0ks9tKL70FSUlL0p59+ql1cXPTatWttEoM9v6fsiT0eJ7LYi8/J1glS2Naa\nNWvw9PSkUqVKhIaGMnLkSGrXrk29evVsHVqu2L4dunWDO3egYr1L/N22BoOavsCUllNsHZpdU0ox\nYsQIhgwZUuBa2yL3SIIq4O7cucOYMWO4cOECRYoUwd/fn9mzZxeIa1Dffw+vvAKJidDthQR21W3I\n80+0YF6neQXi9VuDJCeRkyRBFXD9+vWjX79+tg4jV2kNH30EY8caj0eNghkzXPj7ViBlC5XFyUH+\nLYSwBwW6k4QoeBIS4LXXjOSkFIyadBHfrh+hlKZyscq4O2fsRi2EsA1JUKLAiIiAtm1h/nxwc4O5\n31xhiUcDvvj9CyLjIm0dXoFVoUKFDD1VhQA5xScKiKNH4fnnITQUSpaEBctu8Mbhp0lMSWRn/50U\ncS9i6xDztQEDBhAREcHGjRm77v/+++8Wp/kQIt+3oGJjY+nUqRP/+9//iImJsXU4wgbWr4emTY3k\n1LAhBO6N5r2Tz3L5zmU2vbyJar7VbB1igebr65thGCVbeNT52IT15fsEtWzZMrZv387bb7+Nr68v\ngwcP5syZM7YOS+QCrWH6dOjaFaKjoVcv2LULTifuIuRaCCtfXCmjRNiB9Kf4lFLMnz+fgIAAPD09\neeKJJ1iyZInZcy5dusTkyZMpUqQIRYoUoWPHjpw+fTp1+5kzZ+jSpQuPPfYYnp6e1KtXL0PrrUKF\nCkycOJGBAwdSuHBhevfunbMvVGRbvk9QM2fOJC4ujpiYGO7evcvChQv5+OOPbR2WyGGRkcb9TePG\nGYlq2jSjW7m7O3Ss3JGzb56lQ6UOtg5TZGLy5Ml06dKFw4cP89JLLzFw4MDUGQRiY2Np2bIlLi4u\n7Nq1i/3791OyZEnatGmTOuxXdHQ07du3Z9u2bRw+fJgePXrQvXt3Tpw4YVbPrFmzqFq1KkFBQakz\nGAj7ka8T1KFDhzJMi+Hm5sbgwYNtFJHIDYcOQb16sG4dFC5snOJ7913NmF/eYcPJDQCU8i5l4yjF\n/fTt25c+ffpQsWJFpkyZgpOTE7/++isAy5cvR2vNmDFjqFWrFlWrVuW///0v0dHRqa2k2rVr89pr\nr1GzZk0qVqzIe++9R7169Vi5cqVZPS1atOCdd96hYsWKVKpUKddfp7i/fN1JYvbs2Rlmyi1dunTq\nnE4if9Ea5s2Dt94yupPXrw8rVsDjj8P03R/y8b6PSdEpdK7S2dahigdIO4+Zk5MTvr6+qTMJHDp0\niHPnztGhQwez8f9iY2NTT9/HxMQwadIkNm7cSHh4OImJicTFxWWYH00+C+ybVROUUqoo8A3wLBAB\njNVaL7VQrj/wb6AScBtYCozTWlttDumoqChWrVplNnWEp6cn//nPf6xVhbAj0dHw6quw1PRuGzYM\nZs0yupMv+HMB43aM4+WaLzOj7cMNrCty1/3mMUtJSaFOnTq8/fbb/Otf/zIrV7RoUQBGjx7Nli1b\nmDlzJpUqVcLDw4N+/fpl6AghvQftm7VbUF8ACYAfUAfYpJQ6rLUOSVfOA3gL+A3wBdYDo4EPrRXI\nokWLMswMq7WmV69e1qpC2InffoO+feH0afD0NO5zevllY9uGkxsYumEozz75LN92+RYHla/PahcI\n9erVY9myZfj4+FCxYkWLZfbs2UO/fv3o0aMHAHFxcZw5c4bKlSvnZqjiEVktQSmlPIEewFNa62hg\nj1JqHdAXeDdtWa31V2keXlJKfQ+0tFYsWmtmzZplNk+So6MjvXv3lm9M+UhiIvzf/8HUqZCcDE89\nBT/+CNXS9BoPDA2kXsl6rHpxFS6OLpnvTOS427dvExwcbLaucOHC2d5P7969mTlzJu+99x7e3t6U\nK1eOCxcusG7dOl577TUqVapE5cqVWbNmDV26dMHZ2ZlJkyZlON0v7J81W1CVgSSt9ak06w4D/ll4\nbnMgfSsLAKXUUGAoGJMDBgYGPnBnR44csTjzbZMmTbL0/OyIjo62+j7zI2sfp4sX3fm//6vGiROF\nUErz4osXGTToHFevpnD1qvElRSlFJ5dOtHmiDUH7gqxWd06KjIwkOTk5372nrly5wu7du6lb13xm\n4ubNm6e2btK+5pCQEIoXL576OH2Z6dOn8+WXX9K1a1diYmIoVqwYderU4fjx41y6dImAgAA+/vhj\nmjVrhpeXFy+88ALVq1fnypUrqfuwVG9+lKc/o7IyJ0dWFuAZ4Eq6dUOAwAc8byBwESj+oDqyOh9U\nly5dNGC21K1bN6tTlWSLPc61Yo+sdZxSUrSeN09rDw9j/qayZbXescO8TFhkmG76TVMdci3EKnXm\nprwyH5Q9kP+9rLHH44QN5oOKBgqlW+cD3MnsCUqprsB0oI3WOsIaQVy/fp2tW7earfPy8mL06NHW\n2L2wodOnjY4QO3caj3v3hs8/N7qS33Pz7k3aLWnHpTuXSExOtE2gQgirsOYV41OAk1Iq7c0Etcn8\n1N1zwP+Azlrro9YK4uuvv7ZUV+rFUpH3JCYaN9rWrGkkp+LFYflyWLLEPDnFJsbSaWknzt46y/qe\n66n9WG3bBS2EeGRWa0FprWOUUquByUqpwUBd4HmgafqySqlWwPdAN631QWvFkJKSwty5c80uhjo7\nOzN48GBcXV2tVY3IRb/9BkOGGIO9AvTrB598YiSptBKTE3lxxYscuHiAFQEraFGhRe4HK4SwKmv3\nuR0OuAPXMO5tGqa1DlFKlVNKRSulypnKTcA4/feTaX20Umrzo1a+bdu2DAPCOjo68sYbbzzqrkUu\nu3kT3ngDmjQxktMTT8C2bbBoUcbkBBCXFEd0QjRfdvySHtWltSxEfmDV+6C01jeBrhbWhwFeaR5b\nrUt5WjNnziQ6OtpsXf369XniiSdyojqRA5KSjNEg3n8fbt0CR0cYPdp4nNmA10kpSXi7erO933Yc\nHRwtFxJC5Dn55q7Fixcvsnv3brN13t7eMnJEHvLzz1C7NowYYSSnVq3gzz/hww8zT05zD8yl5aKW\n3I6/LclJiHwm3ySor776KsM6Z2dnOnbsaINoRHYcPw6dO0O7dsbvTz4Ja9fCL78YHSMys/zYct7a\n+hYlPEvg6Sw3YAuR3+SLBJWUlMRXX31FfHx86jpXV1def/11nJzy9Xi4edrp09CnjzECxMaN4O0N\nM2ZASAh06QJKZf7cbWe20W9NP5qXb8733b+X1pMQ+VC++PTesGEDSUnm48wqpXj11VdtFJG4n9BQ\nmDLF6PCQnAzOzjB0KEyYAH5+D37+ocuH6P5jd6oWr8q6nutwc3LL8ZiFELkvXySojz/+mDt3zO8H\nbt68OaVLl7ZRRMKSs2dh5kz4+mvj3iZHRxg8GMaPh/Lls74fLxcv6pesz9IeSynslv2x3IQQeUOe\nT1B///03f/75p9k6GTnCvhw6BJMmVefXXyElxTh116cPfPABZDIYtUW342/j7eJNleJVCBwQmGPx\nCiHsQ56/BvX555+TnJxsts7Ly4vWrVvbKCIBxuSBW7dC69bQoAEEBpbA0RH694djx2Dx4uwlp6i4\nKLqMPBkAAA6bSURBVJp/25yRW0fmXNBCCLuSpxJUfHw8a9asSZ10LD4+nm+++YbExH/GXHN3d+et\nt97KMBeUyB2RkfDpp1CjBjz3HOzYYXR+eOmlMM6ehYULoXr17O0zLimOrj90JeR6CO0qtsuRuIUQ\n9idPneK7ffs2AQEBeHl58eqrr5oNx39PSkoKgwYNskF0BVtQEHz1FSxbBnfvGutKloQ33zQGeA0O\nPkuZMuXuvxMLklOS6bumL4GhgSzutpjnKj5n5ciFEPYqTyUoJycnPDw8iIqKYs6cOWitzVpPSik6\ndOhgMXEJ64uIMAZtXbTISFD3tG5tTLn+/PNGD71H8fbWt1l5fCWfPPsJfWr1ebSdCSHylDyXoO6d\nurt3mi8tDw8PXnnlldwOq0CJi4MNG4xrSJs3G0MTARQpAgMGGK2lKlWsV99zFZ/Dx9WHkU3k2pMQ\nBU2eSlCOjo73Jjm0KDk5mYCAANq0acOoUaPw9/dH3e9uT5ElcXHGQK2rV8OaNRAVZax3dIT27aFv\nX+jaFdzdrVdnWFQY5XzK0aFSh/9v7+6Dq6rvPI6/v3kAcnkmKDh0eXANFZE2WVF3BNZIAXlMaWmF\nWnZ3LFsd6dbp0jKw1o6rTtuZ0mk7TBUmO65SBFG3MDgGpMOKDNTpoKVhGdY2MBNJEVCeQkKeSMh3\n/ziJJIEkN+TCOTf385r5Te4995d7v3Pm5HzzO/d3vj9m58xO3BuLSNJIqpkEGRkZrS7ptVVbW0td\nXR1FRUVMmzaNJ5988gZG17NUVsJrr8HChXDTTcHlupdfDpLTXXfBr34FH38M27bBN76R2OS09c9b\nuW31bRSVFCXuTUUk6STVCCojI6NVOaP29OnTh5ycHJYt02WheLkHdfDefjuYHr57N7S8ipqXB1/9\nKixYAOPGXb849hzdw6LfLiLvljzyR+dfvw8SkchLqgSVlpZGZmZmh0kqFosxefJktmzZQqy9EtgC\nwKefBonod78LEtOxY5dfM4PJk+ErXwnamDHXP56DnxykYFMBowaOoujhIvr2UgFYkVSWVAkKgiU0\n2ktQsViMxYsX88ILL5CeruKhbZ04ESSk5vbhh61fv/nmoKL4zJkwfXpwae9GOVtzlpkbZhLLjLFj\n8Q6GxjQTUyTVJV2CGjRoEKdPn75ie1ZWFk8//TTLly/XxAigqgr274d9+y63jz5q3ScrK1ixdurU\nYLJDbi6EdX/z4D6DWfb3y5jxtzMYNagLhflEpMdKugSVnZ3NkSNHWm3LysripZdeYuHChSFFFa6K\niqB80MGDwf1I+/YFzxsbW/fr2xcmTYL77w/a3XdDr17hxNys6mIVZefLGHfTOL5/3/fDDUZEIiXp\nEtSwFusxmBn9+vVj27ZtTJ48OcSobozaWjhyJEhELdvRo1f2TU8PRkT33HO5jRsHUVoeq/5SPV9/\n4+vs+3gfR544osrkItJKhE5X8Rk+fDgQzOjLzs5m9+7dfD6Rd4aGrL4+SDglJcGCfs0/Dx8Otl/t\nNrBevYL6dhMmBEnp3nuDWXdRniPS6I0seXMJ249sp3BuoZKTiFwh6RLUiBEjSEtLIycnh127drUa\nUSWD8+eDRFNW1ro1bzt+/MpLc83S0uDWW4MVaCdMuNxycqI1MorHyp0rWf+/63nugef49l3fDjsc\nEYmgJDutQW5uLvPmzWPDhg307RuNach1dUFduk8+gZMnr2zN20+cCG6A7YgZfO5zMHZs0HJygjZ2\nbDDVO+zvjBLh9UOvs+q9VXzn7u/wwyk/DDscEYmopEtQBQUFFBQUJPQ93YNZb5WVQauoCH6ePw9n\nz8KZM8HP5tby+alTU6itjf+zYrFg9diRIy+3ls9HjOgZSagjX/78l1k9czVL716qGZci0q6EJigz\nGwK8CMwATgP/7u4b2+n7b8AKIAb8N/C4u3dYJqKhIbgUVlNzuVVXd/y8eVvLBNQyCTW3Dkr8dSKd\njAzIzobhw69sw4a1fj5oUDBKSkV7y/Yybug4smPZfPfe74YdjohEXKJHUM8DF4FhQC5QZGYH3P1Q\ny05m9iCwEpgKHAe2AM80bWvXgQMwenSCI26SlQUDBgSL6/XvHzweMCBIPEOGBO1qjw8d2sOsWVNS\nNunE68OKD1n+ynLmjJ3Da197LexwRCQJWEfVwbv0RmZ9gXPAne5e0rTtN8Bxd1/Zpu9G4CN3f7Lp\n+VRgo7sP7/gz8rx37x2kpdV91tLTmx9fJD299rPHwWu1rR6np1eTnl5NRkZ1m8c1mF3q6KPbVV5e\nzqBBmoHWkeqsavbn7SezMZPc/bn0vtg77JAiq7i4mIaGBiZOnBh2KJGnv734RHE/7d69+4/u3ulB\nnsgR1FigoTk5NTkA5F+l73hga5t+w8ws293PtOxoZo8CjwJkZmZy++0zuh1oY2PQOiiMHrdLly5R\nXl7e/Tfqoer71HP4nsPgMHrPaGqqaqihJuywIquhoQF31zEVB/3txSeZ91MiE1Q/oKLNtgqgfzt9\nz7fpR1PfVgnK3QuBQoCJEyf6By2Xbo2Ad999l/z8/LDDiKz5m+ZTVlrGz+/8OY/99LGww4m8/Px8\nysvLKS4uDjuUyNPfXnyiuJ/inRyVyAR1ARjQZttA4GoTq9v2Hdj0s5NJ2JJs1s5dy+Ezh7lUem2X\nUEUkdSWyNGgJkGFmOS22fRE4dJW+h5pea9nvk7aX9yQ5XWq8xJr319DQ2MDwfsOZMmpK2CGJSBJK\nWIJy9ypgM/CsmfU1s8lAAbD+Kt1/AywxszvMbDDwI+DlRMUi4XF3lhYtZem2pbxV8lbY4YhIEkv0\n4gpLgSzgU2Ajwb1Nh8xspJldMLORAO7+NvAzYBdwFCgFnk5wLBKCZ3Y/Q+H+QlZOWsn82+eHHY6I\nJLGE3gfl7meBK85K7l5GMDGi5bZfAL9I5OdLuNZ+sJZndj/DI7mP8JMv/STscEQkyYW0PJ30NGeq\nz7Bi5wrmjp1L4bxClTASkW5Lulp8Ek3ZsWz2PLKH24bcRkaaDisR6T6NoKRbDpw8wJr31wDwhWFf\nIJYZ4UWoRCSp6F9duWal50qZuWEmGWkZPDzhYQb2Gdj5L4mIxEkJSq7JqapTPPjKg9Q11LHzkZ1K\nTiKScEpQ0mUXLl5g9sbZHKs4xs5/2sn4m8eHHZKI9EBKUNJlO47soPhkMZsf2sx9f3Nf2OGISA+l\nBCVdtuCOBZTcUsKYwWPCDkVEejDN4pO4uDtPvfMUu0p3ASg5ich1pxGUxGXVe6v48Z4fU1NfwwNj\nHgg7HBFJARpBSafWFa9jxc4VLBy/kFUzVoUdjoikCCUo6VBRSRFL3lzCtFunsW7+OtJMh4yI3Bg6\n20iHtv5lK7nDc9n80GZ6Z/QOOxwRSSH6Dko6tHbuWirrKunfu3/YoYhIitEISq5wrOIY09dPp/Rc\nKWmWpioRIhIKjaCklXM155j5ykzKzpdRXlsedjgiksKUoOQzNfU1zHt1HofPHmb7N7eTd0te2CGJ\nSApTghIAGhobWPTbRbz31/fY9LVNTB0zNeyQRCTF6TsoAaCyrpLjlcdZPWs1D41/KOxwREQ0ghJo\n9EYGZw3m99/6Pb3Se4UdjogIoBFUyvv1vl8zZ+McquurlZxEJFKUoFLYG4fe4IntT9A7vbeSk4hE\njhJUinqn9B0Wb1nMpJGTeHXBq2Sk6WqviERLQhKUmQ0xsy1mVmVmR83s4Q76/rOZ/dHMKszsmJn9\nzMx0dryB/nTiT8zfNJ+cITm8uehNsjKzwg5JROQKiRpBPQ9cBIYB3wTWmFl764DHgO8BQ4F7gS8B\nP0hQHBKncTeNY8fiHQzOGhx2KCIiV9XtkYuZ9QUWAHe6+wVgr5ltBf4RWNm2v7uvafH0YzPbAGiB\noRugur6aWGaMvFvy+MOSP2BmYYckItKuRFxaGws0uHtJi20HgPw4f/8fgEPtvWhmjwKPNj29YGZ/\nuZYgr6OhwOmwg0gC2k/xG2pm2led0zEVnyjup1HxdEpEguoHVLTZVgF0Wv7azL4FTAT+pb0+7l4I\nFHYnwOvJzD5w94lhxxF12k/x076Kj/ZTfJJ5P3X6HZSZvWtm3k7bC1wABrT5tYFAZSfvOx/4KTDL\n3aOW3UVEJGSdjqDcPb+j15u+g8owsxx3P9y0+Yt0fNluJvCfwBx3Pxh/uCIikiq6PYvP3auAzcCz\nZtbXzCYDBcD6q/U3s6nABmCBu+/r7udHQGQvP0aM9lP8tK/io/0Un6TdT+bu3X8TsyHAfwHTgTPA\nSnff2PTaSOD/gDvcvczMdgFTgNoWb7HH3Wd1OxAREekxEpKgREREEk2ljkREJJKUoEREJJKUoBLM\nzHLMrNbMXgk7lqgxs95m9mJTvcZKMys2M3332KQrNS1TlY6hrkvmc5ISVOI9D7wfdhARlQH8Fbif\n4F65p4DXzWx0iDFFSVdqWqYqHUNdl7TnJCWoBDKzRUA58D9hxxJF7l7l7v/h7h+5e6O7vwWUAneF\nHVvYWtS0/JG7X3D3vUBzTUtpomOoa5L9nKQElSBmNgB4FlgWdizJwsyGEdRybPem7hTSXk1LjaA6\noGOofT3hnKQElTjPAS+6+7GwA0kGZpZJcMP2Onf/c9jxRMA117RMVTqGOpX05yQlqDh0Vo/QzHKB\nacAvw441THHUbWzul0ZQaeQi8K+hBRwt11TTMlXpGOpYTzknaSXbOMRRj/B7wGigrGmNpX5Aupnd\n4e5/d90DjIjO9hOABTvoRYKJALPdvf56x5UkSuhiTctUpWMoLvn0gHOSKkkkgJnFaP3f7w8IDo7H\n3f1UKEFFlJmtBXKBaU0LXEoTM9sEOMHyM3lAEXCfuytJtaBjqHM95ZykEVQCuHs1UN383MwuALXJ\ndCDcCGY2CngMqANOtljR9zF33xBaYNGxlKCm5acENS0fV3JqTcdQfHrKOUkjKBERiSRNkhARkUhS\nghIRkUhSghIRkUhSghIRkUhSghIRkUhSghIRkUhSghIRkUhSghIRkUj6f9NgHHANczmAAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109f47290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.linspace(-5, 5, 200)\n",
    "\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [1, 1], 'k--')\n",
    "plt.plot([0, 0], [-0.2, 1.2], 'k-')\n",
    "plt.plot([-5, 5], [-3/4, 7/4], 'g--')\n",
    "plt.plot(z, logit(z), \"b-\", linewidth=2)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Saturating', xytext=(3.5, 0.7), xy=(5, 1), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Saturating', xytext=(-3.5, 0.3), xy=(-5, 0), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.annotate('Linear', xytext=(2, 0.2), xy=(0, 0.5), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Sigmoid activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.2, 1.2])\n",
    "\n",
    "save_fig(\"sigmoid_saturation_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xavier and He Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the book uses `tensorflow.contrib.layers.fully_connected()` rather than `tf.layers.dense()` (which did not exist when this chapter was written). It is now preferable to use `tf.layers.dense()`, because anything in the contrib module may change or be deleted without notice. The `dense()` function is almost identical to the `fully_connected()` function. The main differences relevant to this chapter are:\n",
    "* several parameters are renamed: `scope` becomes `name`, `activation_fn` becomes `activation` (and similarly the `_fn` suffix is removed from other parameters such as `normalizer_fn`), `weights_initializer` becomes `kernel_initializer`, etc.\n",
    "* the default `activation` is now `None` rather than `tf.nn.relu`.\n",
    "* it does not support `tensorflow.contrib.framework.arg_scope()` (introduced later in chapter 11).\n",
    "* it does not support regularizer params (introduced later in chapter 11)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                          kernel_initializer=he_init, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonsaturating Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReLU\n",
    "got a problem call dying relu, as the input become zero and the neurons are unlikely to come back life, to solve this problem we try the variant of relu : leaky relu "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leaky ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leaky_relu(z, alpha=0.01):\n",
    "    return np.maximum(alpha*z, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure leaky_relu_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8FPX9x/HXh3AlHCJyVMGCeKCgVSDeLcaj1FsUVBCt\nJ4dWrQdaDyoinhVr8QQsisghihyK0v4UiYpXBUXxAkpBBRURSSCEBJJ8f398Fw0hx26Szczuvp+P\nxz7YzU523jts9r0z890Zc84hIiISNvWCDiAiIlIeFZSIiISSCkpEREJJBSUiIqGkghIRkVBSQYmI\nSCipoKRCZpZtZo8EnSMZmFmWmTkza1UH81plZkPrYD77m9m7ZlZgZqviPb8o8jgz6xt0Dqk9KqgE\nZWYTzGxO0DliFSk9F7lsNbMVZnaPmTWK8XEuMrO8KuazU7lW9Xu1oYKCeAfYHVhfi/O53cw+Leeu\nQ4HHams+lbgTyAf2j8yzTlTy2t8deKmuckj81Q86gKSkp4BbgIb4N7YnIz+/ObBEceac2wp8X0fz\nWlcX8wH2AWY751bV0fwq5Zyrk+UrdUdrUEnKzHYxs3Fm9oOZbTKzN8wss9T9u5nZVDNbbWZbzOwz\nM7u4isc83sxyzGyImfU0s21m9qsy09xlZp9UES/fOfe9c+5r59wLwGtArzKP087MnjWzDZHLy2a2\nb4yLoVrM7F4zWxpZLqvM7G9m1rjMNCeb2fuRadab2Utm1tjMsoEOwP3b1xQj0/+8ic/Mmkd+77Qy\nj9krskzbVJXDzC4ChgNdS62RXhS5b4c1ODP7tZnNjLwONpnZDDNrX+r+283sUzPrF1mj3WRmsyrb\nHBl5XgcDt0XmfbuZdYxczyw77fZNb6Wm6WNmr5pZvpl9bma/L/M7+5vZi2aWa2Z5kU2JB5nZ7cCF\nwCmlnndW2flEbh9kZq9Flt9PkTWvXUrdP8HM5pjZn81sTeR19pSZZVT0vKVuqaCSkJkZ8DLQDjgV\n6Aa8CbxuZrtHJmsMfBi5vyswGhhrZsdX8Jh9gZnAIOfcGOfcm8AK4I+lpqkXuT0+hqwHA0cD20r9\nLAOYDxQAxwBHAt8Br9XRm8dm4BLgAOAKoB9wa6l8JwIvAq8CPSIZ5+P/ns4CVgN34Dc57U4ZzrmN\n+E1RA8rcNQB41Tn3QxQ5pgEPAEtLzWda2XlF/k9mA22BYyOXPYBZkdfJdh2Bc4Ez8R8WugF3VbB8\niMxvaSTD7sCoSqYtz13AQ/iS+wB41syaRjLvASwAHPB74JDItGmR+TyH/1Cz/Xm/U87zbgL8G8gD\nDos8r6P4ZW19u98BBwIn8Mvz/3OMz0XixTmnSwJegAnAnAruOw7/h5le5ueLgRsrecxngX+Wup0N\nPAIMAnKBXmWmHwp8Uer2SUAhsFsl88gGtkbyFeLfhIqBPqWmuQRYDlipn6Xh99+cE7l9EZBXxXwe\nKefnlf5eBY81BPhvqdtvA89WMv0qYGiZn2VFnmuryO3T8ftvmkVupwMbgfNiyHE78Gll88e/wRcD\nHUvd3wkoAU4o9TgFwC6lprm19LwqyPMpcHup2x0jzzGzzHQO6FtmmsGl7m8X+dlvI7fvAr4CGsby\n2i8zn4GR12yzcv4P9in1ON8AaaWmeQJ4rTp/k7rU/kVrUMmpB5ABrItsHskzPzDgQGBvADNLM7Nb\nzeyTyCaqPPyn/1+XeazewKPAic65/ytz39NAJzM7KnL7EmCWc66qgQDT8J+Kj8R/Gn7C+U19pfPv\nBWwqlT0X2HV7/ngys75mtsDMvo/M+0F2XC7dgHk1nM1cfEGdGbl9OmDArBhyROMA4FtXaj+Rc+5/\nwLdAl1LTfeWcyy11+1ugTYzzikXpzcDfRv7dPr9uwALn99tV1wHAJ865TaV+9g6+mEs/78+dc8Vl\nssTzeUsMNEgiOdUD1uI3X5S1MfLvUOB6/OaMJfg1mrvZ+Y/zY+Ag4FIze89FPmaC3xlvZi8Cl5jZ\nUvyb7GlULdc5918AMzsf+MzMLnLOTSiVfzF+k1ZZP0Xx+OCf5y7l/LwFvuzKZWZH4NckRwDXAjn4\n5xXrJqxKOee2mdlz+M16EyP/znTO5ddhjtKnMthWzn2xfoAtifz786ZDM2tQwbQ/z8855yJbG+vq\nA3NtP2+JExVUcvoQv8+hJPJpuTy/BV5yzj0DP++32g//RljaSuAq/CazcWY2qHRJ4TeJTAf+hx+l\n9losQSNv1HcD95jZc5E36A+B/sCPzrmyeaK1FDjZzKxM3u6R+ypyNLDGOTdy+w/MrEOZaT4Cjsc/\n9/JsxW+SrMok4E0z6wKciN8fGEuOaObzBbCHmXXcvhZlZp3w+6E+jyJjLLaPHiy93+2QajzOR8D5\nZtawgrWoaJ/3JWbWrNRa1FH48vmiGpkkAPqkkNiam9khZS4d8SXxNjDbzE4ys73M7EgzG2Fm29eq\nlgHHm9lvzWx//L6mvcqbSaTkjsW/iY4ts3P9Vfy+oeHABOdcSTkPUZUp+E+uV0ZuT8avAc42s2Mi\n+Xua2QO240i+euU8/wMj9z2O39fysJkdbGadzexafPHdX0mWZUA7MxtgZp3M7PLI75R2F3C2md1p\nZl3MrKuZXVtqAMcq4HfmRyJWOBLOOfcOfl/LFOBHdtxsGE2OVUAHM+tufnRged8lew2/OW2ymWWa\nH2E3Gf8h4PVKlkPMnHNbgPeAv0SWyVFUb43vMaAp8JyZHWpm+5hZfzPbXnargAMj/6etKlhLm4zf\nhDrR/Gi+nsBYYMb2tXcJPxVUYvsd/tNm6cuoyBrDyfg3oCfwawzPAZ35ZXv/ncB/8PtC3sSPGJtc\n0YyccyvwO5lPolRJReb1FNAg8m/MIp+SHwFujHzizQd64tfKnge+xO/v2hXYUOpX08t5/tmRx/xf\n5DH2Bf4v8lz7AWc75+ZWkuUlfIH9A//G/nvgtjLTvILfd3RSZJ5v4At8eznfBuyJH+VY1XeSJuNH\nsj1bel9INDmAF4BX8MW2jp0LbPv/zxmR++dHLt8DvcusWdaWSyL/foAvhGGxPoBzbg3+/64hPu9H\n+LX4osgkT+DXghbin9fR5TxGPvAHoDn+/3428G6pfJIALD6vUUklZvY4fmTU76ucWEQkStoHJdVm\n/kuPXfDffTon4DgikmRUUFITs/FfghzvnHs56DAikly0iU9EREJJgyRERCSU4raJr1WrVq5jx47x\nevga2bx5M02aNAk6RkLSsovd0qVLKS4upkuXLlVPLDvQ6636Klp2K1fCTz9Bo0ZwwAGQFs039mrZ\nokWLfnTOta5qurgVVMeOHVm4cGG8Hr5GsrOzycrKCjpGQtKyi11WVhY5OTmh/XsIM73eqq+8ZffA\nAzB0KDRpAu+/D127BpPNzL6KZjpt4hMRSQGvvgo33uivT5wYXDnFQgUlIpLk/vc/OPdcKCmBv/4V\nzjor6ETRUUGJiCSxzZuhd2/YsAFOPRVuvz3oRNFTQYmIJCnn4OKLYckS6NwZJk2Cegn0rp9AUUVE\nJBb33QfPPw/NmsGsWbBLeSegCbGYCsrM9jWzAjObFK9AIiJSc++/35JbbvHXJ0+G/fcPNk91xLoG\n9Sj+KMUiIhJSy5fDnXcegHMwYgScFs1pREMo6oIys374k9nV9FTXIiISJ5s2+UEReXkN6N0bhsV8\nwpPwiOqLumbWHLgDOA64rJLpBgGDANq2bUt2dnYtRKx9eXl5oc0Wdlp2scvJyaG4uFjLrRr0eotN\nSQkMH96Vzz9vzZ57bmLgwMW8+WZx1b8YUtEeSWIk/ojVq3c8meqOnHPjgHEAmZmZLqzfANe306tP\nyy52LVq0ICcnR8utGvR6i83IkbBggR8Mcffdn3Pyyb+r+pdCrMqCipxm+QSgW/zjiIhIdbz0Egwf\nDmYwdSqkp28JOlKNRbMGlQV0BL6OrD01BdLMrItzrnv8oomISDS+/BLOP99/7+nuu+GkkyAZtoxG\nU1DjgGdL3R6KL6zL4xFIRESil5vrB0Vs3Ah9+8JNNwWdqPZUWVDOuXwgf/ttM8sDCpxz6+IZTERE\nKldS4tecli6Fgw6Cp57ym/iSRcyn23DO3R6HHCIiEqMRI2DOHNh1V3+kiKZNg05Uu3SoIxGRBDRz\nJtxxhz+23rPPQqdOQSeqfSooEZEE89ln8Mc/+uv33Qe9egWbJ15UUCIiCWTDhu1HioD+/eH664NO\nFD8qKBGRBFFcDAMGwH//C4ccAv/8Z3INiihLBSUikiD++leYOxd2283vg8rICDpRfKmgREQSwHPP\nwT33QFqav96xY9CJ4k8FJSIScp984s+MC/DAA3DcccHmqSsqKBGREPvpJz8oIj/fj9y7+uqgE9Ud\nFZSISEgVFUG/frByJfToAWPGJPegiLJUUCIiIXXzzfDqq9C6tR8UkZ4edKK6pYISEQmhKVNg1Cio\nXx+mT4c99ww6Ud1TQYmIhMxHH8FlkXOX/+Mf0LNnsHmCooISEQmRdev8oIgtW+CSS+CKK4JOFBwV\nlIhISGzbBueeC19/DYcfDo8+mlqDIspSQYmIhMQNN8D8+fCrX8ELL0DjxkEnCpYKSkQkBCZOhNGj\noUEDX07t2gWdKHgqKBGRgC1cCIMG+euPPAJHHRVsnrBQQYmIBGjtWjjzTCgshMGDfykqUUGJiARm\n61Y4+2xYvRqOPhoeeijoROGighIRCch118Fbb8Eee/gv4zZsGHSicFFBiYgEYPx4P4y8YUOYMcOP\n3JMdqaBEROrYe+/98gXcMWP8d55kZyooEZE69N13cNZZfv/TlVf+cp4n2ZkKSkSkjhQWQp8+vqR6\n9oS//z3oROGmghIRqSNXXw3vvgvt28Pzz/sv5UrFVFAiInVg7FgYN84fvmjWLGjTJuhE4aeCEhGJ\ns7ffhquu8tfHjfNnx5WqqaBEROJozRq/32nbNrjmGrjggqATJQ4VlIhInBQU+BF7a9fCccfB/fcH\nnSixqKBEROLAObj8cvjPf6BDB5g2zZ++XaKnghIRiYNHH4UJEyA93Q+KaNUq6ESJRwUlIlLL3ngD\nrr3WX3/ySTjkkGDzJCoVlIhILfr6a3+E8qIif4bcfv2CTpS4VFAiIrVkyxZ/bqd166BXL7jnnqAT\nJTYVlIhILXDOn2zwww+hUyeYOhXS0oJOldhUUCIitWD0aJg0CZo08YMiWrYMOlHiU0GJiNTQvHkw\ndKi/PmECHHRQoHGShgpKRKQGVq6Ec8+F4mK45Rbo2zfoRMlDBSUiUk35+X5QxPr1cPLJcMcdQSdK\nLlEVlJlNMrPvzWyjmS0zs8viHUxEJMycg0svhY8/hn33hcmTNSiitkW7BnUv0Mk51xw4HbjTzHQ8\nXhFJWaNGwbPPQtOmflBEixZBJ0o+URWUc+5T51z+9puRy95xSyUiEmL//jfcdJO//swz0KVLsHmS\nVdSHLjSzx4CLgHTgI+CVcqYZBAwCaNu2LdnZ2bUSsrbl5eWFNlvYadnFLicnh+LiYi23agjj623N\nmsYMGdKDkpIGXHjhKlq0WEXIIgLhXHaxMudc9BObpQFHAlnAfc65bRVNm5mZ6RYuXFjjgPGQnZ1N\nVlZW0DESkpZd7LKyssjJyWHx4sVBR0k4YXu95eXBkUfCp5/C6afDzJlQL6RDzcK27Eozs0XOucyq\npotp0Trnip1zC4D2wOXVDScikmicg4su8uW0//5+015YyylZVHfx1kf7oEQkhdxzD7zwAjRv7gdF\nNG8edKLkV2VBmVkbM+tnZk3NLM3M/gD0B+bFP56ISPBefhmGDQMzmDIFOncOOlFqiGaQhMNvzhuD\nL7SvgGuccy/GM5iISBgsWwYDBvhNfCNHwimnBJ0odVRZUM65dcAxdZBFRCRUNm6E3r0hNxfOOssf\nykjqjnbxiYiUo6QE/vhH+OIL6NrVHwRWgyLqlha3iEg5Ro6E2bP9ESJmzYJmzYJOlHpUUCIiZbz4\nItx+ux8UMXUq7LNP0IlSkwpKRKSUL76A88/31++5B048Mdg8qUwFJSISkZMDZ5wBmzbBOefAjTcG\nnSi1qaBERPCDIs4/H5Yvh9/8Bp580m/ik+CooEREgOHD/RdyW7b0gyKaNAk6kaigRCTlvfAC3Hmn\nH0Y+bRrstVfQiQRUUCKS4j79FC680F+//3444YRg88gvVFAikrI2bPBHiti82R/O6Nprg04kpamg\nRCQlFRdD//6wYgV06wbjxmlQRNiooEQkJd16qz91e6tW/sSDGRlBJ5KyVFAiknKmTYP77oO0NHj+\neejQIehEUh4VlIiklI8/hosv9tcffBBCelZ0QQUlIilk/Xo/KGLLFj9y78org04klVFBiUhKKCqC\nc8+FVavg0ENhzBgNigg7FZSIpIS//AXmzYM2bWDGDGjcOOhEUhUVlIgkvUmT4O9/h/r1/VEj2rcP\nOpFEQwUlIkntww9h4EB//aGH4Le/DTaPRE8FJSJJ64cf/KCIggK47DIYMiToRBILFZSIJKVt2/w5\nnb75Bo44Ah55RIMiEo0KSkSS0vXXwxtvwO67+/1OjRoFnUhipYISkaQzYQI8/DA0aODLaY89gk4k\n1aGCEpGk8p///LKv6bHH4Mgjg80j1aeCEpGk8f33cNZZUFgIl1/uB0ZI4lJBiUhS2LoV+vaFNWv8\nUPJ//CPoRFJTKigRSQrXXANvvw3t2sH06dCwYdCJpKZUUCKS8J54Ah5/3I/UmzkT2rYNOpHUBhWU\niCS0d96BP/3JXx8zxh8IVpKDCkpEEta330KfPv5LuVdfDRddFHQiqU0qKBFJSIWFvpy+/x6OOQZG\njQo6kdQ2FZSIJBzn/Ga9996DX//an7a9QYOgU0ltU0GJSMIZMwbGj/fndJo5E1q3DjqRxIMKSkQS\nyltv+f1NAP/8J3TvHmweiR8VlIgkjNWr/Zdxi4rguutgwICgE0k8qaBEJCEUFMCZZ/pzPB1/PNx3\nX9CJJN5UUCISes75A8AuXAgdO8K0af707ZLcVFAiEnoPPwxPPw0ZGTBrFuy2W9CJpC6ooEQk1LKz\n/f4mgKeegoMPDjSO1KEqC8rMGpnZeDP7ysw2mdliMzupLsKJSGr7/vtGnH02FBfDX/7iT+EuqSOa\nNaj6wDfAMcAuwDDgOTPrGL9YIpLq8vPhttsO5Mcf4Q9/gLvuCjqR1LUqdzM65zYDt5f60RwzWwn0\nAFbFJ5aIpDLnYOBAWL68GXvvDVOnQlpa0KmkrsU8DsbM2gL7AZ+Vc98gYBBA27Ztyc7Ormm+uMjL\nywtttrDTsotdTk4OxcXFWm4xeO659kyZsg+NGxdx660f8fHHm4OOlHCS4W/VnHPRT2zWAJgLrHDO\nDa5s2szMTLdw4cIaxouP7OxssrKygo6RkLTsYpeVlUVOTg6LFy8OOkpCeO01v0mvpARGjPiU2247\nMOhICSnMf6tmtsg5l1nVdFGP4jOzesAzwFbgyhpkExEp1//+B+ee68tp2DDo2fPHoCNJgKIqKDMz\nYDzQFujjnNsW11QiknI2b4beveGnn+DUU2HEiKATSdCi3Qf1OHAAcIJzbksc84hICnIOLrkEliyB\n/faDSZOgnr6lmfKi+R5UB2AwcAjwvZnlRS46TKOI1Iq//Q2eew6aNfNHithll6ATSRhEM8z8K8Dq\nIIuIpKB//QtuvtlfnzQJDjgg2DwSHlqJFpHA/Pe/0L+/38Q3YgScfnrQiSRMVFAiEohNm/ygiJwc\n/++wYUEnkrBRQYlInSspgQsvhM8+85v0nn5agyJkZ3pJiEidu/tumDnTD4aYNQuaNw86kYSRCkpE\n6tScOXDbbWAGU6b4YeUi5dE5KUWkzixdCgMG+EERd90FJ58cdCIJM61BiUidyM2FM86AjRuhb99f\nhpaLVEQFJSJxV1ICF1zg16AOPNCfGdf07UqpggpKROJuxAh46SXYdVc/KKJp06ATSSJQQYlIXM2a\nBXfc4YeRP/ss7L130IkkUaigRCRuPv/cb9oDuPde6NUr2DySWFRQIhIXOTl+UEReHvTrB0OHBp1I\nEo0KSkRqXXExnHeeP9beIYfA+PEaFCGxU0GJSK277TaYOxd2280fMSIjI+hEkohUUCJSq55/3h/K\nKC0Npk2Djh2DTiSJSgUlIrXmk0/goov89VGj4PjjA40jCU4FJSK14qef/Gkz8vP9yL0//znoRJLo\nVFAiUmNFRX6k3sqV0KMHjB2rQRFScyooEamxW26BV1+F1q1hxgxITw86kSQDFZSI1MjUqXD//VC/\nPkyfDr/+ddCJJFmooESk2hYvhksv9df/8Q/o2TPYPJJcVFAiUi0//ugHRWzZAhdfDFdcEXQiSTYq\nKBGJWVERnHMOfPUVHHYYPPaYBkVI7VNBiUjMbrgB5s+Htm39oIjGjYNOJMlIBSUiMXnmGb+/qUED\neOEFaNcu6ESSrFRQIhK1hQth4EB//eGH4eijg80jyU0FJSJRWbsWzjwTCgth0CAYPDjoRJLsVFAi\nUqVt2+Dss2H1ajjqKHjooaATSSpQQYlIla69Ft56C/bYw38Zt1GjoBNJKlBBiUilnnwSHn0UGjb0\nI/Z23z3oRJIqVFAiUqH334fLL/fXH38cDj882DySWlRQIlKu776Ds86CrVvhT3+CSy4JOpGkGhWU\niOxk61bo2xe+/dYfX+/BB4NOJKlIBSUiO7n6anjnHWjf3p/CvUGDoBNJKlJBicgOxo71l0aNYOZM\naNMm6ESSqlRQIvKzt9+Gq67y18eNg8zMYPNIalNBiQgAa9ZAnz7+S7nXXAN//GPQiSTVqaBEhIIC\nP2Jv7Vo49lh/hlyRoEVVUGZ2pZktNLNCM5sQ50wiUoec88PI//Mf6NABpk3zp28XCVq0L8NvgTuB\nPwDp8YsjInXtscf80SLS0/2giNatg04k4kVVUM65GQBmlgm0j2siEakzb77p9zcBjB8P3boFm0ek\nNO2DEklR33zjv4xbVARDh0L//kEnEtlRrW5pNrNBwCCAtm3bkp2dXZsPX2vy8vJCmy3stOxil5OT\nQ3FxcaiWW2FhPa6+uhvr1jUjM/MnTjxxCdnZLuhYO9HrrfqSYdnVakE558YB4wAyMzNdVlZWbT58\nrcnOzias2cJOyy52LVq0ICcnJzTLzTk/hHzZMujUCf7975a0bHlM0LHKpddb9SXDstMmPpEUM3o0\nTJoEGRkwaxa0bBl0IpHyRbUGZWb1I9OmAWlm1hgocs4VxTOciNSu11/3+5sAJkyAgw4KNI5IpaJd\ngxoGbAFuAs6PXB8Wr1AiUvtWrYJzzoHiYrj5Zn8Kd5Ewi3aY+e3A7XFNIiJxk58PvXvD+vVw0kkw\ncmTQiUSqpn1QIknOObj0Uvj4Y9h3X5gyBdLSgk4lUjUVlEiSe+ABePZZaNrUD4po0SLoRCLRUUGJ\nJLH/+z/4y1/89YkToUuXYPOIxEIFJZKkVqyAfv2gpARuuw3OPDPoRCKxUUGJJKG8PD8oYsMGOO00\nGD486EQisVNBiSQZ5+Dii+HTT6FzZ/+l3Hr6S5cEpJetSJK5916YPh2aN4fZs/2/IolIBSWSRF55\nBW69Fcxg8mS/BiWSqFRQdSArK4srr7wy6BiS5JYvh/PO85v47rgDTj016EQiNaOCAi666CJO1V+z\nJLBNm+CMMyA314/Wu+WWoBOJ1JwKSiTBlZT402d88YX/ntPTT2tQhCQHvYyrkJuby6BBg2jTpg3N\nmjXjmGOOYeHChT/fv379evr370/79u1JT0+na9euPPXUU5U+5rx582jRogVjxoyJd3xJAXfe+csR\nImbPhmbNgk4kUjtUUJVwznHKKaewZs0a5syZw0cffUTPnj057rjj+O677wAoKCige/fuzJkzh88+\n+4w///nPDB48mHnz5pX7mNOnT+fMM89k3LhxDBkypC6fjiShF1/033Eyg6lTYZ99gk4kUntq9Yy6\nyWb+/PksXryYdevWkZ6eDsDIkSN56aWXeOaZZ7jxxhtp164dN9xww8+/M2jQIF5//XWmTp3K8ccf\nv8PjjRs3jhtuuIHp06fTq1evOn0ukny+/BLOP99fv/tuOPHEYPOI1DYVVCUWLVpEfn4+rVu33uHn\nBQUFrFixAoDi4mLuvfdepk2bxpo1aygsLGTr1q07nWp51qxZjB07ljfffJMjjzyyrp6CJKncXD8o\nYtMmf16n7cfbE0kmKqhKlJSU0LZtW956662d7mse+fbjqFGjeOCBBxg9ejQHHXQQTZs25ZZbbuGH\nH37YYfqDDz6YJUuWMH78eI444gjMrE6egySfkhIYMACWLfNnxH3qKb+JTyTZqKAq0b17d9auXUu9\nevXo1KlTudMsWLCA0047jQsuuADw+62WLVtGizLnNNhrr714+OGHycrKYtCgQYwbN04lJdUyfDi8\n/DK0bOkHRzRpEnQikfjQIImIjRs3snjx4h0u++yzD0cffTRnnHEGc+fOZeXKlbz77rsMHz7857Wq\n/fbbj3nz5rFgwQK+/PJLrrzySlauXFnuPDp16sT8+fP517/+xeDBg3HO1eVTlCQwY4YftVevHkyb\nBhV8bhJJCiqoiLfeeotu3brtcLnhhht45ZVXOO644xg4cCCdO3fmnHPOYenSpeyxxx4ADBs2jMMO\nO4yTTjqJnj170qRJEwYMGFDhfPbee2+ys7OZO3euSkpi8umn/vtOAH/7G5xwQrB5ROJNm/iACRMm\nMGHChArvHz16NKNHjy73vl133ZUZM2ZU+vjZ2dk73N5777355ptvYo0pKWzDBn/6jM2b/eGMrrsu\n6EQi8ac1KJGQKy6G/v39CQi7dYMnntCgCEkNKiiRkBs2DP79b2jVCmbOhIyMoBOJ1A0VlEiIPfec\nP79TWpq/3qFD0IlE6k5SF1RRURFjx45l/fr1QUcRidnHH/sz4wL8/e9w7LHB5hGpa0lbUN988w2H\nHXYYV111FWeffbZGy0lCWb/eD4rIz4cLL4Srrgo6kUjdS8qCmj17Nl27duWTTz5h27ZtvP/++4wa\nNSroWCJRKSqCfv1g1SrIzIQxYzQoQlJTUhVUYWEhQ4YM4bzzzmPTpk0UFxcDkJ+fz/Dhw3c4TYZI\nWN10E7zSKEGuAAAKYklEQVT2GrRp47+Y27hx0IlEgpE0BbV8+XIOPvhgJk6cSH5+/k73O+dYvnx5\nAMlEojd5MjzwANSvD9Onw557Bp1IJDhJ8UXdSZMmMWTIEPLz83fa19SgQQOaN2/OzJkz+d3vfhdQ\nQpGqffghXHaZv/7QQ6CXq6S6hC6ozZs3M3DgQGbPnl3uWlNGRgaHH344zz//PLvttlsACUWis24d\nnHkmFBTApZeCzmUpksCb+JYsWUKXLl2YOXNmueWUnp7OiBEjmDdvnspJQm3bNjjnHPj6azjiCHj0\nUQ2KEIEEXINyzvH4448zdOhQtmzZstP9jRo1omXLlrz44otkZmYGkFAkNkOHQnY2/OpX8MIL0KhR\n0IlEwiGhCionJ4fzzz+f+fPnl1tOGRkZ/P73v2fixIk/n1BQJMwmTPD7mxo08CP2IgfJFxESqKDe\nf/99Tj/9dHJzcyksLNzp/oyMDB588EEGDhyoEwFKQvjgg1/2NT36KBx5ZLB5RMIm9AVVUlLCvffe\ny5133lnuWlPjxo3ZfffdmTNnDl26dAkgoUjs1q71gyIKC31JDRwYdCKR8Al1Qf3www/07duXRYsW\nVbhJr0+fPowdO5b09PQAEorEbutW6NsX1qyBo4+GCk41JpLyAh3Ft379ej788MNy73v99dfZf//9\nee+993YapVevXj2aNGnC+PHjmThxospJEso118CCBdCunf8ybsOGQScSCadAC+qKK67g6KOPZsWK\nFT//rKioiJtuuolTTz2VDRs2sG3bth1+JyMjg/33359PPvmEfv361XVkkRr55z/h8cf9SL0ZM/zI\nPREpX2AFtWzZMl588UW2bt3KaaedxtatW1m9ejWHH344Dz/8cLmb9NLT07n00kv56KOP6NSpUwCp\nRarv3XfhT3/y1x9/HA47LNg8ImEX1T4oM2sJjAd6AT8CNzvnptRkxjfddBPbtm2jpKSEVatW0bt3\nbxYsWEB+fv7PB3n9OWT9+mRkZDBlyhROOeWUmsxWJBDbttWjTx+//+mqq345z5OIVCzaQRKPAluB\ntsAhwMtm9rFz7rPqzPTzzz9n7ty5PxfRli1beP311yscPt61a1dmzpxJu3btqjM7kUAVFMDKlU3Y\nsgWOOcYfDFZEqmZVncjPzJoAG4ADnXPLIj+bCHzrnLupot9r1qyZ69GjR7n3LVmyhJ9++qnKcPXq\n1aN9+/Z07NixVr/blJOTQ4sWLWrt8VKJlt2OnPPnb6rosnUrrF69GIBGjQ6hRw//pVyJjl5v1Rfm\nZffGG28scs5VeaifaNag9gOKtpdTxMdAVtkJzWwQMAj8UcRzcnJ2erAtW7awYcOGKmealpZGx44d\nadq0Kbm5uVHEjF5xcXG52aRqybbsnIPiYqv2xbnoPjilpZWwzz65bN6sMzvHItleb3UpGZZdNAXV\nFNhY5mcbgWZlJ3TOjQPGAWRmZrryThDYq1evKs/L1KFDBxYuXEirVq2iiBe77OxssrKy4vLYyS5s\ny66wEHJyKr/k5lZ8XzljcWKSlga77AItWlR8mT49C7McFi/+qHaedAoJ2+stkYR52UW7RSyagsoD\nyh7YbhdgU4yZWLRoEQsWLNjpnE1l/fDDDyxZsoRjjz021llIgikoqLpgKiubgoKazT8tDXbd1RdJ\nVUVT3qVJk6qPPD5vns8qIrGJpqCWAfXNbF/n3PZVn4OBmAdIXH/99RRE8Y6yZcsW+vTpw9KlS2nd\nunWss5E64lzsBVO2aMoZFxOT+vV/KZjSl2jLJiNDp7YQCasqC8o5t9nMZgB3mNllQDfgdOCoWGb0\n3nvv8cEHH1S59rTdpk2buPbaa5k0aVIss5EYOAf5+dFtCtt++eab7hQX/3K7zPeoY9agQfkFE23Z\npKerYESSVbTDzK8AngR+ANYDl8c6xPy6664r98SCjRo1olGjRhQWFtKwYUP2228/Dj30UHr06KFN\nfFVwDjZvjm2fS9lLUVGsc91xa2/DhlUXTGVF07ixCkZEyhdVQTnnfgJ6V3cm77zzDu+++y7NmjWj\nuLiY4uJiOnXqRPfu3Tn00EP5zW9+Q9euXWnTpk11Z5GQnIO8vOrv4M/JgTLfaY5Z48ax7XNZsWIR\nxx/f4+eyady4dpaFiEhZdXI089122427776bgw46iAMPPJAOHTokxTmbSkqqLpiqiqakpGYZMjJi\n3+9SevpYz96anb2Jzp1rlllEJBp1UlCdO3fm5ptvrotZxaSkBDZtqv4O/tzcmhdMkyax73cpPY2O\nhC0iySrU54OqSnExbNwY+36X778/goIC/7tRjtmoUNOm1dv3sv3nOqqAiEj5Ai2o4uKdiyWWotlY\n9uvDUftlx0mzZrFtEit7u35CV7yISHjF7e117Vq47bbKC2ZTzF/13dkuu8S+7+XLL9/jD384gubN\nVTAiImEVt7fn1ath5MjKpzHbsVxiLZpmzfyRAGKVm1tAy5bVe14iIlI34lZQbdrAFVdUXTD1Aj2n\nr4iIhFXcCmrPPWH48Hg9uoiIJDutv4iISCipoEREJJRUUCIiEkoqKBERCSUVlIiIhJIKSkREQkkF\nJSIioaSCEhGRUFJBiYhIKKmgREQklMzV9IRIFT2w2Trgq7g8eM21An4MOkSC0rKrHi236tFyq74w\nL7sOzrnWVU0Ut4IKMzNb6JzLDDpHItKyqx4tt+rRcqu+ZFh22sQnIiKhpIISEZFQStWCGhd0gASm\nZVc9Wm7Vo+VWfQm/7FJyH5SIiIRfqq5BiYhIyKmgREQklFRQIiISSilfUGa2r5kVmNmkoLMkAjNr\nZGbjzewrM9tkZovN7KSgc4WVmbU0s5lmtjmyzM4LOlPY6TVWO5LhvS3lCwp4FPgg6BAJpD7wDXAM\nsAswDHjOzDoGmCnMHgW2Am2BAcDjZtY12Eihp9dY7Uj497aULigz6wfkAPOCzpIonHObnXO3O+dW\nOedKnHNzgJVAj6CzhY2ZNQH6AH91zuU55xYAs4ELgk0WbnqN1VyyvLelbEGZWXPgDuC6oLMkMjNr\nC+wHfBZ0lhDaDyhyzi0r9bOPAa1BxUCvsdgk03tbyhYUMBIY75xbHXSQRGVmDYDJwNPOuS+DzhNC\nTYGNZX62EWgWQJaEpNdYtSTNe1tSFpSZZZuZq+CywMwOAU4AHgw6a9hUtexKTVcPeAa/f+XKwAKH\nWx7QvMzPdgE2BZAl4eg1Frtke2+rH3SAeHDOZVV2v5ldA3QEvjYz8J9008ysi3Oue9wDhlhVyw7A\n/EIbj9/xf7Jzblu8cyWoZUB9M9vXObc88rOD0aaqKuk1Vm1ZJNF7W0oe6sjMMtjxk+1Q/H/q5c65\ndYGESiBmNgY4BDjBOZcXdJ4wM7NnAQdcBnQDXgaOcs6ppCqh11j1JNt7W1KuQVXFOZcP5G+/bWZ5\nQEEi/gfWNTPrAAwGCoHvI5/SAAY75yYHFiy8rgCeBH4A1uPfKFROldBrrPqS7b0tJdegREQk/JJy\nkISIiCQ+FZSIiISSCkpEREJJBSUiIqGkghIRkVBSQYmISCipoEREJJRUUCIiEkr/D+DDxw30dHP2\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181b0dc390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, leaky_relu(z, 0.05), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([0, 0], [-0.5, 4.2], 'k-')\n",
    "plt.grid(True)\n",
    "props = dict(facecolor='black', shrink=0.1)\n",
    "plt.annotate('Leak', xytext=(-3.5, 0.5), xy=(-5, -0.2), arrowprops=props, fontsize=14, ha=\"center\")\n",
    "plt.title(\"Leaky ReLU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -0.5, 4.2])\n",
    "\n",
    "save_fig(\"leaky_relu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing Leaky ReLU in TensorFlow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leaky_relu(z, name=None):\n",
    "    return tf.maximum(0.01 * z, z, name=name)\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a neural network on MNIST using the Leaky ReLU. First let's create the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=leaky_relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=leaky_relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.86 Validation accuracy: 0.9044\n",
      "5 Batch accuracy: 0.94 Validation accuracy: 0.951\n",
      "10 Batch accuracy: 0.96 Validation accuracy: 0.9666\n",
      "15 Batch accuracy: 1.0 Validation accuracy: 0.9722\n",
      "20 Batch accuracy: 1.0 Validation accuracy: 0.9748\n",
      "25 Batch accuracy: 1.0 Validation accuracy: 0.9768\n",
      "30 Batch accuracy: 0.98 Validation accuracy: 0.9778\n",
      "35 Batch accuracy: 0.96 Validation accuracy: 0.9796\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 40\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 5 == 0:\n",
    "            acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            acc_test = accuracy.eval(feed_dict={X: mnist.validation.images, y: mnist.validation.labels})\n",
    "            print(epoch, \"Batch accuracy:\", acc_train, \"Validation accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) takes on negative values when z<0 , allows the unit to have output close but no equal to zero, in order to alleviate the vanishing gradients problem \n",
    "(2) nonzero gradient , avoids dying units issue \n",
    "(3) smooth everywehere include z =0 , so we can speed up the gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def elu(z, alpha=1):\n",
    "    return np.where(z < 0, alpha * (np.exp(z) - 1), z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure elu_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1dc48f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, elu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1, -1], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"ELU activation function ($\\alpha=1$)\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "save_fig(\"elu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing ELU in TensorFlow is trivial, just specify the activation function when building each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.elu, name=\"hidden1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SELU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This activation function was proposed in this [great paper](https://arxiv.org/pdf/1706.02515.pdf) by GÃ¼nter Klambauer, Thomas Unterthiner and Andreas Mayr, published in June 2017 (I will definitely add it to the book). It outperforms the other activation functions very significantly for deep neural networks, so you should really try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def selu(z,\n",
    "         scale=1.0507009873554804934193349852946,\n",
    "         alpha=1.6732632423543772848170429916717):\n",
    "    return scale * elu(z, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving figure selu_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB6tXMCVB9+rVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x181afd9b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(z, selu(z), \"b-\", linewidth=2)\n",
    "plt.plot([-5, 5], [0, 0], 'k-')\n",
    "plt.plot([-5, 5], [-1.758, -1.758], 'k--')\n",
    "plt.plot([0, 0], [-2.2, 3.2], 'k-')\n",
    "plt.grid(True)\n",
    "plt.title(r\"SELU activation function\", fontsize=14)\n",
    "plt.axis([-5, 5, -2.2, 3.2])\n",
    "\n",
    "save_fig(\"selu_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this activation function, even a 100 layer deep neural network preserves roughly mean 0 and standard deviation 1 across all layers, avoiding the exploding/vanishing gradients problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: -0.26 < mean < 0.27, 0.74 < std deviation < 1.27\n",
      "Layer 10: -0.24 < mean < 0.27, 0.74 < std deviation < 1.27\n",
      "Layer 20: -0.17 < mean < 0.18, 0.74 < std deviation < 1.24\n",
      "Layer 30: -0.27 < mean < 0.24, 0.78 < std deviation < 1.20\n",
      "Layer 40: -0.38 < mean < 0.39, 0.74 < std deviation < 1.25\n",
      "Layer 50: -0.27 < mean < 0.31, 0.73 < std deviation < 1.27\n",
      "Layer 60: -0.26 < mean < 0.43, 0.74 < std deviation < 1.35\n",
      "Layer 70: -0.19 < mean < 0.21, 0.75 < std deviation < 1.21\n",
      "Layer 80: -0.18 < mean < 0.16, 0.72 < std deviation < 1.19\n",
      "Layer 90: -0.19 < mean < 0.16, 0.75 < std deviation < 1.20\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "Z = np.random.normal(size=(500, 100))\n",
    "for layer in range(100):\n",
    "    W = np.random.normal(size=(100, 100), scale=np.sqrt(1/100))\n",
    "    Z = selu(np.dot(Z, W))\n",
    "    means = np.mean(Z, axis=1)\n",
    "    stds = np.std(Z, axis=1)\n",
    "    if layer % 10 == 0:\n",
    "        print(\"Layer {}: {:.2f} < mean < {:.2f}, {:.2f} < std deviation < {:.2f}\".format(\n",
    "            layer, means.min(), means.max(), stds.min(), stds.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a TensorFlow implementation (there will almost certainly be a `tf.nn.selu()` function in future TensorFlow versions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def selu(z,\n",
    "         scale=1.0507009873554804934193349852946,\n",
    "         alpha=1.6732632423543772848170429916717):\n",
    "    return scale * tf.where(z >= 0.0, z, alpha * tf.nn.elu(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELUs can also be combined with dropout, check out [this implementation](https://github.com/bioinf-jku/SNNs/blob/master/selu.py) by the Institute of Bioinformatics, Johannes Kepler University Linz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a neural net for MNIST using the SELU activation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=selu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=selu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "n_epochs = 40\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train it. Do not forget to scale the inputs to mean 0 and standard deviation 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Batch accuracy: 0.96 Validation accuracy: 0.924\n",
      "5 Batch accuracy: 1.0 Validation accuracy: 0.957\n",
      "10 Batch accuracy: 0.94 Validation accuracy: 0.967\n",
      "15 Batch accuracy: 0.98 Validation accuracy: 0.9682\n",
      "20 Batch accuracy: 1.0 Validation accuracy: 0.9708\n",
      "25 Batch accuracy: 1.0 Validation accuracy: 0.969\n",
      "30 Batch accuracy: 1.0 Validation accuracy: 0.9698\n",
      "35 Batch accuracy: 1.0 Validation accuracy: 0.9708\n"
     ]
    }
   ],
   "source": [
    "means = mnist.train.images.mean(axis=0, keepdims=True)\n",
    "stds = mnist.train.images.std(axis=0, keepdims=True) + 1e-10\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            X_batch_scaled = (X_batch - means) / stds\n",
    "            sess.run(training_op, feed_dict={X: X_batch_scaled, y: y_batch})\n",
    "        if epoch % 5 == 0:\n",
    "            acc_train = accuracy.eval(feed_dict={X: X_batch_scaled, y: y_batch})\n",
    "            X_val_scaled = (mnist.validation.images - means) / stds\n",
    "            acc_test = accuracy.eval(feed_dict={X: X_val_scaled, y: mnist.validation.labels})\n",
    "            print(epoch, \"Batch accuracy:\", acc_train, \"Validation accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final_selu.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization\n",
    "\n",
    "address the vanishing/exploding gradients problems and more generally problem that distribution of each layer's inputs changes \n",
    "\n",
    "before activation : simply zero-centering and normalizing the inputs , and then scaling and shifting the result using two new parameter per layer 1 : scaling 2 shifting ie : lets model learn the optimal scale and the mean of inputs for each layers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the book uses `tensorflow.contrib.layers.batch_norm()` rather than `tf.layers.batch_normalization()` (which did not exist when this chapter was written). It is now preferable to use `tf.layers.batch_normalization()`, because anything in the contrib module may change or be deleted without notice. Instead of using the `batch_norm()` function as a regularizer parameter to the `fully_connected()` function, we now use `batch_normalization()` and we explicitly create a distinct layer. The parameters are a bit different, in particular:\n",
    "* `decay` is renamed to `momentum`,\n",
    "* `is_training` is renamed to `training`,\n",
    "* `updates_collections` is removed: the update operations needed by batch normalization are added to the `UPDATE_OPS` collection and you need to explicity run these operations during training (see the execution phase below),\n",
    "* we don't need to specify `scale=True`, as that is the default.\n",
    "\n",
    "Also note that in order to run batch norm just _before_ each hidden layer's activation function, we apply the ELU activation function manually, right after the batch norm layer.\n",
    "\n",
    "Note: since the `tf.layers.dense()` function is incompatible with `tf.contrib.layers.arg_scope()` (which is used in the book), we now use python's `functools.partial()` function instead. It makes it easy to create a `my_dense_layer()` function that just calls `tf.layers.dense()` with the desired parameters automatically set (unless they are overridden when calling `my_dense_layer()`). As you can see, the code remains very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
    "bn1 = tf.layers.batch_normalization(hidden1, training=training, momentum=0.9)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "bn2 = tf.layers.batch_normalization(hidden2, training=training, momentum=0.9)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = tf.layers.batch_normalization(logits_before_bn, training=training,\n",
    "                                       momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid repeating the same parameters over and over again, we can use Python's `partial()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "my_batch_norm_layer = partial(tf.layers.batch_normalization,\n",
    "                              training=training, momentum=0.9)\n",
    "# avoid repeating the same parameter again and again \n",
    "hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
    "#bn1 = tf.layers.batch_normalization(hidden1, training=training, momentum=0.9)\n",
    "bn1 = my_batch_norm_layer(hidden1)\n",
    "bn1_act = tf.nn.elu(bn1)\n",
    "hidden2 = tf.layers.dense(bn1_act, n_hidden2, name=\"hidden2\")\n",
    "bn2 = my_batch_norm_layer(hidden2)\n",
    "bn2_act = tf.nn.elu(bn2)\n",
    "logits_before_bn = tf.layers.dense(bn2_act, n_outputs, name=\"outputs\")\n",
    "logits = my_batch_norm_layer(logits_before_bn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a neural net for MNIST, using the ELU activation function and Batch Normalization at each layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "batch_norm_momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "    my_batch_norm_layer = partial(\n",
    "            tf.layers.batch_normalization,\n",
    "            training=training,\n",
    "            momentum=batch_norm_momentum)\n",
    "\n",
    "    my_dense_layer = partial(\n",
    "            tf.layers.dense,\n",
    "            kernel_initializer=he_init)\n",
    "\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    bn1 = tf.nn.elu(my_batch_norm_layer(hidden1))\n",
    "    hidden2 = my_dense_layer(bn1, n_hidden2, name=\"hidden2\")\n",
    "    bn2 = tf.nn.elu(my_batch_norm_layer(hidden2))\n",
    "    logits_before_bn = my_dense_layer(bn2, n_outputs, name=\"outputs\")\n",
    "    logits = my_batch_norm_layer(logits_before_bn)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: since we are using `tf.layers.batch_normalization()` rather than `tf.contrib.layers.batch_norm()` (as in the book), we need to explicitly run the extra update operations needed by batch normalization (`sess.run([training_op, extra_update_ops],...`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Test accuracy: 0.8652\n",
      "1 Test accuracy: 0.8961\n",
      "2 Test accuracy: 0.9122\n",
      "3 Test accuracy: 0.9222\n",
      "4 Test accuracy: 0.929\n",
      "5 Test accuracy: 0.9351\n",
      "6 Test accuracy: 0.9379\n",
      "7 Test accuracy: 0.9435\n",
      "8 Test accuracy: 0.9451\n",
      "9 Test accuracy: 0.9485\n",
      "10 Test accuracy: 0.951\n",
      "11 Test accuracy: 0.9532\n",
      "12 Test accuracy: 0.9555\n",
      "13 Test accuracy: 0.9576\n",
      "14 Test accuracy: 0.9597\n",
      "15 Test accuracy: 0.9609\n",
      "16 Test accuracy: 0.9615\n",
      "17 Test accuracy: 0.9634\n",
      "18 Test accuracy: 0.9641\n",
      "19 Test accuracy: 0.965\n"
     ]
    }
   ],
   "source": [
    "extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run([training_op, extra_update_ops],\n",
    "                     feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: mnist.test.images,\n",
    "                                                y: mnist.test.labels})\n",
    "        print(epoch, \"Test accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What!? That's not a great accuracy for MNIST. Of course, if you train for longer it will get much better accuracy, but with such a shallow network, Batch Norm and ELU are unlikely to have very positive impact: they shine mostly for much deeper nets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you could also make the training operation depend on the update operations:\n",
    "\n",
    "```python\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(extra_update_ops):\n",
    "        training_op = optimizer.minimize(loss)\n",
    "```\n",
    "\n",
    "This way, you would just have to evaluate the `training_op` during training, TensorFlow would automatically run the update operations as well:\n",
    "\n",
    "```python\n",
    "sess.run(training_op, feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more thing: notice that the list of trainable variables is shorter than the list of all global variables. This is because the moving averages are non-trainable variables. If you want to reuse a pretrained neural network (see below), you must not forget these non-trainable variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'hidden1/kernel:0',\n",
       " u'hidden1/bias:0',\n",
       " u'batch_normalization/gamma:0',\n",
       " u'batch_normalization/beta:0',\n",
       " u'hidden2/kernel:0',\n",
       " u'hidden2/bias:0',\n",
       " u'batch_normalization_1/gamma:0',\n",
       " u'batch_normalization_1/beta:0',\n",
       " u'outputs/kernel:0',\n",
       " u'outputs/bias:0',\n",
       " u'batch_normalization_2/gamma:0',\n",
       " u'batch_normalization_2/beta:0']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in tf.trainable_variables()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'hidden1/kernel:0',\n",
       " u'hidden1/bias:0',\n",
       " u'batch_normalization/gamma:0',\n",
       " u'batch_normalization/beta:0',\n",
       " u'batch_normalization/moving_mean:0',\n",
       " u'batch_normalization/moving_variance:0',\n",
       " u'hidden2/kernel:0',\n",
       " u'hidden2/bias:0',\n",
       " u'batch_normalization_1/gamma:0',\n",
       " u'batch_normalization_1/beta:0',\n",
       " u'batch_normalization_1/moving_mean:0',\n",
       " u'batch_normalization_1/moving_variance:0',\n",
       " u'outputs/kernel:0',\n",
       " u'outputs/bias:0',\n",
       " u'batch_normalization_2/gamma:0',\n",
       " u'batch_normalization_2/beta:0',\n",
       " u'batch_normalization_2/moving_mean:0',\n",
       " u'batch_normalization_2/moving_variance:0']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in tf.global_variables()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Clipping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a simple neural net for MNIST and add gradient clipping. The first part is the same as earlier (except we added a few more layers to demonstrate reusing pretrained models, see below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_hidden3 = 50\n",
    "n_hidden4 = 50\n",
    "n_hidden5 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\")\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.relu, name=\"hidden5\")\n",
    "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply gradient clipping. For this, we need to get the gradients, use the `clip_by_value()` function to clip them, then apply them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold = 1.0\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -threshold, threshold), var)\n",
    "              for grad, var in grads_and_vars]\n",
    "training_op = optimizer.apply_gradients(capped_gvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest is the same as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Test accuracy: 0.3138\n",
      "1 Test accuracy: 0.8003\n",
      "2 Test accuracy: 0.8805\n",
      "3 Test accuracy: 0.9037\n",
      "4 Test accuracy: 0.9122\n",
      "5 Test accuracy: 0.9196\n",
      "6 Test accuracy: 0.9241\n",
      "7 Test accuracy: 0.9299\n",
      "8 Test accuracy: 0.9329\n",
      "9 Test accuracy: 0.9388\n",
      "10 Test accuracy: 0.9432\n",
      "11 Test accuracy: 0.9451\n",
      "12 Test accuracy: 0.9454\n",
      "13 Test accuracy: 0.9483\n",
      "14 Test accuracy: 0.9525\n",
      "15 Test accuracy: 0.9513\n",
      "16 Test accuracy: 0.9565\n",
      "17 Test accuracy: 0.9583\n",
      "18 Test accuracy: 0.9561\n",
      "19 Test accuracy: 0.9605\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: mnist.test.images,\n",
    "                                                y: mnist.test.labels})\n",
    "        print(epoch, \"Test accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing Pretrained Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing a TensorFlow Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First you need to load the graph's structure. The `import_meta_graph()` function does just that, loading the graph's operations into the default graph, and returning a `Saver` that you can then use to restore the model's state. Note that by default, a `Saver` saves the structure of the graph into a `.meta` file, so that's the file you should load:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.import_meta_graph(\"./my_model_final.ckpt.meta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you need to get a handle on all the operations you will need for training. If you don't know the graph's structure, you can list all the operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "y\n",
      "hidden1/kernel/Initializer/random_uniform/shape\n",
      "hidden1/kernel/Initializer/random_uniform/min\n",
      "hidden1/kernel/Initializer/random_uniform/max\n",
      "hidden1/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden1/kernel/Initializer/random_uniform/sub\n",
      "hidden1/kernel/Initializer/random_uniform/mul\n",
      "hidden1/kernel/Initializer/random_uniform\n",
      "hidden1/kernel\n",
      "hidden1/kernel/Assign\n",
      "hidden1/kernel/read\n",
      "hidden1/bias/Initializer/zeros\n",
      "hidden1/bias\n",
      "hidden1/bias/Assign\n",
      "hidden1/bias/read\n",
      "dnn/hidden1/MatMul\n",
      "dnn/hidden1/BiasAdd\n",
      "dnn/hidden1/Relu\n",
      "hidden2/kernel/Initializer/random_uniform/shape\n",
      "hidden2/kernel/Initializer/random_uniform/min\n",
      "hidden2/kernel/Initializer/random_uniform/max\n",
      "hidden2/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden2/kernel/Initializer/random_uniform/sub\n",
      "hidden2/kernel/Initializer/random_uniform/mul\n",
      "hidden2/kernel/Initializer/random_uniform\n",
      "hidden2/kernel\n",
      "hidden2/kernel/Assign\n",
      "hidden2/kernel/read\n",
      "hidden2/bias/Initializer/zeros\n",
      "hidden2/bias\n",
      "hidden2/bias/Assign\n",
      "hidden2/bias/read\n",
      "dnn/hidden2/MatMul\n",
      "dnn/hidden2/BiasAdd\n",
      "dnn/hidden2/Relu\n",
      "hidden3/kernel/Initializer/random_uniform/shape\n",
      "hidden3/kernel/Initializer/random_uniform/min\n",
      "hidden3/kernel/Initializer/random_uniform/max\n",
      "hidden3/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden3/kernel/Initializer/random_uniform/sub\n",
      "hidden3/kernel/Initializer/random_uniform/mul\n",
      "hidden3/kernel/Initializer/random_uniform\n",
      "hidden3/kernel\n",
      "hidden3/kernel/Assign\n",
      "hidden3/kernel/read\n",
      "hidden3/bias/Initializer/zeros\n",
      "hidden3/bias\n",
      "hidden3/bias/Assign\n",
      "hidden3/bias/read\n",
      "dnn/hidden3/MatMul\n",
      "dnn/hidden3/BiasAdd\n",
      "dnn/hidden3/Relu\n",
      "hidden4/kernel/Initializer/random_uniform/shape\n",
      "hidden4/kernel/Initializer/random_uniform/min\n",
      "hidden4/kernel/Initializer/random_uniform/max\n",
      "hidden4/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden4/kernel/Initializer/random_uniform/sub\n",
      "hidden4/kernel/Initializer/random_uniform/mul\n",
      "hidden4/kernel/Initializer/random_uniform\n",
      "hidden4/kernel\n",
      "hidden4/kernel/Assign\n",
      "hidden4/kernel/read\n",
      "hidden4/bias/Initializer/zeros\n",
      "hidden4/bias\n",
      "hidden4/bias/Assign\n",
      "hidden4/bias/read\n",
      "dnn/hidden4/MatMul\n",
      "dnn/hidden4/BiasAdd\n",
      "dnn/hidden4/Relu\n",
      "hidden5/kernel/Initializer/random_uniform/shape\n",
      "hidden5/kernel/Initializer/random_uniform/min\n",
      "hidden5/kernel/Initializer/random_uniform/max\n",
      "hidden5/kernel/Initializer/random_uniform/RandomUniform\n",
      "hidden5/kernel/Initializer/random_uniform/sub\n",
      "hidden5/kernel/Initializer/random_uniform/mul\n",
      "hidden5/kernel/Initializer/random_uniform\n",
      "hidden5/kernel\n",
      "hidden5/kernel/Assign\n",
      "hidden5/kernel/read\n",
      "hidden5/bias/Initializer/zeros\n",
      "hidden5/bias\n",
      "hidden5/bias/Assign\n",
      "hidden5/bias/read\n",
      "dnn/hidden5/MatMul\n",
      "dnn/hidden5/BiasAdd\n",
      "dnn/hidden5/Relu\n",
      "outputs/kernel/Initializer/random_uniform/shape\n",
      "outputs/kernel/Initializer/random_uniform/min\n",
      "outputs/kernel/Initializer/random_uniform/max\n",
      "outputs/kernel/Initializer/random_uniform/RandomUniform\n",
      "outputs/kernel/Initializer/random_uniform/sub\n",
      "outputs/kernel/Initializer/random_uniform/mul\n",
      "outputs/kernel/Initializer/random_uniform\n",
      "outputs/kernel\n",
      "outputs/kernel/Assign\n",
      "outputs/kernel/read\n",
      "outputs/bias/Initializer/zeros\n",
      "outputs/bias\n",
      "outputs/bias/Assign\n",
      "outputs/bias/read\n",
      "dnn/outputs/MatMul\n",
      "dnn/outputs/BiasAdd\n",
      "loss/SparseSoftmaxCrossEntropyWithLogits/Shape\n",
      "loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\n",
      "loss/Const\n",
      "loss/loss\n",
      "gradients/Shape\n",
      "gradients/Const\n",
      "gradients/Fill\n",
      "gradients/loss/loss_grad/Reshape/shape\n",
      "gradients/loss/loss_grad/Reshape\n",
      "gradients/loss/loss_grad/Shape\n",
      "gradients/loss/loss_grad/Tile\n",
      "gradients/loss/loss_grad/Shape_1\n",
      "gradients/loss/loss_grad/Shape_2\n",
      "gradients/loss/loss_grad/Const\n",
      "gradients/loss/loss_grad/Prod\n",
      "gradients/loss/loss_grad/Const_1\n",
      "gradients/loss/loss_grad/Prod_1\n",
      "gradients/loss/loss_grad/Maximum/y\n",
      "gradients/loss/loss_grad/Maximum\n",
      "gradients/loss/loss_grad/floordiv\n",
      "gradients/loss/loss_grad/Cast\n",
      "gradients/loss/loss_grad/truediv\n",
      "gradients/zeros_like\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims\n",
      "gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul\n",
      "gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/outputs/MatMul_grad/MatMul\n",
      "gradients/dnn/outputs/MatMul_grad/MatMul_1\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden5/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden5/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden5/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden5/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden4/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden4/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden4/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden3/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden3/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden3/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden2/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden2/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden2/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden1/Relu_grad/ReluGrad\n",
      "gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1\n",
      "gradients/dnn/hidden1/MatMul_grad/MatMul\n",
      "gradients/dnn/hidden1/MatMul_grad/MatMul_1\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/group_deps\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency\n",
      "gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1\n",
      "clip_by_value/Minimum/y\n",
      "clip_by_value/Minimum\n",
      "clip_by_value/y\n",
      "clip_by_value\n",
      "clip_by_value_1/Minimum/y\n",
      "clip_by_value_1/Minimum\n",
      "clip_by_value_1/y\n",
      "clip_by_value_1\n",
      "clip_by_value_2/Minimum/y\n",
      "clip_by_value_2/Minimum\n",
      "clip_by_value_2/y\n",
      "clip_by_value_2\n",
      "clip_by_value_3/Minimum/y\n",
      "clip_by_value_3/Minimum\n",
      "clip_by_value_3/y\n",
      "clip_by_value_3\n",
      "clip_by_value_4/Minimum/y\n",
      "clip_by_value_4/Minimum\n",
      "clip_by_value_4/y\n",
      "clip_by_value_4\n",
      "clip_by_value_5/Minimum/y\n",
      "clip_by_value_5/Minimum\n",
      "clip_by_value_5/y\n",
      "clip_by_value_5\n",
      "clip_by_value_6/Minimum/y\n",
      "clip_by_value_6/Minimum\n",
      "clip_by_value_6/y\n",
      "clip_by_value_6\n",
      "clip_by_value_7/Minimum/y\n",
      "clip_by_value_7/Minimum\n",
      "clip_by_value_7/y\n",
      "clip_by_value_7\n",
      "clip_by_value_8/Minimum/y\n",
      "clip_by_value_8/Minimum\n",
      "clip_by_value_8/y\n",
      "clip_by_value_8\n",
      "clip_by_value_9/Minimum/y\n",
      "clip_by_value_9/Minimum\n",
      "clip_by_value_9/y\n",
      "clip_by_value_9\n",
      "clip_by_value_10/Minimum/y\n",
      "clip_by_value_10/Minimum\n",
      "clip_by_value_10/y\n",
      "clip_by_value_10\n",
      "clip_by_value_11/Minimum/y\n",
      "clip_by_value_11/Minimum\n",
      "clip_by_value_11/y\n",
      "clip_by_value_11\n",
      "GradientDescent/learning_rate\n",
      "GradientDescent/update_hidden1/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden1/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden2/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden2/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden3/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden3/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden4/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden4/bias/ApplyGradientDescent\n",
      "GradientDescent/update_hidden5/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_hidden5/bias/ApplyGradientDescent\n",
      "GradientDescent/update_outputs/kernel/ApplyGradientDescent\n",
      "GradientDescent/update_outputs/bias/ApplyGradientDescent\n",
      "GradientDescent\n",
      "eval/in_top_k/InTopKV2/k\n",
      "eval/in_top_k/InTopKV2\n",
      "eval/Cast\n",
      "eval/Const\n",
      "eval/accuracy\n",
      "init\n",
      "save/Const\n",
      "save/SaveV2/tensor_names\n",
      "save/SaveV2/shape_and_slices\n",
      "save/SaveV2\n",
      "save/control_dependency\n",
      "save/RestoreV2/tensor_names\n",
      "save/RestoreV2/shape_and_slices\n",
      "save/RestoreV2\n",
      "save/Assign\n",
      "save/RestoreV2_1/tensor_names\n",
      "save/RestoreV2_1/shape_and_slices\n",
      "save/RestoreV2_1\n",
      "save/Assign_1\n",
      "save/RestoreV2_2/tensor_names\n",
      "save/RestoreV2_2/shape_and_slices\n",
      "save/RestoreV2_2\n",
      "save/Assign_2\n",
      "save/RestoreV2_3/tensor_names\n",
      "save/RestoreV2_3/shape_and_slices\n",
      "save/RestoreV2_3\n",
      "save/Assign_3\n",
      "save/RestoreV2_4/tensor_names\n",
      "save/RestoreV2_4/shape_and_slices\n",
      "save/RestoreV2_4\n",
      "save/Assign_4\n",
      "save/RestoreV2_5/tensor_names\n",
      "save/RestoreV2_5/shape_and_slices\n",
      "save/RestoreV2_5\n",
      "save/Assign_5\n",
      "save/RestoreV2_6/tensor_names\n",
      "save/RestoreV2_6/shape_and_slices\n",
      "save/RestoreV2_6\n",
      "save/Assign_6\n",
      "save/RestoreV2_7/tensor_names\n",
      "save/RestoreV2_7/shape_and_slices\n",
      "save/RestoreV2_7\n",
      "save/Assign_7\n",
      "save/RestoreV2_8/tensor_names\n",
      "save/RestoreV2_8/shape_and_slices\n",
      "save/RestoreV2_8\n",
      "save/Assign_8\n",
      "save/RestoreV2_9/tensor_names\n",
      "save/RestoreV2_9/shape_and_slices\n",
      "save/RestoreV2_9\n",
      "save/Assign_9\n",
      "save/RestoreV2_10/tensor_names\n",
      "save/RestoreV2_10/shape_and_slices\n",
      "save/RestoreV2_10\n",
      "save/Assign_10\n",
      "save/RestoreV2_11/tensor_names\n",
      "save/RestoreV2_11/shape_and_slices\n",
      "save/RestoreV2_11\n",
      "save/Assign_11\n",
      "save/restore_all\n"
     ]
    }
   ],
   "source": [
    "for op in tf.get_default_graph().get_operations():\n",
    "    print(op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops, that's a lot of operations! It's much easier to use TensorBoard to visualize the graph. The following hack will allow you to visualize the graph within Jupyter (if it does not work with your browser, you will need to use a `FileWriter` to save the graph and then visualize it in TensorBoard):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = b\"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.374540118847&quot;).pbtxt = 'node {\\n  name: &quot;X&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 784\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;y&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\020\\\\003\\\\000\\\\000,\\\\001\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.0743979513645\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0743979513645\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 5\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 784\\n        }\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;hidden1/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 300\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;hidden1/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden1/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden1/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;hidden1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden1/MatMul&quot;\\n  input: &quot;hidden1/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden1/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden1/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;,\\\\001\\\\000\\\\0002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.130930736661\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.130930736661\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 22\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 300\\n        }\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;hidden2/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 50\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;hidden2/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden2/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden2/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;hidden2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden2/MatMul&quot;\\n  input: &quot;hidden2/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden2/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden2/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;2\\\\000\\\\000\\\\0002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.244948968291\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.244948968291\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 39\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden3/kernel&quot;\\n  input: &quot;hidden3/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden3/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 50\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden3/bias&quot;\\n  input: &quot;hidden3/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden3/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden3/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden3/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;hidden3/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden3/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden3/MatMul&quot;\\n  input: &quot;hidden3/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden3/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden3/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;2\\\\000\\\\000\\\\0002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.244948968291\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.244948968291\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 56\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden4/kernel&quot;\\n  input: &quot;hidden4/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden4/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 50\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden4/bias&quot;\\n  input: &quot;hidden4/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden4/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden4/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden4/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden3/Relu&quot;\\n  input: &quot;hidden4/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden4/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden4/MatMul&quot;\\n  input: &quot;hidden4/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden4/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden4/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;2\\\\000\\\\000\\\\0002\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.244948968291\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.244948968291\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 73\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden5/kernel&quot;\\n  input: &quot;hidden5/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden5/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 50\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden5/bias&quot;\\n  input: &quot;hidden5/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;hidden5/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;hidden5/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden5/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden4/Relu&quot;\\n  input: &quot;hidden5/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden5/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/hidden5/MatMul&quot;\\n  input: &quot;hidden5/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/hidden5/Relu&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;dnn/hidden5/BiasAdd&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;2\\\\000\\\\000\\\\000\\\\n\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -0.316227763891\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.316227763891\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 42\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 90\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/max&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/RandomUniform&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Initializer/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/mul&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 50\\n        }\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/kernel&quot;\\n  input: &quot;outputs/kernel/Initializer/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/kernel/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;outputs/kernel&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias/Initializer/zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 10\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;outputs/bias/Initializer/zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;outputs/bias/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;outputs/bias&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden5/Relu&quot;\\n  input: &quot;outputs/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dnn/outputs/BiasAdd&quot;\\n  op: &quot;BiasAdd&quot;\\n  input: &quot;dnn/outputs/MatMul&quot;\\n  input: &quot;outputs/bias/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  op: &quot;SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;dnn/outputs/BiasAdd&quot;\\n  input: &quot;y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tlabels&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;loss/loss&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  input: &quot;loss/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/loss/loss_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/loss/loss_grad/Reshape&quot;\\n  input: &quot;gradients/loss/loss_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Shape_1&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Shape_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/loss/loss_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/loss/loss_grad/Shape_1&quot;\\n  input: &quot;gradients/loss/loss_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/loss/loss_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/loss/loss_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/loss/loss_grad/Shape_2&quot;\\n  input: &quot;gradients/loss/loss_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/loss/loss_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/loss/loss_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients/loss/loss_grad/Prod_1&quot;\\n  input: &quot;gradients/loss/loss_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/loss/loss_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;gradients/loss/loss_grad/Prod&quot;\\n  input: &quot;gradients/loss/loss_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/loss/loss_grad/Shape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/loss/loss_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/loss_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/loss/loss_grad/Tile&quot;\\n  input: &quot;gradients/loss/loss_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/zeros_like&quot;\\n  op: &quot;ZerosLike&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  op: &quot;PreventGradient&quot;\\n  input: &quot;loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;message&quot;\\n    value {\\n      s: &quot;Currently there is no way to take the second derivative of sparse_softmax_cross_entropy_with_logits due to the fused implementation\\\\\\'s interaction with tf.gradients()&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: -1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  op: &quot;ExpandDims&quot;\\n  input: &quot;gradients/loss/loss_grad/truediv&quot;\\n  input: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tdim&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims&quot;\\n  input: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;^gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n  input: &quot;^gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/outputs/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/outputs/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;outputs/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden5/Relu&quot;\\n  input: &quot;gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/outputs/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/dnn/outputs/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/outputs/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/dnn/outputs/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden5/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/dnn/hidden5/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden5/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden5/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden5/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden5/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden5/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden5/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden5/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden5/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden5/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden4/Relu&quot;\\n  input: &quot;gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden5/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden5/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden5/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden5/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden5/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden5/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/dnn/hidden5/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden5/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden4/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/dnn/hidden4/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden4/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden4/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden4/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden4/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden4/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden4/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden4/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden3/Relu&quot;\\n  input: &quot;gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden4/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden4/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden4/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden4/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden4/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden4/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/dnn/hidden4/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden4/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden3/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/dnn/hidden3/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden3/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden3/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden3/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden3/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden3/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden3/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden3/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  input: &quot;gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden3/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden3/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden3/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden3/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden3/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden3/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/dnn/hidden3/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden3/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden2/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden2/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden2/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden2/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden2/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  input: &quot;gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden2/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/dnn/hidden2/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden2/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  op: &quot;ReluGrad&quot;\\n  input: &quot;gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency&quot;\\n  input: &quot;dnn/hidden1/Relu&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n  op: &quot;BiasAddGrad&quot;\\n  input: &quot;gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n  input: &quot;^gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden1/Relu_grad/ReluGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n  input: &quot;^gradients/dnn/hidden1/BiasAdd_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden1/BiasAdd_grad/BiasAddGrad&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  input: &quot;hidden1/kernel/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;X&quot;\\n  input: &quot;gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n  input: &quot;^gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden1/MatMul_grad/MatMul&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n  input: &quot;^gradients/dnn/hidden1/MatMul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/dnn/hidden1/MatMul_grad/MatMul_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden1/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value/Minimum&quot;\\n  input: &quot;clip_by_value/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_1/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_1/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden1/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_1/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_1/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_1&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_1/Minimum&quot;\\n  input: &quot;clip_by_value_1/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_2/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_2/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden2/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_2/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_2/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_2&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_2/Minimum&quot;\\n  input: &quot;clip_by_value_2/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_3/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_3/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden2/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_3/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_3/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_3&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_3/Minimum&quot;\\n  input: &quot;clip_by_value_3/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_4/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_4/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden3/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_4/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_4/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_4&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_4/Minimum&quot;\\n  input: &quot;clip_by_value_4/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_5/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_5/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden3/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_5/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_5/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_5&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_5/Minimum&quot;\\n  input: &quot;clip_by_value_5/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_6/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_6/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden4/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_6/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_6/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_6&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_6/Minimum&quot;\\n  input: &quot;clip_by_value_6/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_7/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_7/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden4/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_7/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_7/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_7&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_7/Minimum&quot;\\n  input: &quot;clip_by_value_7/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_8/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_8/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden5/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_8/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_8/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_8&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_8/Minimum&quot;\\n  input: &quot;clip_by_value_8/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_9/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_9/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/hidden5/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_9/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_9/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_9&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_9/Minimum&quot;\\n  input: &quot;clip_by_value_9/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_10/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_10/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/outputs/MatMul_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_10/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_10/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_10&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_10/Minimum&quot;\\n  input: &quot;clip_by_value_10/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_11/Minimum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_11/Minimum&quot;\\n  op: &quot;Minimum&quot;\\n  input: &quot;gradients/dnn/outputs/BiasAdd_grad/tuple/control_dependency_1&quot;\\n  input: &quot;clip_by_value_11/Minimum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_11/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;clip_by_value_11&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;clip_by_value_11/Minimum&quot;\\n  input: &quot;clip_by_value_11/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.00999999977648\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden1/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden1/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden2/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden2/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden3/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden3/kernel&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden3/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden3/bias&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden4/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden4/kernel&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden4/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden4/bias&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden5/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden5/kernel&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_hidden5/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;hidden5/bias&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_9&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_outputs/kernel/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;outputs/kernel&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_outputs/bias/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;clip_by_value_11&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^GradientDescent/update_hidden1/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden1/bias/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden2/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden2/bias/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden3/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden3/bias/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden4/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden4/bias/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden5/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_hidden5/bias/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_outputs/kernel/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_outputs/bias/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;eval/in_top_k/InTopKV2/k&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT64\\n        tensor_shape {\\n        }\\n        int64_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/in_top_k/InTopKV2&quot;\\n  op: &quot;InTopKV2&quot;\\n  input: &quot;dnn/outputs/BiasAdd&quot;\\n  input: &quot;y&quot;\\n  input: &quot;eval/in_top_k/InTopKV2/k&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT64\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;eval/in_top_k/InTopKV2&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_BOOL\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;eval/accuracy&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;eval/Cast&quot;\\n  input: &quot;eval/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^hidden1/kernel/Assign&quot;\\n  input: &quot;^hidden1/bias/Assign&quot;\\n  input: &quot;^hidden2/kernel/Assign&quot;\\n  input: &quot;^hidden2/bias/Assign&quot;\\n  input: &quot;^hidden3/kernel/Assign&quot;\\n  input: &quot;^hidden3/bias/Assign&quot;\\n  input: &quot;^hidden4/kernel/Assign&quot;\\n  input: &quot;^hidden4/bias/Assign&quot;\\n  input: &quot;^hidden5/kernel/Assign&quot;\\n  input: &quot;^hidden5/bias/Assign&quot;\\n  input: &quot;^outputs/kernel/Assign&quot;\\n  input: &quot;^outputs/bias/Assign&quot;\\n}\\nnode {\\n  name: &quot;save/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;model&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 12\\n          }\\n        }\\n        string_val: &quot;hidden1/bias&quot;\\n        string_val: &quot;hidden1/kernel&quot;\\n        string_val: &quot;hidden2/bias&quot;\\n        string_val: &quot;hidden2/kernel&quot;\\n        string_val: &quot;hidden3/bias&quot;\\n        string_val: &quot;hidden3/kernel&quot;\\n        string_val: &quot;hidden4/bias&quot;\\n        string_val: &quot;hidden4/kernel&quot;\\n        string_val: &quot;hidden5/bias&quot;\\n        string_val: &quot;hidden5/kernel&quot;\\n        string_val: &quot;outputs/bias&quot;\\n        string_val: &quot;outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 12\\n          }\\n        }\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2&quot;\\n  op: &quot;SaveV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/SaveV2/tensor_names&quot;\\n  input: &quot;save/SaveV2/shape_and_slices&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;hidden3/bias&quot;\\n  input: &quot;hidden3/kernel&quot;\\n  input: &quot;hidden4/bias&quot;\\n  input: &quot;hidden4/kernel&quot;\\n  input: &quot;hidden5/bias&quot;\\n  input: &quot;hidden5/kernel&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;outputs/kernel&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;^save/SaveV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@save/Const&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden1/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2/tensor_names&quot;\\n  input: &quot;save/RestoreV2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/bias&quot;\\n  input: &quot;save/RestoreV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_1/tensor_names&quot;\\n  input: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden1/kernel&quot;\\n  input: &quot;save/RestoreV2_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden1/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden2/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_2/tensor_names&quot;\\n  input: &quot;save/RestoreV2_2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_2&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/bias&quot;\\n  input: &quot;save/RestoreV2_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_3&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_3/tensor_names&quot;\\n  input: &quot;save/RestoreV2_3/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_3&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden2/kernel&quot;\\n  input: &quot;save/RestoreV2_3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden2/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden3/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_4&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_4/tensor_names&quot;\\n  input: &quot;save/RestoreV2_4/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_4&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden3/bias&quot;\\n  input: &quot;save/RestoreV2_4&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_5&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_5/tensor_names&quot;\\n  input: &quot;save/RestoreV2_5/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_5&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden3/kernel&quot;\\n  input: &quot;save/RestoreV2_5&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden3/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_6/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden4/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_6/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_6&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_6/tensor_names&quot;\\n  input: &quot;save/RestoreV2_6/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_6&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden4/bias&quot;\\n  input: &quot;save/RestoreV2_6&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_7/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_7/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_7&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_7/tensor_names&quot;\\n  input: &quot;save/RestoreV2_7/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_7&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden4/kernel&quot;\\n  input: &quot;save/RestoreV2_7&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden4/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_8/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden5/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_8/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_8&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_8/tensor_names&quot;\\n  input: &quot;save/RestoreV2_8/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_8&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden5/bias&quot;\\n  input: &quot;save/RestoreV2_8&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_9/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_9/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_9&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_9/tensor_names&quot;\\n  input: &quot;save/RestoreV2_9/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_9&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;hidden5/kernel&quot;\\n  input: &quot;save/RestoreV2_9&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@hidden5/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_10/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;outputs/bias&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_10/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_10&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_10/tensor_names&quot;\\n  input: &quot;save/RestoreV2_10/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_10&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/bias&quot;\\n  input: &quot;save/RestoreV2_10&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/bias&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_11/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;outputs/kernel&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_11/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_11&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_11/tensor_names&quot;\\n  input: &quot;save/RestoreV2_11/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_11&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;outputs/kernel&quot;\\n  input: &quot;save/RestoreV2_11&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@outputs/kernel&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/restore_all&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^save/Assign&quot;\\n  input: &quot;^save/Assign_1&quot;\\n  input: &quot;^save/Assign_2&quot;\\n  input: &quot;^save/Assign_3&quot;\\n  input: &quot;^save/Assign_4&quot;\\n  input: &quot;^save/Assign_5&quot;\\n  input: &quot;^save/Assign_6&quot;\\n  input: &quot;^save/Assign_7&quot;\\n  input: &quot;^save/Assign_8&quot;\\n  input: &quot;^save/Assign_9&quot;\\n  input: &quot;^save/Assign_10&quot;\\n  input: &quot;^save/Assign_11&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.374540118847&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you know which operations you need, you can get a handle on them using the graph's `get_operation_by_name()` or `get_tensor_by_name()` methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name(\"eval/accuracy:0\")\n",
    "\n",
    "training_op = tf.get_default_graph().get_operation_by_name(\"GradientDescent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are the author of the original model, you could make things easier for people who will reuse your model by giving operations very clear names and documenting them. Another approach is to create a collection containing all the important operations that people will want to get a handle on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for op in (X, y, accuracy, training_op):\n",
    "    tf.add_to_collection(\"my_important_ops\", op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way people who reuse your model will be able to simply write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y, accuracy, training_op = tf.get_collection(\"my_important_ops\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can start a session, restore the model's state and continue training on your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "    # continue training the model..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, let's test this for real!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 Test accuracy: 0.961\n",
      "1 Test accuracy: 0.961\n",
      "2 Test accuracy: 0.9625\n",
      "3 Test accuracy: 0.9611\n",
      "4 Test accuracy: 0.9638\n",
      "5 Test accuracy: 0.9649\n",
      "6 Test accuracy: 0.9664\n",
      "7 Test accuracy: 0.963\n",
      "8 Test accuracy: 0.9665\n",
      "9 Test accuracy: 0.9668\n",
      "10 Test accuracy: 0.9664\n",
      "11 Test accuracy: 0.9671\n",
      "12 Test accuracy: 0.9678\n",
      "13 Test accuracy: 0.968\n",
      "14 Test accuracy: 0.969\n",
      "15 Test accuracy: 0.9686\n",
      "16 Test accuracy: 0.969\n",
      "17 Test accuracy: 0.9704\n",
      "18 Test accuracy: 0.9673\n",
      "19 Test accuracy: 0.9681\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: mnist.test.images,\n",
    "                                                y: mnist.test.labels})\n",
    "        print(epoch, \"Test accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if you have access to the Python code that built the original graph, you can use it instead of `import_meta_graph()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_hidden3 = 50\n",
    "n_hidden4 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\")\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\")\n",
    "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.relu, name=\"hidden5\")\n",
    "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "threshold = 1.0\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "grads_and_vars = optimizer.compute_gradients(loss)\n",
    "capped_gvs = [(tf.clip_by_value(grad, -threshold, threshold), var)\n",
    "              for grad, var in grads_and_vars]\n",
    "training_op = optimizer.apply_gradients(capped_gvs)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And continue training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 Test accuracy: 0.9611\n",
      "1 Test accuracy: 0.9626\n",
      "2 Test accuracy: 0.9626\n",
      "3 Test accuracy: 0.9586\n",
      "4 Test accuracy: 0.9645\n",
      "5 Test accuracy: 0.9643\n",
      "6 Test accuracy: 0.9646\n",
      "7 Test accuracy: 0.9645\n",
      "8 Test accuracy: 0.9641\n",
      "9 Test accuracy: 0.9631\n",
      "10 Test accuracy: 0.9663\n",
      "11 Test accuracy: 0.9672\n",
      "12 Test accuracy: 0.969\n",
      "13 Test accuracy: 0.967\n",
      "14 Test accuracy: 0.9675\n",
      "15 Test accuracy: 0.9691\n",
      "16 Test accuracy: 0.9687\n",
      "17 Test accuracy: 0.97\n",
      "18 Test accuracy: 0.9693\n",
      "19 Test accuracy: 0.9704\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: mnist.test.images,\n",
    "                                                y: mnist.test.labels})\n",
    "        print(epoch, \"Test accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general you will want to reuse only the lower layers. If you are using `import_meta_graph()` it will load the whole graph, but you can simply ignore the parts you do not need. In this example, we add a new 4th hidden layer on top of the pretrained 3rd layer (ignoring the old 4th hidden layer). We also build a new output layer, the loss for this new output, and a new optimizer to minimize it. We also need another saver to save the whole graph (containing both the entire old graph plus the new operations), and an initialization operation to initialize all the new variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_hidden4 = 20  # new layer\n",
    "n_outputs = 10  # new layer\n",
    "\n",
    "saver = tf.train.import_meta_graph(\"./my_model_final.ckpt.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "hidden3 = tf.get_default_graph().get_tensor_by_name(\"dnn/hidden4/Relu:0\")\n",
    "\n",
    "new_hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"new_hidden4\")\n",
    "new_logits = tf.layers.dense(new_hidden4, n_outputs, name=\"new_outputs\")\n",
    "\n",
    "with tf.name_scope(\"new_loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=new_logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"new_eval\"):\n",
    "    correct = tf.nn.in_top_k(new_logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"new_train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "new_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can train this new model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 Test accuracy: 0.9185\n",
      "1 Test accuracy: 0.9362\n",
      "2 Test accuracy: 0.9488\n",
      "3 Test accuracy: 0.9517\n",
      "4 Test accuracy: 0.9565\n",
      "5 Test accuracy: 0.9584\n",
      "6 Test accuracy: 0.9594\n",
      "7 Test accuracy: 0.9601\n",
      "8 Test accuracy: 0.9623\n",
      "9 Test accuracy: 0.964\n",
      "10 Test accuracy: 0.9648\n",
      "11 Test accuracy: 0.9656\n",
      "12 Test accuracy: 0.9659\n",
      "13 Test accuracy: 0.9658\n",
      "14 Test accuracy: 0.967\n",
      "15 Test accuracy: 0.9666\n",
      "16 Test accuracy: 0.9676\n",
      "17 Test accuracy: 0.9673\n",
      "18 Test accuracy: 0.9683\n",
      "19 Test accuracy: 0.9677\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: mnist.test.images,\n",
    "                                                y: mnist.test.labels})\n",
    "        print(epoch, \"Test accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = new_saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have access to the Python code that built the original graph, you can just reuse the parts you need and drop the rest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # reused\n",
    "n_hidden2 = 50  # reused\n",
    "n_hidden3 = 50  # reused\n",
    "n_hidden4 = 20  # new!\n",
    "n_outputs = 10  # new!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")       # reused\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\") # reused\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\") # reused\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\") # new!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\")                         # new!\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, you must create one `Saver` to restore the pretrained model (giving it the list of variables to restore, or else it will complain that the graphs don't match), and another `Saver` to save the new model, once it is trained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 Test accuracy: 0.9037\n",
      "1 Test accuracy: 0.9296\n",
      "2 Test accuracy: 0.9384\n",
      "3 Test accuracy: 0.9442\n",
      "4 Test accuracy: 0.9483\n",
      "5 Test accuracy: 0.9509\n",
      "6 Test accuracy: 0.9527\n",
      "7 Test accuracy: 0.9538\n",
      "8 Test accuracy: 0.9566\n",
      "9 Test accuracy: 0.9579\n",
      "10 Test accuracy: 0.9589\n",
      "11 Test accuracy: 0.959\n",
      "12 Test accuracy: 0.96\n",
      "13 Test accuracy: 0.9616\n",
      "14 Test accuracy: 0.9629\n",
      "15 Test accuracy: 0.963\n",
      "16 Test accuracy: 0.9643\n",
      "17 Test accuracy: 0.9647\n",
      "18 Test accuracy: 0.9654\n",
      "19 Test accuracy: 0.9648\n"
     ]
    }
   ],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123L]\") # regular expression\n",
    "restore_saver = tf.train.Saver(reuse_vars) # to restore layers 1-3\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):                                      # not shown in the book\n",
    "        for iteration in range(mnist.train.num_examples // batch_size): # not shown\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)      # not shown\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})  # not shown\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: mnist.test.images,  # not shown\n",
    "                                                y: mnist.test.labels}) # not shown\n",
    "        print(epoch, \"Test accuracy:\", accuracy_val)                   # not shown\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reusing Models from Other Frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, for each variable we want to reuse, we find its initializer's assignment operation, and we get its second input, which corresponds to the initialization value. When we run the initializer, we replace the initialization values with the ones we want, using a `feed_dict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 2\n",
    "n_hidden1 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  61.   83.  105.]]\n"
     ]
    }
   ],
   "source": [
    "original_w = [[1., 2., 3.], [4., 5., 6.]] # Load the weights from the other framework\n",
    "original_b = [7., 8., 9.]                 # Load the biases from the other framework\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "# [...] Build the rest of the model\n",
    "\n",
    "# Get a handle on the assignment nodes for the hidden1 variables\n",
    "graph = tf.get_default_graph()\n",
    "assign_kernel = graph.get_operation_by_name(\"hidden1/kernel/Assign\")\n",
    "assign_bias = graph.get_operation_by_name(\"hidden1/bias/Assign\")\n",
    "init_kernel = assign_kernel.inputs[1]\n",
    "init_bias = assign_bias.inputs[1]\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init, feed_dict={init_kernel: original_w, init_bias: original_b})\n",
    "    # [...] Train the model on your new task\n",
    "    print(hidden1.eval(feed_dict={X: [[10.0, 11.0]]}))  # not shown in the book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the weights variable created by the `tf.layers.dense()` function is called `\"kernel\"` (instead of `\"weights\"` when using the `tf.contrib.layers.fully_connected()`, as in the book), and the biases variable is called `bias` instead of `biases`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach (initially used in the book) would be to create dedicated assignment nodes and dedicated placeholders. This is more verbose and less efficient, but you may find this more explicit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 61.  83. 105.]]\n"
     ]
    }
   ],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 2\n",
    "n_hidden1 = 3\n",
    "\n",
    "original_w = [[1., 2., 3.], [4., 5., 6.]] # Load the weights from the other framework\n",
    "original_b = [7., 8., 9.]                 # Load the biases from the other framework\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "# [...] Build the rest of the model\n",
    "\n",
    "# Get a handle on the variables of layer hidden1\n",
    "with tf.variable_scope(\"\", default_name=\"\", reuse=True):  # root scope\n",
    "    hidden1_weights = tf.get_variable(\"hidden1/kernel\")\n",
    "    hidden1_biases = tf.get_variable(\"hidden1/bias\")\n",
    "\n",
    "# Create dedicated placeholders and assignment nodes\n",
    "original_weights = tf.placeholder(tf.float32, shape=(n_inputs, n_hidden1))\n",
    "original_biases = tf.placeholder(tf.float32, shape=n_hidden1)\n",
    "assign_hidden1_weights = tf.assign(hidden1_weights, original_weights)\n",
    "assign_hidden1_biases = tf.assign(hidden1_biases, original_biases)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    sess.run(assign_hidden1_weights, feed_dict={original_weights: original_w})\n",
    "    sess.run(assign_hidden1_biases, feed_dict={original_biases: original_b})\n",
    "    # [...] Train the model on your new task\n",
    "    print(hidden1.eval(feed_dict={X: [[10.0, 11.0]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we could also get a handle on the variables using `get_collection()` and specifying the `scope`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'hidden1/kernel:0' shape=(2, 3) dtype=float32_ref>,\n",
       " <tf.Variable 'hidden1/bias:0' shape=(3,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"hidden1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we could use the graph's `get_tensor_by_name()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'hidden1/kernel:0' shape=(2, 3) dtype=float32_ref>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'hidden1/bias:0' shape=(3,) dtype=float32_ref>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_default_graph().get_tensor_by_name(\"hidden1/bias:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freezing the Lower Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # reused\n",
    "n_hidden2 = 50  # reused\n",
    "n_hidden3 = 50  # reused\n",
    "n_hidden4 = 20  # new!\n",
    "n_outputs = 10  # new!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")       # reused\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\") # reused\n",
    "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.relu, name=\"hidden3\") # reused\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu, name=\"hidden4\") # new!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\")                         # new!\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"):                                         # not shown in the book\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)     # not shown\n",
    "    train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                   scope=\"hidden[34]|outputs\")\n",
    "    training_op = optimizer.minimize(loss, var_list=train_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "new_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 Test accuracy: 0.8952\n",
      "1 Test accuracy: 0.9283\n",
      "2 Test accuracy: 0.938\n",
      "3 Test accuracy: 0.9417\n",
      "4 Test accuracy: 0.9447\n",
      "5 Test accuracy: 0.9467\n",
      "6 Test accuracy: 0.95\n",
      "7 Test accuracy: 0.9503\n",
      "8 Test accuracy: 0.9526\n",
      "9 Test accuracy: 0.9519\n",
      "10 Test accuracy: 0.9539\n",
      "11 Test accuracy: 0.9537\n",
      "12 Test accuracy: 0.9549\n",
      "13 Test accuracy: 0.9551\n",
      "14 Test accuracy: 0.9541\n",
      "15 Test accuracy: 0.9539\n",
      "16 Test accuracy: 0.9553\n",
      "17 Test accuracy: 0.9546\n",
      "18 Test accuracy: 0.9546\n",
      "19 Test accuracy: 0.9556\n"
     ]
    }
   ],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # regular expression\n",
    "restore_saver = tf.train.Saver(reuse_vars) # to restore layers 1-3\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: mnist.test.images,\n",
    "                                                y: mnist.test.labels})\n",
    "        print(epoch, \"Test accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # reused\n",
    "n_hidden2 = 50  # reused\n",
    "n_hidden3 = 50  # reused\n",
    "n_hidden4 = 20  # new!\n",
    "n_outputs = 10  # new!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                              name=\"hidden1\") # reused frozen\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,\n",
    "                              name=\"hidden2\") # reused frozen\n",
    "    hidden2_stop = tf.stop_gradient(hidden2)\n",
    "    # stop gradient at this node \n",
    "    hidden3 = tf.layers.dense(hidden2_stop, n_hidden3, activation=tf.nn.relu,\n",
    "                              name=\"hidden3\") # reused, not frozen\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu,\n",
    "                              name=\"hidden4\") # new!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\") # new!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training code is exactly the same as earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 Test accuracy: 0.9054\n",
      "1 Test accuracy: 0.9327\n",
      "2 Test accuracy: 0.9415\n",
      "3 Test accuracy: 0.9453\n",
      "4 Test accuracy: 0.9478\n",
      "5 Test accuracy: 0.9485\n",
      "6 Test accuracy: 0.9511\n",
      "7 Test accuracy: 0.9496\n",
      "8 Test accuracy: 0.9522\n",
      "9 Test accuracy: 0.9514\n",
      "10 Test accuracy: 0.9523\n",
      "11 Test accuracy: 0.9515\n",
      "12 Test accuracy: 0.9518\n",
      "13 Test accuracy: 0.9547\n",
      "14 Test accuracy: 0.9544\n",
      "15 Test accuracy: 0.9538\n",
      "16 Test accuracy: 0.9548\n",
      "17 Test accuracy: 0.9546\n",
      "18 Test accuracy: 0.9547\n",
      "19 Test accuracy: 0.9549\n"
     ]
    }
   ],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # regular expression\n",
    "restore_saver = tf.train.Saver(reuse_vars) # to restore layers 1-3\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: mnist.test.images,\n",
    "                                                y: mnist.test.labels})\n",
    "        print(epoch, \"Test accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caching the Frozen Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300 # reused\n",
    "n_hidden2 = 50  # reused\n",
    "n_hidden3 = 50  # reused\n",
    "n_hidden4 = 20  # new!\n",
    "n_outputs = 10  # new!\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                              name=\"hidden1\") # reused frozen\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,\n",
    "                              name=\"hidden2\") # reused frozen & cached\n",
    "    hidden2_stop = tf.stop_gradient(hidden2)\n",
    "    hidden3 = tf.layers.dense(hidden2_stop, n_hidden3, activation=tf.nn.relu,\n",
    "                              name=\"hidden3\") # reused, not frozen\n",
    "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.relu,\n",
    "                              name=\"hidden4\") # new!\n",
    "    logits = tf.layers.dense(hidden4, n_outputs, name=\"outputs\") # new!\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reuse_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                               scope=\"hidden[123]\") # regular expression\n",
    "restore_saver = tf.train.Saver(reuse_vars) # to restore layers 1-3\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_model_final.ckpt\n",
      "0 Test accuracy: 0.9142\n",
      "1 Test accuracy: 0.9401\n",
      "2 Test accuracy: 0.9442\n",
      "3 Test accuracy: 0.9464\n",
      "4 Test accuracy: 0.9491\n",
      "5 Test accuracy: 0.9488\n",
      "6 Test accuracy: 0.951\n",
      "7 Test accuracy: 0.9515\n",
      "8 Test accuracy: 0.9536\n",
      "9 Test accuracy: 0.9531\n",
      "10 Test accuracy: 0.9541\n",
      "11 Test accuracy: 0.9536\n",
      "12 Test accuracy: 0.9544\n",
      "13 Test accuracy: 0.9558\n",
      "14 Test accuracy: 0.9549\n",
      "15 Test accuracy: 0.9563\n",
      "16 Test accuracy: 0.9557\n",
      "17 Test accuracy: 0.9558\n",
      "18 Test accuracy: 0.956\n",
      "19 Test accuracy: 0.9567\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_batches = mnist.train.num_examples // batch_size\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_model_final.ckpt\")\n",
    "    \n",
    "    h2_cache = sess.run(hidden2, feed_dict={X: mnist.train.images})\n",
    "    # get the hidden2 layers output for all training dataset \n",
    "    h2_cache_test = sess.run(hidden2, feed_dict={X: mnist.test.images}) # not shown in the book\n",
    "    #  get the hidden2 layers output for all testing dataset \n",
    "    for epoch in range(n_epochs):\n",
    "        shuffled_idx = np.random.permutation(mnist.train.num_examples)\n",
    "        hidden2_batches = np.array_split(h2_cache[shuffled_idx], n_batches)\n",
    "        y_batches = np.array_split(mnist.train.labels[shuffled_idx], n_batches)\n",
    "        # get the batch size cause it first calculate all the output at the time get output of hidden2 \n",
    "        for hidden2_batch, y_batch in zip(hidden2_batches, y_batches):\n",
    "            sess.run(training_op, feed_dict={hidden2:hidden2_batch, y:y_batch})\n",
    "\n",
    "        accuracy_val = accuracy.eval(feed_dict={hidden2: h2_cache_test, # not shown\n",
    "                                                y: mnist.test.labels})  # not shown\n",
    "        print(epoch, \"Test accuracy:\", accuracy_val)                    # not shown\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_new_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,\n",
    "                                       momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nesterov Accelerated Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,\n",
    "                                       momentum=0.9, use_nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate,\n",
    "                                      momentum=0.9, decay=0.9, epsilon=1e-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"):       # not shown in the book\n",
    "    initial_learning_rate = 0.1\n",
    "    decay_steps = 10000\n",
    "    decay_rate = 1/10\n",
    "    global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "    learning_rate = tf.train.exponential_decay(initial_learning_rate, global_step,\n",
    "                                               decay_steps, decay_rate)\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.9)\n",
    "    training_op = optimizer.minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Test accuracy: 0.9579\n",
      "1 Test accuracy: 0.9691\n",
      "2 Test accuracy: 0.976\n",
      "3 Test accuracy: 0.9793\n",
      "4 Test accuracy: 0.9811\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: mnist.test.images,\n",
    "                                                y: mnist.test.labels})\n",
    "        print(epoch, \"Test accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avoiding Overfitting Through Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\ell_1$ and $\\ell_2$ regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implement $\\ell_1$ regularization manually. First, we create the model, as usual (with just one hidden layer this time, for simplicity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    logits = tf.layers.dense(hidden1, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we get a handle on the layer weights, and we compute the total loss, which is equal to the sum of the usual cross entropy loss and the $\\ell_1$ loss (i.e., the absolute values of the weights):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W1 = tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")\n",
    "W2 = tf.get_default_graph().get_tensor_by_name(\"outputs/kernel:0\")\n",
    "\n",
    "scale = 0.001 # l1 regularization hyperparameter\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                              logits=logits)\n",
    "    base_loss = tf.reduce_mean(xentropy, name=\"avg_xentropy\")\n",
    "    reg_losses = tf.reduce_sum(tf.abs(W1)) + tf.reduce_sum(tf.abs(W2))\n",
    "    loss = tf.add(base_loss, scale * reg_losses, name=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest is just as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Test accuracy: 0.8343\n",
      "1 Test accuracy: 0.8726\n",
      "2 Test accuracy: 0.8832\n",
      "3 Test accuracy: 0.8899\n",
      "4 Test accuracy: 0.8958\n",
      "5 Test accuracy: 0.8986\n",
      "6 Test accuracy: 0.9011\n",
      "7 Test accuracy: 0.9032\n",
      "8 Test accuracy: 0.9046\n",
      "9 Test accuracy: 0.9047\n",
      "10 Test accuracy: 0.9065\n",
      "11 Test accuracy: 0.9059\n",
      "12 Test accuracy: 0.9072\n",
      "13 Test accuracy: 0.9072\n",
      "14 Test accuracy: 0.9069\n",
      "15 Test accuracy: 0.9071\n",
      "16 Test accuracy: 0.9064\n",
      "17 Test accuracy: 0.9071\n",
      "18 Test accuracy: 0.9068\n",
      "19 Test accuracy: 0.9063\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: mnist.test.images,\n",
    "                                                y: mnist.test.labels})\n",
    "        print(epoch, \"Test accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can pass a regularization function to the `tf.layers.dense()` function, which will use it to create operations that will compute the regularization loss, and it adds these operations to the collection of regularization losses. The beginning is the same as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will use Python's `partial()` function to avoid repeating the same arguments over and over again. Note that we set the `kernel_regularizer` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scale = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_dense_layer = partial(\n",
    "    tf.layers.dense, activation=tf.nn.relu,\n",
    "    kernel_regularizer=tf.contrib.layers.l1_regularizer(scale))\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    hidden2 = my_dense_layer(hidden1, n_hidden2, name=\"hidden2\")\n",
    "    logits = my_dense_layer(hidden2, n_outputs, activation=None,\n",
    "                            name=\"outputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we must add the regularization losses to the base loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):                                     # not shown in the book\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(  # not shown\n",
    "        labels=y, logits=logits)                                # not shown\n",
    "    base_loss = tf.reduce_mean(xentropy, name=\"avg_xentropy\")   # not shown\n",
    "    reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    loss = tf.add_n([base_loss] + reg_losses, name=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the rest is the same as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Test accuracy: 0.8298\n",
      "1 Test accuracy: 0.8778\n",
      "2 Test accuracy: 0.8917\n",
      "3 Test accuracy: 0.9017\n",
      "4 Test accuracy: 0.9068\n",
      "5 Test accuracy: 0.9103\n",
      "6 Test accuracy: 0.9125\n",
      "7 Test accuracy: 0.9137\n",
      "8 Test accuracy: 0.9149\n",
      "9 Test accuracy: 0.9174\n",
      "10 Test accuracy: 0.9176\n",
      "11 Test accuracy: 0.9184\n",
      "12 Test accuracy: 0.9191\n",
      "13 Test accuracy: 0.9183\n",
      "14 Test accuracy: 0.9195\n",
      "15 Test accuracy: 0.9201\n",
      "16 Test accuracy: 0.9181\n",
      "17 Test accuracy: 0.9184\n",
      "18 Test accuracy: 0.9181\n",
      "19 Test accuracy: 0.9174\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 200\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        accuracy_val = accuracy.eval(feed_dict={X: mnist.test.images,\n",
    "                                                y: mnist.test.labels})\n",
    "        print(epoch, \"Test accuracy:\", accuracy_val)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the book uses `tf.contrib.layers.dropout()` rather than `tf.layers.dropout()` (which did not exist when this chapter was written). It is now preferable to use `tf.layers.dropout()`, because anything in the contrib module may change or be deleted without notice. The `tf.layers.dropout()` function is almost identical to the `tf.contrib.layers.dropout()` function, except for a few minor differences. Most importantly:\n",
    "* you must specify the dropout rate (`rate`) rather than the keep probability (`keep_prob`), where `rate` is simply equal to `1 - keep_prob`,\n",
    "* the `is_training` parameter is renamed to `training`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "dropout_rate = 0.5  # == 1 - keep_prob\n",
    "X_drop = tf.layers.dropout(X, dropout_rate, training=training)\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X_drop, n_hidden1, activation=tf.nn.relu,\n",
    "                              name=\"hidden1\")\n",
    "    hidden1_drop = tf.layers.dropout(hidden1, dropout_rate, training=training)\n",
    "    hidden2 = tf.layers.dense(hidden1_drop, n_hidden2, activation=tf.nn.relu,\n",
    "                              name=\"hidden2\")\n",
    "    hidden2_drop = tf.layers.dropout(hidden2, dropout_rate, training=training)\n",
    "    logits = tf.layers.dense(hidden2_drop, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.9)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Test accuracy: 0.9205\n",
      "1 Test accuracy: 0.9418\n",
      "2 Test accuracy: 0.9486\n",
      "3 Test accuracy: 0.9508\n",
      "4 Test accuracy: 0.954\n",
      "5 Test accuracy: 0.957\n",
      "6 Test accuracy: 0.9604\n",
      "7 Test accuracy: 0.9585\n",
      "8 Test accuracy: 0.9598\n",
      "9 Test accuracy: 0.9663\n",
      "10 Test accuracy: 0.9644\n",
      "11 Test accuracy: 0.9646\n",
      "12 Test accuracy: 0.9675\n",
      "13 Test accuracy: 0.9657\n",
      "14 Test accuracy: 0.9645\n",
      "15 Test accuracy: 0.9668\n",
      "16 Test accuracy: 0.969\n",
      "17 Test accuracy: 0.9682\n",
      "18 Test accuracy: 0.9698\n",
      "19 Test accuracy: 0.9682\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={training: True, X: X_batch, y: y_batch})\n",
    "        acc_test = accuracy.eval(feed_dict={X: mnist.test.images, y: mnist.test.labels})\n",
    "        print(epoch, \"Test accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go back to a plain and simple neural net for MNIST with just 2 hidden layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's get a handle on the first hidden layer's weight and create an operation that will compute the clipped weights using the `clip_by_norm()` function. Then we create an assignment operation to assign the clipped weights to the weights variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold = 1.0\n",
    "weights = tf.get_default_graph().get_tensor_by_name(\"hidden1/kernel:0\")\n",
    "clipped_weights = tf.clip_by_norm(weights, clip_norm=threshold, axes=1)\n",
    "clip_weights = tf.assign(weights, clipped_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this as well for the second hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights2 = tf.get_default_graph().get_tensor_by_name(\"hidden2/kernel:0\")\n",
    "clipped_weights2 = tf.clip_by_norm(weights2, clip_norm=threshold, axes=1)\n",
    "clip_weights2 = tf.assign(weights2, clipped_weights2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add an initializer and a saver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can train the model. It's pretty much as usual, except that right after running the `training_op`, we run the `clip_weights` and `clip_weights2` operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Test accuracy: 0.9517\n",
      "1 Test accuracy: 0.9674\n",
      "2 Test accuracy: 0.9712\n",
      "3 Test accuracy: 0.9759\n",
      "4 Test accuracy: 0.975\n",
      "5 Test accuracy: 0.9761\n",
      "6 Test accuracy: 0.9765\n",
      "7 Test accuracy: 0.9796\n",
      "8 Test accuracy: 0.9791\n",
      "9 Test accuracy: 0.9794\n",
      "10 Test accuracy: 0.9805\n",
      "11 Test accuracy: 0.9809\n",
      "12 Test accuracy: 0.9807\n",
      "13 Test accuracy: 0.9799\n",
      "14 Test accuracy: 0.982\n",
      "15 Test accuracy: 0.9816\n",
      "16 Test accuracy: 0.9825\n",
      "17 Test accuracy: 0.9825\n",
      "18 Test accuracy: 0.9816\n",
      "19 Test accuracy: 0.9822\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:                                              # not shown in the book\n",
    "    init.run()                                                          # not shown\n",
    "    for epoch in range(n_epochs):                                       # not shown\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):  # not shown\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)       # not shown\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            clip_weights.eval()\n",
    "            clip_weights2.eval()                                        # not shown\n",
    "        acc_test = accuracy.eval(feed_dict={X: mnist.test.images,       # not shown\n",
    "                                            y: mnist.test.labels})      # not shown\n",
    "        print(epoch, \"Test accuracy:\", acc_test)                        # not shown\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")               # not shown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation above is straightforward and it works fine, but it is a bit messy. A better approach is to define a `max_norm_regularizer()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def max_norm_regularizer(threshold, axes=1, name=\"max_norm\",\n",
    "                         collection=\"max_norm\"):\n",
    "    def max_norm(weights):\n",
    "        clipped = tf.clip_by_norm(weights, clip_norm=threshold, axes=axes)\n",
    "        clip_weights = tf.assign(weights, clipped, name=name)\n",
    "        tf.add_to_collection(collection, clip_weights)\n",
    "        return None # there is no regularization loss term\n",
    "    return max_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can call this function to get a max norm regularizer (with the threshold you want). When you create a hidden layer, you can pass this regularizer to the `kernel_regularizer` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 50\n",
    "n_outputs = 10\n",
    "\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_norm_reg = max_norm_regularizer(threshold=1.0)\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                              kernel_regularizer=max_norm_reg, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,\n",
    "                              kernel_regularizer=max_norm_reg, name=\"hidden2\")\n",
    "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"loss\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.MomentumOptimizer(learning_rate, momentum)\n",
    "    training_op = optimizer.minimize(loss)    \n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training is as usual, except you must run the weights clipping operations after each training operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Test accuracy: 0.9496\n",
      "1 Test accuracy: 0.9672\n",
      "2 Test accuracy: 0.9727\n",
      "3 Test accuracy: 0.9743\n",
      "4 Test accuracy: 0.9753\n",
      "5 Test accuracy: 0.9755\n",
      "6 Test accuracy: 0.9791\n",
      "7 Test accuracy: 0.9796\n",
      "8 Test accuracy: 0.9799\n",
      "9 Test accuracy: 0.9799\n",
      "10 Test accuracy: 0.9774\n",
      "11 Test accuracy: 0.9802\n",
      "12 Test accuracy: 0.9787\n",
      "13 Test accuracy: 0.9806\n",
      "14 Test accuracy: 0.9796\n",
      "15 Test accuracy: 0.9805\n",
      "16 Test accuracy: 0.9813\n",
      "17 Test accuracy: 0.9803\n",
      "18 Test accuracy: 0.9807\n",
      "19 Test accuracy: 0.9808\n"
     ]
    }
   ],
   "source": [
    "clip_all_weights = tf.get_collection(\"max_norm\")\n",
    "#change the weight to be max_norm weight after each training step \n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            sess.run(clip_all_weights)\n",
    "            \n",
    "        acc_test = accuracy.eval(feed_dict={X: mnist.test.images,     # not shown in the book\n",
    "                                            y: mnist.test.labels})    # not shown\n",
    "        print(epoch, \"Test accuracy:\", acc_test)                      # not shown\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_model_final.ckpt\")             # not shown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercise solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. to 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See appendix A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Exercise: Build a DNN with five hidden layers of 100 neurons each, He initialization, and the ELU activation function._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need similar DNNs in the next exercises, so let's create a function to build this DNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "def dnn(inputs, n_hidden_layers=5, n_neurons=100, name=None,\n",
    "        activation=tf.nn.elu, initializer=he_init):\n",
    "    with tf.variable_scope(name, \"dnn\"):\n",
    "        for layer in range(n_hidden_layers):\n",
    "            inputs = tf.layers.dense(inputs, n_neurons, activation=activation,\n",
    "                                     kernel_initializer=initializer,\n",
    "                                     name=\"hidden%d\" % (layer + 1))\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28 # MNIST\n",
    "n_outputs = 5\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
    "\n",
    "dnn_outputs = dnn(X)\n",
    "\n",
    "logits = tf.layers.dense(dnn_outputs, n_outputs, kernel_initializer=he_init, name=\"logits\")\n",
    "Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Exercise: Using Adam optimization and early stopping, try training it on MNIST but only on digits 0 to 4, as we will use transfer learning for digits 5 to 9 in the next exercise. You will need a softmax output layer with five neurons, and as always make sure to save checkpoints at regular intervals and save the final model so you can reuse it later._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's complete the graph with the cost function, the training op, and all the other usual components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "training_op = optimizer.minimize(loss, name=\"training_op\")\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fetch the MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create the training set, validation and test set (we need the validation set to implement early stopping):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train1 = mnist.train.images[mnist.train.labels < 5]\n",
    "y_train1 = mnist.train.labels[mnist.train.labels < 5]\n",
    "X_valid1 = mnist.validation.images[mnist.validation.labels < 5]\n",
    "y_valid1 = mnist.validation.labels[mnist.validation.labels < 5]\n",
    "X_test1 = mnist.test.images[mnist.test.labels < 5]\n",
    "y_test1 = mnist.test.labels[mnist.test.labels < 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.128663\tBest loss: 0.128663\tAccuracy: 96.64%\n",
      "1\tValidation loss: 0.448317\tBest loss: 0.128663\tAccuracy: 78.19%\n",
      "2\tValidation loss: 0.190859\tBest loss: 0.128663\tAccuracy: 95.54%\n",
      "3\tValidation loss: 0.146951\tBest loss: 0.128663\tAccuracy: 96.79%\n",
      "4\tValidation loss: 0.086076\tBest loss: 0.086076\tAccuracy: 97.69%\n",
      "5\tValidation loss: 0.115353\tBest loss: 0.086076\tAccuracy: 97.77%\n",
      "6\tValidation loss: 0.239142\tBest loss: 0.086076\tAccuracy: 95.15%\n",
      "7\tValidation loss: 0.088810\tBest loss: 0.086076\tAccuracy: 98.12%\n",
      "8\tValidation loss: 0.108763\tBest loss: 0.086076\tAccuracy: 97.81%\n",
      "9\tValidation loss: 0.300808\tBest loss: 0.086076\tAccuracy: 96.17%\n",
      "10\tValidation loss: 0.179260\tBest loss: 0.086076\tAccuracy: 97.46%\n",
      "11\tValidation loss: 0.125690\tBest loss: 0.086076\tAccuracy: 98.48%\n",
      "12\tValidation loss: 0.738371\tBest loss: 0.086076\tAccuracy: 77.72%\n",
      "13\tValidation loss: 1.894743\tBest loss: 0.086076\tAccuracy: 78.54%\n",
      "14\tValidation loss: 0.415678\tBest loss: 0.086076\tAccuracy: 78.50%\n",
      "15\tValidation loss: 0.537646\tBest loss: 0.086076\tAccuracy: 75.45%\n",
      "16\tValidation loss: 1.009708\tBest loss: 0.086076\tAccuracy: 53.99%\n",
      "17\tValidation loss: 1.228350\tBest loss: 0.086076\tAccuracy: 38.15%\n",
      "18\tValidation loss: 1.510606\tBest loss: 0.086076\tAccuracy: 29.44%\n",
      "19\tValidation loss: 1.632344\tBest loss: 0.086076\tAccuracy: 22.01%\n",
      "20\tValidation loss: 1.628246\tBest loss: 0.086076\tAccuracy: 22.01%\n",
      "21\tValidation loss: 1.626765\tBest loss: 0.086076\tAccuracy: 22.01%\n",
      "22\tValidation loss: 1.651615\tBest loss: 0.086076\tAccuracy: 18.73%\n",
      "23\tValidation loss: 1.663751\tBest loss: 0.086076\tAccuracy: 19.27%\n",
      "24\tValidation loss: 1.675138\tBest loss: 0.086076\tAccuracy: 22.01%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_0_to_4.ckpt\n",
      "Final test accuracy: 98.05%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train1))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train1) // batch_size):\n",
    "            X_batch, y_batch = X_train1[rnd_indices], y_train1[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid1, y: y_valid1})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = saver.save(sess, \"./my_mnist_model_0_to_4.ckpt\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_mnist_model_0_to_4.ckpt\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test1, y: y_test1})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get 98.05% accuracy on the test set. That's not too bad, but let's see if we can do better by tuning the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Exercise: Tune the hyperparameters using cross-validation and see what precision you can achieve._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a `DNNClassifier` class, compatible with Scikit-Learn's `RandomizedSearchCV` class, to perform hyperparameter tuning. Here are the key points of this implementation:\n",
    "* the `__init__()` method (constructor) does nothing more than create instance variables for each of the hyperparameters.\n",
    "* the `fit()` method creates the graph, starts a session and trains the model:\n",
    "  * it calls the `_build_graph()` method to build the graph (much lile the graph we defined earlier). Once this method is done creating the graph, it saves all the important operations as instance variables for easy access by other methods.\n",
    "  * the `_dnn()` method builds the hidden layers, just like the `dnn()` function above, but also with support for batch normalization and dropout (for the next exercises).\n",
    "  * if the `fit()` method is given a validation set (`X_valid` and `y_valid`), then it implements early stopping. This implementation does not save the best model to disk, but rather to memory: it uses the `_get_model_params()` method to get all the graph's variables and their values, and the `_restore_model_params()` method to restore the variable values (of the best model found). This trick helps speed up training.\n",
    "  * After the `fit()` method has finished training the model, it keeps the session open so that predictions can be made quickly, without having to save a model to disk and restore it for every prediction. You can close the session by calling the `close_session()` method.\n",
    "* the `predict_proba()` method uses the trained model to predict the class probabilities.\n",
    "* the `predict()` method calls `predict_proba()` and returns the class with the highest probability, for each instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "class DNNClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_hidden_layers=5, n_neurons=100, optimizer_class=tf.train.AdamOptimizer,\n",
    "                 learning_rate=0.01, batch_size=20, activation=tf.nn.elu, initializer=he_init,\n",
    "                 batch_norm_momentum=None, dropout_rate=None, random_state=None):\n",
    "        \"\"\"Initialize the DNNClassifier by simply storing all the hyperparameters.\"\"\"\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.n_neurons = n_neurons\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.activation = activation\n",
    "        self.initializer = initializer\n",
    "        self.batch_norm_momentum = batch_norm_momentum\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.random_state = random_state\n",
    "        self._session = None\n",
    "\n",
    "    def _dnn(self, inputs):\n",
    "        \"\"\"Build the hidden layers, with support for batch normalization and dropout.\"\"\"\n",
    "        for layer in range(self.n_hidden_layers):\n",
    "            if self.dropout_rate:\n",
    "                inputs = tf.layers.dropout(inputs, self.dropout_rate, training=self._training)\n",
    "            inputs = tf.layers.dense(inputs, self.n_neurons,\n",
    "                                     kernel_initializer=self.initializer,\n",
    "                                     name=\"hidden%d\" % (layer + 1))\n",
    "            if self.batch_norm_momentum:\n",
    "                inputs = tf.layers.batch_normalization(inputs, momentum=self.batch_norm_momentum,\n",
    "                                                       training=self._training)\n",
    "            inputs = self.activation(inputs, name=\"hidden%d_out\" % (layer + 1))\n",
    "        return inputs\n",
    "\n",
    "    def _build_graph(self, n_inputs, n_outputs):\n",
    "        \"\"\"Build the same model as earlier\"\"\"\n",
    "        if self.random_state is not None:\n",
    "            tf.set_random_seed(self.random_state)\n",
    "            np.random.seed(self.random_state)\n",
    "\n",
    "        X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "        y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "        if self.batch_norm_momentum or self.dropout_rate:\n",
    "            self._training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "        else:\n",
    "            self._training = None\n",
    "\n",
    "        dnn_outputs = self._dnn(X)\n",
    "\n",
    "        logits = tf.layers.dense(dnn_outputs, n_outputs, kernel_initializer=he_init, name=\"logits\")\n",
    "        Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "        xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "                                                                  logits=logits)\n",
    "        loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "        optimizer = self.optimizer_class(learning_rate=self.learning_rate)\n",
    "        training_op = optimizer.minimize(loss)\n",
    "\n",
    "        correct = tf.nn.in_top_k(logits, y, 1)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        # Make the important operations available easily through instance variables\n",
    "        self._X, self._y = X, y\n",
    "        self._Y_proba, self._loss = Y_proba, loss\n",
    "        self._training_op, self._accuracy = training_op, accuracy\n",
    "        self._init, self._saver = init, saver\n",
    "\n",
    "    def close_session(self):\n",
    "        if self._session:\n",
    "            self._session.close()\n",
    "\n",
    "    def _get_model_params(self):\n",
    "        \"\"\"Get all variable values (used for early stopping, faster than saving to disk)\"\"\"\n",
    "        with self._graph.as_default():\n",
    "            gvars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "        return {gvar.op.name: value for gvar, value in zip(gvars, self._session.run(gvars))}\n",
    "\n",
    "    def _restore_model_params(self, model_params):\n",
    "        \"\"\"Set all variables to the given values (for early stopping, faster than loading from disk)\"\"\"\n",
    "        gvar_names = list(model_params.keys())\n",
    "        assign_ops = {gvar_name: self._graph.get_operation_by_name(gvar_name + \"/Assign\")\n",
    "                      for gvar_name in gvar_names}\n",
    "        init_values = {gvar_name: assign_op.inputs[1] for gvar_name, assign_op in assign_ops.items()}\n",
    "        feed_dict = {init_values[gvar_name]: model_params[gvar_name] for gvar_name in gvar_names}\n",
    "        self._session.run(assign_ops, feed_dict=feed_dict)\n",
    "\n",
    "    def fit(self, X, y, n_epochs=100, X_valid=None, y_valid=None):\n",
    "        \"\"\"Fit the model to the training set. If X_valid and y_valid are provided, use early stopping.\"\"\"\n",
    "        self.close_session()\n",
    "\n",
    "        # infer n_inputs and n_outputs from the training set.\n",
    "        n_inputs = X.shape[1]\n",
    "        self.classes_ = np.unique(y)\n",
    "        n_outputs = len(self.classes_)\n",
    "        \n",
    "        # Translate the labels vector to a vector of sorted class indices, containing\n",
    "        # integers from 0 to n_outputs - 1.\n",
    "        # For example, if y is equal to [8, 8, 9, 5, 7, 6, 6, 6], then the sorted class\n",
    "        # labels (self.classes_) will be equal to [5, 6, 7, 8, 9], and the labels vector\n",
    "        # will be translated to [3, 3, 4, 0, 2, 1, 1, 1]\n",
    "        self.class_to_index_ = {label: index\n",
    "                                for index, label in enumerate(self.classes_)}\n",
    "        y = np.array([self.class_to_index_[label]\n",
    "                      for label in y], dtype=np.int32)\n",
    "        \n",
    "        self._graph = tf.Graph()\n",
    "        with self._graph.as_default():\n",
    "            self._build_graph(n_inputs, n_outputs)\n",
    "            # extra ops for batch normalization\n",
    "            extra_update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "        # needed in case of early stopping\n",
    "        max_checks_without_progress = 20\n",
    "        checks_without_progress = 0\n",
    "        best_loss = np.infty\n",
    "        best_params = None\n",
    "        \n",
    "        # Now train the model!\n",
    "        self._session = tf.Session(graph=self._graph)\n",
    "        with self._session.as_default() as sess:\n",
    "            self._init.run()\n",
    "            for epoch in range(n_epochs):\n",
    "                rnd_idx = np.random.permutation(len(X))\n",
    "                for rnd_indices in np.array_split(rnd_idx, len(X) // self.batch_size):\n",
    "                    X_batch, y_batch = X[rnd_indices], y[rnd_indices]\n",
    "                    feed_dict = {self._X: X_batch, self._y: y_batch}\n",
    "                    if self._training is not None:\n",
    "                        feed_dict[self._training] = True\n",
    "                    sess.run(self._training_op, feed_dict=feed_dict)\n",
    "                    if extra_update_ops:\n",
    "                        sess.run(extra_update_ops, feed_dict=feed_dict)\n",
    "                if X_valid is not None and y_valid is not None:\n",
    "                    loss_val, acc_val = sess.run([self._loss, self._accuracy],\n",
    "                                                 feed_dict={self._X: X_valid,\n",
    "                                                            self._y: y_valid})\n",
    "                    if loss_val < best_loss:\n",
    "                        best_params = self._get_model_params()\n",
    "                        best_loss = loss_val\n",
    "                        checks_without_progress = 0\n",
    "                    else:\n",
    "                        checks_without_progress += 1\n",
    "                    print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "                        epoch, loss_val, best_loss, acc_val * 100))\n",
    "                    if checks_without_progress > max_checks_without_progress:\n",
    "                        print(\"Early stopping!\")\n",
    "                        break\n",
    "                else:\n",
    "                    loss_train, acc_train = sess.run([self._loss, self._accuracy],\n",
    "                                                     feed_dict={self._X: X_batch,\n",
    "                                                                self._y: y_batch})\n",
    "                    print(\"{}\\tLast training batch loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "                        epoch, loss_train, acc_train * 100))\n",
    "            # If we used early stopping then rollback to the best model found\n",
    "            if best_params:\n",
    "                self._restore_model_params(best_params)\n",
    "            return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        if not self._session:\n",
    "            raise NotFittedError(\"This %s instance is not fitted yet\" % self.__class__.__name__)\n",
    "        with self._session.as_default() as sess:\n",
    "            return self._Y_proba.eval(feed_dict={self._X: X})\n",
    "\n",
    "    def predict(self, X):\n",
    "        class_indices = np.argmax(self.predict_proba(X), axis=1)\n",
    "        return np.array([[self.classes_[class_index]]\n",
    "                         for class_index in class_indices], np.int32)\n",
    "\n",
    "    def save(self, path):\n",
    "        self._saver.save(self._session, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we get the exact same accuracy as earlier using this class (without dropout or batch norm):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.128663\tBest loss: 0.128663\tAccuracy: 96.64%\n",
      "1\tValidation loss: 0.448317\tBest loss: 0.128663\tAccuracy: 78.19%\n",
      "2\tValidation loss: 0.190859\tBest loss: 0.128663\tAccuracy: 95.54%\n",
      "3\tValidation loss: 0.146951\tBest loss: 0.128663\tAccuracy: 96.79%\n",
      "4\tValidation loss: 0.086076\tBest loss: 0.086076\tAccuracy: 97.69%\n",
      "5\tValidation loss: 0.115353\tBest loss: 0.086076\tAccuracy: 97.77%\n",
      "6\tValidation loss: 0.239142\tBest loss: 0.086076\tAccuracy: 95.15%\n",
      "7\tValidation loss: 0.088810\tBest loss: 0.086076\tAccuracy: 98.12%\n",
      "8\tValidation loss: 0.108763\tBest loss: 0.086076\tAccuracy: 97.81%\n",
      "9\tValidation loss: 0.300808\tBest loss: 0.086076\tAccuracy: 96.17%\n",
      "10\tValidation loss: 0.179260\tBest loss: 0.086076\tAccuracy: 97.46%\n",
      "11\tValidation loss: 0.125690\tBest loss: 0.086076\tAccuracy: 98.48%\n",
      "12\tValidation loss: 0.738371\tBest loss: 0.086076\tAccuracy: 77.72%\n",
      "13\tValidation loss: 1.894743\tBest loss: 0.086076\tAccuracy: 78.54%\n",
      "14\tValidation loss: 0.415678\tBest loss: 0.086076\tAccuracy: 78.50%\n",
      "15\tValidation loss: 0.537646\tBest loss: 0.086076\tAccuracy: 75.45%\n",
      "16\tValidation loss: 1.009708\tBest loss: 0.086076\tAccuracy: 53.99%\n",
      "17\tValidation loss: 1.228350\tBest loss: 0.086076\tAccuracy: 38.15%\n",
      "18\tValidation loss: 1.510606\tBest loss: 0.086076\tAccuracy: 29.44%\n",
      "19\tValidation loss: 1.632344\tBest loss: 0.086076\tAccuracy: 22.01%\n",
      "20\tValidation loss: 1.628246\tBest loss: 0.086076\tAccuracy: 22.01%\n",
      "21\tValidation loss: 1.626765\tBest loss: 0.086076\tAccuracy: 22.01%\n",
      "22\tValidation loss: 1.651615\tBest loss: 0.086076\tAccuracy: 18.73%\n",
      "23\tValidation loss: 1.663751\tBest loss: 0.086076\tAccuracy: 19.27%\n",
      "24\tValidation loss: 1.675138\tBest loss: 0.086076\tAccuracy: 22.01%\n",
      "25\tValidation loss: 1.743664\tBest loss: 0.086076\tAccuracy: 18.73%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(activation=<function elu at 0x7fd9e8a620d0>,\n",
       "       batch_norm_momentum=None, batch_size=20, dropout_rate=None,\n",
       "       initializer=<function variance_scaling_initializer.<locals>._initializer at 0x7fd9d5e628c8>,\n",
       "       learning_rate=0.01, n_hidden_layers=5, n_neurons=100,\n",
       "       optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "       random_state=42)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_clf = DNNClassifier(random_state=42)\n",
    "dnn_clf.fit(X_train1, y_train1, n_epochs=1000, X_valid=X_valid1, y_valid=y_valid1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is trained, let's see if it gets the same accuracy as earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98054096127651291"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = dnn_clf.predict(X_test1)\n",
    "accuracy_score(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yep! Working fine. Now we can use Scikit-Learn's `RandomizedSearchCV` class to search for better hyperparameters (this may take over an hour, depending on your system):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV] n_neurons=10, learning_rate=0.05, activation=<function elu at 0x7fd9e8a620d0>, batch_size=100 \n",
      "0\tValidation loss: 0.132355\tBest loss: 0.132355\tAccuracy: 96.44%\n",
      "1\tValidation loss: 0.126329\tBest loss: 0.126329\tAccuracy: 96.21%\n",
      "2\tValidation loss: 0.138284\tBest loss: 0.126329\tAccuracy: 96.76%\n",
      "3\tValidation loss: 0.142094\tBest loss: 0.126329\tAccuracy: 96.25%\n",
      "4\tValidation loss: 0.128141\tBest loss: 0.126329\tAccuracy: 96.76%\n",
      "5\tValidation loss: 0.119928\tBest loss: 0.119928\tAccuracy: 97.26%\n",
      "6\tValidation loss: 0.137134\tBest loss: 0.119928\tAccuracy: 96.72%\n",
      "7\tValidation loss: 0.156194\tBest loss: 0.119928\tAccuracy: 96.79%\n",
      "8\tValidation loss: 0.283938\tBest loss: 0.119928\tAccuracy: 94.53%\n",
      "9\tValidation loss: 1.104801\tBest loss: 0.119928\tAccuracy: 52.38%\n",
      "10\tValidation loss: 0.966833\tBest loss: 0.119928\tAccuracy: 53.09%\n",
      "11\tValidation loss: 0.854368\tBest loss: 0.119928\tAccuracy: 57.47%\n",
      "12\tValidation loss: 1.857330\tBest loss: 0.119928\tAccuracy: 38.98%\n",
      "13\tValidation loss: 1.642338\tBest loss: 0.119928\tAccuracy: 18.73%\n",
      "14\tValidation loss: 1.612854\tBest loss: 0.119928\tAccuracy: 22.01%\n",
      "15\tValidation loss: 1.617682\tBest loss: 0.119928\tAccuracy: 22.01%\n",
      "16\tValidation loss: 1.616873\tBest loss: 0.119928\tAccuracy: 22.01%\n",
      "17\tValidation loss: 1.618228\tBest loss: 0.119928\tAccuracy: 19.27%\n",
      "18\tValidation loss: 1.619055\tBest loss: 0.119928\tAccuracy: 19.27%\n",
      "19\tValidation loss: 1.643334\tBest loss: 0.119928\tAccuracy: 19.08%\n",
      "20\tValidation loss: 1.621200\tBest loss: 0.119928\tAccuracy: 19.08%\n",
      "21\tValidation loss: 1.629823\tBest loss: 0.119928\tAccuracy: 19.27%\n",
      "22\tValidation loss: 1.624553\tBest loss: 0.119928\tAccuracy: 18.73%\n",
      "23\tValidation loss: 1.610214\tBest loss: 0.119928\tAccuracy: 20.91%\n",
      "24\tValidation loss: 1.621143\tBest loss: 0.119928\tAccuracy: 22.01%\n",
      "25\tValidation loss: 1.623761\tBest loss: 0.119928\tAccuracy: 22.01%\n",
      "26\tValidation loss: 1.641760\tBest loss: 0.119928\tAccuracy: 18.73%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, learning_rate=0.05, activation=<function elu at 0x7fd9e8a620d0>, batch_size=100, total=   5.6s\n",
      "[CV] n_neurons=10, learning_rate=0.05, activation=<function elu at 0x7fd9e8a620d0>, batch_size=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.153707\tBest loss: 0.153707\tAccuracy: 95.74%\n",
      "1\tValidation loss: 0.120703\tBest loss: 0.120703\tAccuracy: 96.56%\n",
      "2\tValidation loss: 0.164706\tBest loss: 0.120703\tAccuracy: 96.05%\n",
      "3\tValidation loss: 0.177875\tBest loss: 0.120703\tAccuracy: 95.19%\n",
      "4\tValidation loss: 0.171004\tBest loss: 0.120703\tAccuracy: 95.19%\n",
      "5\tValidation loss: 0.114746\tBest loss: 0.114746\tAccuracy: 96.83%\n",
      "6\tValidation loss: 0.109637\tBest loss: 0.109637\tAccuracy: 97.26%\n",
      "7\tValidation loss: 0.261533\tBest loss: 0.109637\tAccuracy: 94.96%\n",
      "8\tValidation loss: 0.316743\tBest loss: 0.109637\tAccuracy: 94.02%\n",
      "9\tValidation loss: 0.486484\tBest loss: 0.109637\tAccuracy: 77.56%\n",
      "10\tValidation loss: 4.635532\tBest loss: 0.109637\tAccuracy: 53.95%\n",
      "11\tValidation loss: 1.172422\tBest loss: 0.109637\tAccuracy: 48.36%\n",
      "12\tValidation loss: 1.029865\tBest loss: 0.109637\tAccuracy: 55.98%\n",
      "13\tValidation loss: 1.298800\tBest loss: 0.109637\tAccuracy: 36.08%\n",
      "14\tValidation loss: 1.141950\tBest loss: 0.109637\tAccuracy: 38.08%\n",
      "15\tValidation loss: 1.132486\tBest loss: 0.109637\tAccuracy: 38.90%\n",
      "16\tValidation loss: 1.078486\tBest loss: 0.109637\tAccuracy: 45.78%\n",
      "17\tValidation loss: 1.128344\tBest loss: 0.109637\tAccuracy: 45.07%\n",
      "18\tValidation loss: 1.336244\tBest loss: 0.109637\tAccuracy: 34.40%\n",
      "19\tValidation loss: 1.199178\tBest loss: 0.109637\tAccuracy: 39.87%\n",
      "20\tValidation loss: 1.175845\tBest loss: 0.109637\tAccuracy: 40.11%\n",
      "21\tValidation loss: 1.200430\tBest loss: 0.109637\tAccuracy: 40.30%\n",
      "22\tValidation loss: 1.390084\tBest loss: 0.109637\tAccuracy: 34.60%\n",
      "23\tValidation loss: 1.268129\tBest loss: 0.109637\tAccuracy: 40.23%\n",
      "24\tValidation loss: 1.192210\tBest loss: 0.109637\tAccuracy: 40.30%\n",
      "25\tValidation loss: 1.190541\tBest loss: 0.109637\tAccuracy: 41.99%\n",
      "26\tValidation loss: 1.227676\tBest loss: 0.109637\tAccuracy: 38.62%\n",
      "27\tValidation loss: 1.187587\tBest loss: 0.109637\tAccuracy: 39.44%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, learning_rate=0.05, activation=<function elu at 0x7fd9e8a620d0>, batch_size=100, total=   5.9s\n",
      "[CV] n_neurons=10, learning_rate=0.05, activation=<function elu at 0x7fd9e8a620d0>, batch_size=100 \n",
      "0\tValidation loss: 0.182619\tBest loss: 0.182619\tAccuracy: 94.29%\n",
      "1\tValidation loss: 0.152706\tBest loss: 0.152706\tAccuracy: 95.97%\n",
      "2\tValidation loss: 0.193820\tBest loss: 0.152706\tAccuracy: 93.82%\n",
      "3\tValidation loss: 0.195413\tBest loss: 0.152706\tAccuracy: 95.54%\n",
      "4\tValidation loss: 0.171277\tBest loss: 0.152706\tAccuracy: 95.19%\n",
      "5\tValidation loss: 0.140087\tBest loss: 0.140087\tAccuracy: 95.70%\n",
      "6\tValidation loss: 0.170798\tBest loss: 0.140087\tAccuracy: 95.00%\n",
      "7\tValidation loss: 0.163649\tBest loss: 0.140087\tAccuracy: 96.29%\n",
      "8\tValidation loss: 0.199048\tBest loss: 0.140087\tAccuracy: 96.09%\n",
      "9\tValidation loss: 1.552870\tBest loss: 0.140087\tAccuracy: 52.15%\n",
      "10\tValidation loss: 0.813273\tBest loss: 0.140087\tAccuracy: 60.40%\n",
      "11\tValidation loss: 0.775555\tBest loss: 0.140087\tAccuracy: 60.67%\n",
      "12\tValidation loss: 0.775275\tBest loss: 0.140087\tAccuracy: 59.77%\n",
      "13\tValidation loss: 0.770521\tBest loss: 0.140087\tAccuracy: 59.30%\n",
      "14\tValidation loss: 0.734035\tBest loss: 0.140087\tAccuracy: 59.85%\n",
      "15\tValidation loss: 0.744980\tBest loss: 0.140087\tAccuracy: 59.66%\n",
      "16\tValidation loss: 0.785848\tBest loss: 0.140087\tAccuracy: 59.66%\n",
      "17\tValidation loss: 0.776138\tBest loss: 0.140087\tAccuracy: 59.42%\n",
      "18\tValidation loss: 0.764496\tBest loss: 0.140087\tAccuracy: 59.46%\n",
      "19\tValidation loss: 0.763633\tBest loss: 0.140087\tAccuracy: 59.54%\n",
      "20\tValidation loss: 0.743879\tBest loss: 0.140087\tAccuracy: 60.75%\n",
      "21\tValidation loss: 0.763295\tBest loss: 0.140087\tAccuracy: 60.36%\n",
      "22\tValidation loss: 0.717175\tBest loss: 0.140087\tAccuracy: 60.63%\n",
      "23\tValidation loss: 1.869954\tBest loss: 0.140087\tAccuracy: 29.28%\n",
      "24\tValidation loss: 1.215518\tBest loss: 0.140087\tAccuracy: 38.86%\n",
      "25\tValidation loss: 1.196626\tBest loss: 0.140087\tAccuracy: 38.62%\n",
      "26\tValidation loss: 1.170714\tBest loss: 0.140087\tAccuracy: 42.38%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=10, learning_rate=0.05, activation=<function elu at 0x7fd9e8a620d0>, batch_size=100, total=   6.9s\n",
      "[CV] n_neurons=30, learning_rate=0.02, activation=<function relu at 0x7fd9e8a660d0>, batch_size=500 \n",
      "0\tValidation loss: 0.171512\tBest loss: 0.171512\tAccuracy: 95.07%\n",
      "1\tValidation loss: 0.095914\tBest loss: 0.095914\tAccuracy: 97.03%\n",
      "2\tValidation loss: 0.099199\tBest loss: 0.095914\tAccuracy: 96.91%\n",
      "3\tValidation loss: 0.093873\tBest loss: 0.093873\tAccuracy: 97.15%\n",
      "4\tValidation loss: 0.073461\tBest loss: 0.073461\tAccuracy: 98.01%\n",
      "5\tValidation loss: 0.084562\tBest loss: 0.073461\tAccuracy: 97.65%\n",
      "6\tValidation loss: 0.071800\tBest loss: 0.071800\tAccuracy: 98.01%\n",
      "7\tValidation loss: 0.088435\tBest loss: 0.071800\tAccuracy: 97.73%\n",
      "8\tValidation loss: 0.082038\tBest loss: 0.071800\tAccuracy: 97.77%\n",
      "9\tValidation loss: 0.080673\tBest loss: 0.071800\tAccuracy: 97.69%\n",
      "10\tValidation loss: 0.081036\tBest loss: 0.071800\tAccuracy: 97.93%\n",
      "11\tValidation loss: 0.092700\tBest loss: 0.071800\tAccuracy: 97.93%\n",
      "12\tValidation loss: 0.081003\tBest loss: 0.071800\tAccuracy: 98.20%\n",
      "13\tValidation loss: 0.075607\tBest loss: 0.071800\tAccuracy: 98.20%\n",
      "14\tValidation loss: 0.092970\tBest loss: 0.071800\tAccuracy: 98.08%\n",
      "15\tValidation loss: 0.108005\tBest loss: 0.071800\tAccuracy: 97.77%\n",
      "16\tValidation loss: 0.082602\tBest loss: 0.071800\tAccuracy: 98.05%\n",
      "17\tValidation loss: 0.114629\tBest loss: 0.071800\tAccuracy: 97.73%\n",
      "18\tValidation loss: 0.099099\tBest loss: 0.071800\tAccuracy: 97.69%\n",
      "19\tValidation loss: 0.075535\tBest loss: 0.071800\tAccuracy: 98.20%\n",
      "20\tValidation loss: 0.102847\tBest loss: 0.071800\tAccuracy: 98.08%\n",
      "21\tValidation loss: 0.089735\tBest loss: 0.071800\tAccuracy: 98.36%\n",
      "22\tValidation loss: 0.080781\tBest loss: 0.071800\tAccuracy: 97.93%\n",
      "23\tValidation loss: 0.073017\tBest loss: 0.071800\tAccuracy: 98.32%\n",
      "24\tValidation loss: 0.091643\tBest loss: 0.071800\tAccuracy: 97.93%\n",
      "25\tValidation loss: 0.113891\tBest loss: 0.071800\tAccuracy: 98.05%\n",
      "26\tValidation loss: 0.094774\tBest loss: 0.071800\tAccuracy: 98.28%\n",
      "27\tValidation loss: 0.086041\tBest loss: 0.071800\tAccuracy: 98.20%\n",
      "Early stopping!\n",
      "[CV]  n_neurons=30, learning_rate=0.02, activation=<function relu at 0x7fd9e8a660d0>, batch_size=500, total=   6.8s\n",
      "[CV] n_neurons=30, learning_rate=0.02, activation=<function relu at 0x7fd9e8a660d0>, batch_size=500 \n",
      "0\tValidation loss: 0.113188\tBest loss: 0.113188\tAccuracy: 96.60%\n",
      "1\tValidation loss: 0.081384\tBest loss: 0.081384\tAccuracy: 97.58%\n",
      "2\tValidation loss: 0.068770\tBest loss: 0.068770\tAccuracy: 98.12%\n",
      "3\tValidation loss: 0.077316\tBest loss: 0.068770\tAccuracy: 97.73%\n",
      "4\tValidation loss: 0.074333\tBest loss: 0.068770\tAccuracy: 97.97%\n",
      "5\tValidation loss: 0.084735\tBest loss: 0.068770\tAccuracy: 97.30%\n",
      "6\tValidation loss: 0.082893\tBest loss: 0.068770\tAccuracy: 97.69%\n",
      "7\tValidation loss: 0.075860\tBest loss: 0.068770\tAccuracy: 97.65%\n",
      "8\tValidation loss: 0.078686\tBest loss: 0.068770\tAccuracy: 97.77%\n",
      "9\tValidation loss: 0.080869\tBest loss: 0.068770\tAccuracy: 97.77%\n",
      "10\tValidation loss: 0.082026\tBest loss: 0.068770\tAccuracy: 98.12%\n",
      "11\tValidation loss: 0.086516\tBest loss: 0.068770\tAccuracy: 97.69%\n",
      "12\tValidation loss: 0.076660\tBest loss: 0.068770\tAccuracy: 98.12%\n",
      "13\tValidation loss: 0.073815\tBest loss: 0.068770\tAccuracy: 98.08%\n",
      "14\tValidation loss: 0.077873\tBest loss: 0.068770\tAccuracy: 98.20%\n",
      "15\tValidation loss: 0.078704\tBest loss: 0.068770\tAccuracy: 97.93%\n",
      "16\tValidation loss: 0.077061\tBest loss: 0.068770\tAccuracy: 98.28%\n",
      "17\tValidation loss: 0.075423\tBest loss: 0.068770\tAccuracy: 97.93%\n",
      "18\tValidation loss: 0.085646\tBest loss: 0.068770\tAccuracy: 98.24%\n",
      "19\tValidation loss: 0.082202\tBest loss: 0.068770\tAccuracy: 98.05%\n",
      "20\tValidation loss: 0.103338\tBest loss: 0.068770\tAccuracy: 97.46%\n",
      "21\tValidation loss: 0.068182\tBest loss: 0.068182\tAccuracy: 98.40%\n",
      "22\tValidation loss: 0.067592\tBest loss: 0.067592\tAccuracy: 97.93%\n",
      "23\tValidation loss: 0.076756\tBest loss: 0.067592\tAccuracy: 98.28%\n",
      "24\tValidation loss: 0.072327\tBest loss: 0.067592\tAccuracy: 98.48%\n",
      "25\tValidation loss: 0.075613\tBest loss: 0.067592\tAccuracy: 98.44%\n",
      "26\tValidation loss: 0.072291\tBest loss: 0.067592\tAccuracy: 98.40%\n",
      "27\tValidation loss: 0.084550\tBest loss: 0.067592\tAccuracy: 98.28%\n",
      "28\tValidation loss: 0.075566\tBest loss: 0.067592\tAccuracy: 98.36%\n",
      "29\tValidation loss: 0.071688\tBest loss: 0.067592\tAccuracy: 98.28%\n",
      "30\tValidation loss: 0.075556\tBest loss: 0.067592\tAccuracy: 98.24%\n",
      "31\tValidation loss: 0.065671\tBest loss: 0.065671\tAccuracy: 98.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\tValidation loss: 0.083471\tBest loss: 0.065671\tAccuracy: 98.40%\n",
      "33\tValidation loss: 0.086415\tBest loss: 0.065671\tAccuracy: 98.59%\n",
      "34\tValidation loss: 0.085613\tBest loss: 0.065671\tAccuracy: 98.36%\n",
      "35\tValidation loss: 0.099534\tBest loss: 0.065671\tAccuracy: 98.28%\n",
      "36\tValidation loss: 0.102709\tBest loss: 0.065671\tAccuracy: 98.32%\n",
      "37\tValidation loss: 0.093125\tBest loss: 0.065671\tAccuracy: 98.20%\n",
      "38\tValidation loss: 0.109501\tBest loss: 0.065671\tAccuracy: 97.85%\n",
      "39\tValidation loss: 0.109443\tBest loss: 0.065671\tAccuracy: 98.44%\n",
      "40\tValidation loss: 0.087260\tBest loss: 0.065671\tAccuracy: 98.36%\n",
      "41\tValidation loss: 0.106365\tBest loss: 0.065671\tAccuracy: 98.36%\n",
      "42\tValidation loss: 0.102789\tBest loss: 0.065671\tAccuracy: 98.05%\n",
      "43\tValidation loss: 0.094281\tBest loss: 0.065671\tAccuracy: 98.48%\n",
      "44\tValidation loss: 0.094514\tBest loss: 0.065671\tAccuracy: 98.40%\n",
      "[...and much later...]\n",
      "20\tValidation loss: 0.046808\tBest loss: 0.033867\tAccuracy: 98.83%\n",
      "21\tValidation loss: 0.052966\tBest loss: 0.033867\tAccuracy: 98.91%\n",
      "22\tValidation loss: 0.095892\tBest loss: 0.033867\tAccuracy: 98.08%\n",
      "23\tValidation loss: 0.054250\tBest loss: 0.033867\tAccuracy: 98.87%\n",
      "24\tValidation loss: 0.061026\tBest loss: 0.033867\tAccuracy: 98.87%\n",
      "25\tValidation loss: 0.081977\tBest loss: 0.033867\tAccuracy: 98.67%\n",
      "26\tValidation loss: 0.079819\tBest loss: 0.033867\tAccuracy: 98.71%\n",
      "27\tValidation loss: 0.059824\tBest loss: 0.033867\tAccuracy: 98.75%\n",
      "28\tValidation loss: 0.057758\tBest loss: 0.033867\tAccuracy: 98.94%\n",
      "29\tValidation loss: 0.087165\tBest loss: 0.033867\tAccuracy: 98.91%\n",
      "30\tValidation loss: 0.052274\tBest loss: 0.033867\tAccuracy: 99.10%\n",
      "31\tValidation loss: 0.059831\tBest loss: 0.033867\tAccuracy: 98.79%\n",
      "32\tValidation loss: 0.054240\tBest loss: 0.033867\tAccuracy: 98.91%\n",
      "33\tValidation loss: 0.048165\tBest loss: 0.033867\tAccuracy: 98.94%\n",
      "34\tValidation loss: 0.040565\tBest loss: 0.033867\tAccuracy: 99.18%\n",
      "35\tValidation loss: 0.103207\tBest loss: 0.033867\tAccuracy: 98.28%\n",
      "36\tValidation loss: 400.716797\tBest loss: 0.033867\tAccuracy: 71.46%\n",
      "37\tValidation loss: 11.996887\tBest loss: 0.033867\tAccuracy: 96.09%\n",
      "38\tValidation loss: 2.623182\tBest loss: 0.033867\tAccuracy: 96.56%\n",
      "39\tValidation loss: 1.344962\tBest loss: 0.033867\tAccuracy: 97.69%\n",
      "40\tValidation loss: 1.125381\tBest loss: 0.033867\tAccuracy: 97.42%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=DNNClassifier(activation=<function elu at 0x7fd9e8a620d0>,\n",
       "       batch_norm_momentum=None, batch_size=20, dropout_rate=None,\n",
       "       initializer=<function variance_scaling_initializer.<locals>._initializer at 0x7fd9d5e628c8>,\n",
       "       learning_rate=0.01, n_hidden_layers=5, n_neurons=100,\n",
       "       optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "       random_state=42),\n",
       "          fit_params={'y_valid': array([0, 4, ..., 1, 2], dtype=uint8), 'X_valid': array([[ 0.,  0., ...,  0.,  0.],\n",
       "       [ 0.,  0., ...,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0., ...,  0.,  0.],\n",
       "       [ 0.,  0., ...,  0.,  0.]], dtype=float32), 'n_epochs': 1000},\n",
       "          iid=True, n_iter=50, n_jobs=1,\n",
       "          param_distributions={'n_neurons': [10, 30, 50, 70, 90, 100, 120, 140, 160], 'learning_rate': [0.01, 0.02, 0.05, 0.1], 'activation': [<function relu at 0x7fd9e8a660d0>, <function elu at 0x7fd9e8a620d0>, <function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fd9db0b30d0>, <function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fd9d4ddca60>], 'batch_size': [10, 50, 100, 500]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def leaky_relu(alpha=0.01):\n",
    "    def parametrized_leaky_relu(z, name=None):\n",
    "        return tf.maximum(alpha * z, z, name=name)\n",
    "    return parametrized_leaky_relu\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_neurons\": [10, 30, 50, 70, 90, 100, 120, 140, 160],\n",
    "    \"batch_size\": [10, 50, 100, 500],\n",
    "    \"learning_rate\": [0.01, 0.02, 0.05, 0.1],\n",
    "    \"activation\": [tf.nn.relu, tf.nn.elu, leaky_relu(alpha=0.01), leaky_relu(alpha=0.1)],\n",
    "    # you could also try exploring different numbers of hidden layers, different optimizers, etc.\n",
    "    #\"n_hidden_layers\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    #\"optimizer_class\": [tf.train.AdamOptimizer, partial(tf.train.MomentumOptimizer, momentum=0.95)],\n",
    "}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(DNNClassifier(random_state=42), param_distribs, n_iter=50,\n",
    "                                fit_params={\"X_valid\": X_valid1, \"y_valid\": y_valid1, \"n_epochs\": 1000},\n",
    "                                random_state=42, verbose=2)\n",
    "rnd_search.fit(X_train1, y_train1)\n",
    "\n",
    "# fit_params as a constructor argument was deprecated in Scikit-Learn version 0.19 and will\n",
    "# be removed in version 0.21. Pass fit parameters to the fit() method instead:\n",
    "# rnd_search = RandomizedSearchCV(DNNClassifier(random_state=42), param_distribs, n_iter=50,\n",
    "#                                 random_state=42, verbose=2)\n",
    "# fit_params={\"X_valid\": X_valid1, \"y_valid\": y_valid1, \"n_epochs\": 1000}\n",
    "# rnd_search.fit(X_train1, y_train1, **fit_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': <function __main__.leaky_relu.<locals>.parametrized_leaky_relu>,\n",
       " 'batch_size': 500,\n",
       " 'learning_rate': 0.01,\n",
       " 'n_neurons': 140}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99318933644677954"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rnd_search.predict(X_test1)\n",
    "accuracy_score(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonderful! Tuning the hyperparameters got us up to 99.32% accuracy! It may not sound like a great improvement to go from 98.05% to 99.32% accuracy, but consider the error rate: it went from roughly 2% to 0.7%. That's a 65% reduction of the number of errors this model will produce!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a good idea to save this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnd_search.best_estimator_.save(\"./my_best_mnist_model_0_to_4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Exercise: Now try adding Batch Normalization and compare the learning curves: is it converging faster than before? Does it produce a better model?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train the best model found, once again, to see how fast it converges (alternatively, you could tweak the code above to make it write summaries for TensorBoard, so you can visualize the learning curve):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.090732\tBest loss: 0.090732\tAccuracy: 97.22%\n",
      "1\tValidation loss: 0.052198\tBest loss: 0.052198\tAccuracy: 98.40%\n",
      "2\tValidation loss: 0.040040\tBest loss: 0.040040\tAccuracy: 98.94%\n",
      "3\tValidation loss: 0.057495\tBest loss: 0.040040\tAccuracy: 98.55%\n",
      "4\tValidation loss: 0.045600\tBest loss: 0.040040\tAccuracy: 98.75%\n",
      "5\tValidation loss: 0.062344\tBest loss: 0.040040\tAccuracy: 98.48%\n",
      "6\tValidation loss: 0.048719\tBest loss: 0.040040\tAccuracy: 98.67%\n",
      "7\tValidation loss: 0.050346\tBest loss: 0.040040\tAccuracy: 98.79%\n",
      "8\tValidation loss: 0.051224\tBest loss: 0.040040\tAccuracy: 98.79%\n",
      "9\tValidation loss: 0.036505\tBest loss: 0.036505\tAccuracy: 98.98%\n",
      "10\tValidation loss: 0.052532\tBest loss: 0.036505\tAccuracy: 98.71%\n",
      "11\tValidation loss: 0.057086\tBest loss: 0.036505\tAccuracy: 99.10%\n",
      "12\tValidation loss: 0.036754\tBest loss: 0.036505\tAccuracy: 99.06%\n",
      "13\tValidation loss: 0.046782\tBest loss: 0.036505\tAccuracy: 98.87%\n",
      "14\tValidation loss: 0.048929\tBest loss: 0.036505\tAccuracy: 98.91%\n",
      "15\tValidation loss: 0.052919\tBest loss: 0.036505\tAccuracy: 98.75%\n",
      "16\tValidation loss: 0.054287\tBest loss: 0.036505\tAccuracy: 98.67%\n",
      "17\tValidation loss: 0.047722\tBest loss: 0.036505\tAccuracy: 98.79%\n",
      "18\tValidation loss: 0.040474\tBest loss: 0.036505\tAccuracy: 99.14%\n",
      "19\tValidation loss: 0.033867\tBest loss: 0.033867\tAccuracy: 99.14%\n",
      "20\tValidation loss: 0.046808\tBest loss: 0.033867\tAccuracy: 98.83%\n",
      "21\tValidation loss: 0.052966\tBest loss: 0.033867\tAccuracy: 98.91%\n",
      "22\tValidation loss: 0.095892\tBest loss: 0.033867\tAccuracy: 98.08%\n",
      "23\tValidation loss: 0.054250\tBest loss: 0.033867\tAccuracy: 98.87%\n",
      "24\tValidation loss: 0.061026\tBest loss: 0.033867\tAccuracy: 98.87%\n",
      "25\tValidation loss: 0.081977\tBest loss: 0.033867\tAccuracy: 98.67%\n",
      "26\tValidation loss: 0.079819\tBest loss: 0.033867\tAccuracy: 98.71%\n",
      "27\tValidation loss: 0.059824\tBest loss: 0.033867\tAccuracy: 98.75%\n",
      "28\tValidation loss: 0.057758\tBest loss: 0.033867\tAccuracy: 98.94%\n",
      "29\tValidation loss: 0.087165\tBest loss: 0.033867\tAccuracy: 98.91%\n",
      "30\tValidation loss: 0.052274\tBest loss: 0.033867\tAccuracy: 99.10%\n",
      "31\tValidation loss: 0.059831\tBest loss: 0.033867\tAccuracy: 98.79%\n",
      "32\tValidation loss: 0.054240\tBest loss: 0.033867\tAccuracy: 98.91%\n",
      "33\tValidation loss: 0.048165\tBest loss: 0.033867\tAccuracy: 98.94%\n",
      "34\tValidation loss: 0.040565\tBest loss: 0.033867\tAccuracy: 99.18%\n",
      "35\tValidation loss: 0.103207\tBest loss: 0.033867\tAccuracy: 98.28%\n",
      "36\tValidation loss: 400.716797\tBest loss: 0.033867\tAccuracy: 71.46%\n",
      "37\tValidation loss: 11.996887\tBest loss: 0.033867\tAccuracy: 96.09%\n",
      "38\tValidation loss: 2.623182\tBest loss: 0.033867\tAccuracy: 96.56%\n",
      "39\tValidation loss: 1.344962\tBest loss: 0.033867\tAccuracy: 97.69%\n",
      "40\tValidation loss: 1.125381\tBest loss: 0.033867\tAccuracy: 97.42%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fd9d19e37b8>,\n",
       "       batch_norm_momentum=None, batch_size=500, dropout_rate=None,\n",
       "       initializer=<function variance_scaling_initializer.<locals>._initializer at 0x7fd9d5e628c8>,\n",
       "       learning_rate=0.01, n_hidden_layers=5, n_neurons=140,\n",
       "       optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "       random_state=42)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_clf = DNNClassifier(activation=leaky_relu(alpha=0.1), batch_size=500, learning_rate=0.01,\n",
    "                        n_neurons=140, random_state=42)\n",
    "dnn_clf.fit(X_train1, y_train1, n_epochs=1000, X_valid=X_valid1, y_valid=y_valid1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best loss is reached at epoch 19, but it was already within 10% of that result at epoch 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that we do indeed get 99.32% accuracy on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99318933644677954"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dnn_clf.predict(X_test1)\n",
    "accuracy_score(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, now let's use the exact same model, but this time with batch normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.046053\tBest loss: 0.046053\tAccuracy: 98.67%\n",
      "1\tValidation loss: 0.032228\tBest loss: 0.032228\tAccuracy: 98.83%\n",
      "2\tValidation loss: 0.032974\tBest loss: 0.032228\tAccuracy: 98.83%\n",
      "3\tValidation loss: 0.035961\tBest loss: 0.032228\tAccuracy: 98.94%\n",
      "4\tValidation loss: 0.040250\tBest loss: 0.032228\tAccuracy: 98.94%\n",
      "5\tValidation loss: 0.033051\tBest loss: 0.032228\tAccuracy: 99.06%\n",
      "6\tValidation loss: 0.056053\tBest loss: 0.032228\tAccuracy: 98.32%\n",
      "7\tValidation loss: 0.031729\tBest loss: 0.031729\tAccuracy: 99.18%\n",
      "8\tValidation loss: 0.027662\tBest loss: 0.027662\tAccuracy: 99.26%\n",
      "9\tValidation loss: 0.034074\tBest loss: 0.027662\tAccuracy: 98.94%\n",
      "10\tValidation loss: 0.032173\tBest loss: 0.027662\tAccuracy: 99.06%\n",
      "11\tValidation loss: 0.030538\tBest loss: 0.027662\tAccuracy: 99.10%\n",
      "12\tValidation loss: 0.030337\tBest loss: 0.027662\tAccuracy: 99.10%\n",
      "13\tValidation loss: 0.022219\tBest loss: 0.022219\tAccuracy: 99.45%\n",
      "14\tValidation loss: 0.036824\tBest loss: 0.022219\tAccuracy: 99.14%\n",
      "15\tValidation loss: 0.033945\tBest loss: 0.022219\tAccuracy: 99.18%\n",
      "16\tValidation loss: 0.032533\tBest loss: 0.022219\tAccuracy: 98.98%\n",
      "17\tValidation loss: 0.037204\tBest loss: 0.022219\tAccuracy: 99.02%\n",
      "18\tValidation loss: 0.026982\tBest loss: 0.022219\tAccuracy: 99.34%\n",
      "19\tValidation loss: 0.022094\tBest loss: 0.022094\tAccuracy: 99.53%\n",
      "20\tValidation loss: 0.026196\tBest loss: 0.022094\tAccuracy: 99.26%\n",
      "21\tValidation loss: 0.022107\tBest loss: 0.022094\tAccuracy: 99.49%\n",
      "22\tValidation loss: 0.021436\tBest loss: 0.021436\tAccuracy: 99.53%\n",
      "23\tValidation loss: 0.025607\tBest loss: 0.021436\tAccuracy: 99.37%\n",
      "24\tValidation loss: 0.038882\tBest loss: 0.021436\tAccuracy: 99.22%\n",
      "25\tValidation loss: 0.032011\tBest loss: 0.021436\tAccuracy: 99.26%\n",
      "26\tValidation loss: 0.027673\tBest loss: 0.021436\tAccuracy: 99.22%\n",
      "27\tValidation loss: 0.026874\tBest loss: 0.021436\tAccuracy: 99.30%\n",
      "28\tValidation loss: 0.021123\tBest loss: 0.021123\tAccuracy: 99.41%\n",
      "29\tValidation loss: 0.024784\tBest loss: 0.021123\tAccuracy: 99.45%\n",
      "30\tValidation loss: 0.024108\tBest loss: 0.021123\tAccuracy: 99.49%\n",
      "31\tValidation loss: 0.028439\tBest loss: 0.021123\tAccuracy: 99.37%\n",
      "32\tValidation loss: 0.032366\tBest loss: 0.021123\tAccuracy: 99.22%\n",
      "33\tValidation loss: 0.037057\tBest loss: 0.021123\tAccuracy: 99.18%\n",
      "34\tValidation loss: 0.042305\tBest loss: 0.021123\tAccuracy: 98.98%\n",
      "35\tValidation loss: 0.039662\tBest loss: 0.021123\tAccuracy: 99.14%\n",
      "36\tValidation loss: 0.036299\tBest loss: 0.021123\tAccuracy: 99.14%\n",
      "37\tValidation loss: 0.026997\tBest loss: 0.021123\tAccuracy: 99.53%\n",
      "38\tValidation loss: 0.034407\tBest loss: 0.021123\tAccuracy: 99.22%\n",
      "39\tValidation loss: 0.027668\tBest loss: 0.021123\tAccuracy: 99.41%\n",
      "40\tValidation loss: 0.029128\tBest loss: 0.021123\tAccuracy: 99.30%\n",
      "41\tValidation loss: 0.033564\tBest loss: 0.021123\tAccuracy: 99.14%\n",
      "42\tValidation loss: 0.033810\tBest loss: 0.021123\tAccuracy: 99.30%\n",
      "43\tValidation loss: 0.044953\tBest loss: 0.021123\tAccuracy: 98.98%\n",
      "44\tValidation loss: 0.026280\tBest loss: 0.021123\tAccuracy: 99.26%\n",
      "45\tValidation loss: 0.020275\tBest loss: 0.020275\tAccuracy: 99.61%\n",
      "46\tValidation loss: 0.018810\tBest loss: 0.018810\tAccuracy: 99.45%\n",
      "47\tValidation loss: 0.027529\tBest loss: 0.018810\tAccuracy: 99.18%\n",
      "48\tValidation loss: 0.018120\tBest loss: 0.018120\tAccuracy: 99.53%\n",
      "49\tValidation loss: 0.019378\tBest loss: 0.018120\tAccuracy: 99.45%\n",
      "50\tValidation loss: 0.029760\tBest loss: 0.018120\tAccuracy: 99.34%\n",
      "51\tValidation loss: 0.035702\tBest loss: 0.018120\tAccuracy: 99.26%\n",
      "52\tValidation loss: 0.032662\tBest loss: 0.018120\tAccuracy: 99.02%\n",
      "53\tValidation loss: 0.026943\tBest loss: 0.018120\tAccuracy: 99.37%\n",
      "54\tValidation loss: 0.029007\tBest loss: 0.018120\tAccuracy: 99.53%\n",
      "55\tValidation loss: 0.021956\tBest loss: 0.018120\tAccuracy: 99.49%\n",
      "56\tValidation loss: 0.018983\tBest loss: 0.018120\tAccuracy: 99.61%\n",
      "57\tValidation loss: 0.022788\tBest loss: 0.018120\tAccuracy: 99.49%\n",
      "58\tValidation loss: 0.019578\tBest loss: 0.018120\tAccuracy: 99.61%\n",
      "59\tValidation loss: 0.021676\tBest loss: 0.018120\tAccuracy: 99.61%\n",
      "60\tValidation loss: 0.021580\tBest loss: 0.018120\tAccuracy: 99.65%\n",
      "61\tValidation loss: 0.021467\tBest loss: 0.018120\tAccuracy: 99.65%\n",
      "62\tValidation loss: 0.020513\tBest loss: 0.018120\tAccuracy: 99.65%\n",
      "63\tValidation loss: 0.020252\tBest loss: 0.018120\tAccuracy: 99.65%\n",
      "64\tValidation loss: 0.021724\tBest loss: 0.018120\tAccuracy: 99.65%\n",
      "65\tValidation loss: 0.021499\tBest loss: 0.018120\tAccuracy: 99.69%\n",
      "66\tValidation loss: 0.021627\tBest loss: 0.018120\tAccuracy: 99.69%\n",
      "67\tValidation loss: 0.021569\tBest loss: 0.018120\tAccuracy: 99.69%\n",
      "68\tValidation loss: 0.021727\tBest loss: 0.018120\tAccuracy: 99.69%\n",
      "69\tValidation loss: 0.021104\tBest loss: 0.018120\tAccuracy: 99.69%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fd9d19e3c80>,\n",
       "       batch_norm_momentum=0.95, batch_size=500, dropout_rate=None,\n",
       "       initializer=<function variance_scaling_initializer.<locals>._initializer at 0x7fd9d5e628c8>,\n",
       "       learning_rate=0.01, n_hidden_layers=5, n_neurons=90,\n",
       "       optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "       random_state=42)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_clf_bn = DNNClassifier(activation=leaky_relu(alpha=0.1), batch_size=500, learning_rate=0.01,\n",
    "                           n_neurons=90, random_state=42,\n",
    "                           batch_norm_momentum=0.95)\n",
    "dnn_clf_bn.fit(X_train1, y_train1, n_epochs=1000, X_valid=X_valid1, y_valid=y_valid1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best params are reached during epoch 48, that's actually a slower convergence than earlier. Let's check the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99241097489784003"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dnn_clf_bn.predict(X_test1)\n",
    "accuracy_score(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, batch normalization did not improve accuracy. Let's see if we can find a good set of hyperparameters that will work well with batch normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV] activation=<function relu at 0x7fd9e8a660d0>, n_neurons=70, learning_rate=0.01, batch_norm_momentum=0.99, batch_size=50 \n",
      "0\tValidation loss: 0.113224\tBest loss: 0.113224\tAccuracy: 97.30%\n",
      "1\tValidation loss: 0.064190\tBest loss: 0.064190\tAccuracy: 98.24%\n",
      "2\tValidation loss: 0.080173\tBest loss: 0.064190\tAccuracy: 98.28%\n",
      "3\tValidation loss: 0.059603\tBest loss: 0.059603\tAccuracy: 98.28%\n",
      "4\tValidation loss: 0.043533\tBest loss: 0.043533\tAccuracy: 98.48%\n",
      "5\tValidation loss: 0.040107\tBest loss: 0.040107\tAccuracy: 98.87%\n",
      "6\tValidation loss: 0.051212\tBest loss: 0.040107\tAccuracy: 98.24%\n",
      "7\tValidation loss: 0.046029\tBest loss: 0.040107\tAccuracy: 98.71%\n",
      "8\tValidation loss: 0.053079\tBest loss: 0.040107\tAccuracy: 98.59%\n",
      "9\tValidation loss: 0.066891\tBest loss: 0.040107\tAccuracy: 98.28%\n",
      "10\tValidation loss: 0.037712\tBest loss: 0.037712\tAccuracy: 98.83%\n",
      "11\tValidation loss: 0.055569\tBest loss: 0.037712\tAccuracy: 98.55%\n",
      "12\tValidation loss: 0.040949\tBest loss: 0.037712\tAccuracy: 98.98%\n",
      "13\tValidation loss: 0.077433\tBest loss: 0.037712\tAccuracy: 98.36%\n",
      "14\tValidation loss: 0.065955\tBest loss: 0.037712\tAccuracy: 98.63%\n",
      "15\tValidation loss: 0.038968\tBest loss: 0.037712\tAccuracy: 99.02%\n",
      "16\tValidation loss: 0.039190\tBest loss: 0.037712\tAccuracy: 99.06%\n",
      "17\tValidation loss: 0.050690\tBest loss: 0.037712\tAccuracy: 98.71%\n",
      "18\tValidation loss: 0.043054\tBest loss: 0.037712\tAccuracy: 99.02%\n",
      "19\tValidation loss: 0.063156\tBest loss: 0.037712\tAccuracy: 98.71%\n",
      "20\tValidation loss: 0.043066\tBest loss: 0.037712\tAccuracy: 99.14%\n",
      "21\tValidation loss: 0.058145\tBest loss: 0.037712\tAccuracy: 98.79%\n",
      "22\tValidation loss: 0.039590\tBest loss: 0.037712\tAccuracy: 99.06%\n",
      "23\tValidation loss: 0.049981\tBest loss: 0.037712\tAccuracy: 98.75%\n",
      "24\tValidation loss: 0.047458\tBest loss: 0.037712\tAccuracy: 99.10%\n",
      "25\tValidation loss: 0.040638\tBest loss: 0.037712\tAccuracy: 99.06%\n",
      "26\tValidation loss: 0.041426\tBest loss: 0.037712\tAccuracy: 98.98%\n",
      "27\tValidation loss: 0.041325\tBest loss: 0.037712\tAccuracy: 98.98%\n",
      "28\tValidation loss: 0.054609\tBest loss: 0.037712\tAccuracy: 98.91%\n",
      "29\tValidation loss: 0.067671\tBest loss: 0.037712\tAccuracy: 98.75%\n",
      "30\tValidation loss: 0.037608\tBest loss: 0.037608\tAccuracy: 98.79%\n",
      "31\tValidation loss: 0.047441\tBest loss: 0.037608\tAccuracy: 98.98%\n",
      "32\tValidation loss: 0.053716\tBest loss: 0.037608\tAccuracy: 99.02%\n",
      "33\tValidation loss: 0.045445\tBest loss: 0.037608\tAccuracy: 98.83%\n",
      "34\tValidation loss: 0.046023\tBest loss: 0.037608\tAccuracy: 98.94%\n",
      "35\tValidation loss: 0.050073\tBest loss: 0.037608\tAccuracy: 98.91%\n",
      "36\tValidation loss: 0.051887\tBest loss: 0.037608\tAccuracy: 98.87%\n",
      "37\tValidation loss: 0.050272\tBest loss: 0.037608\tAccuracy: 99.02%\n",
      "38\tValidation loss: 0.043531\tBest loss: 0.037608\tAccuracy: 99.10%\n",
      "39\tValidation loss: 0.054661\tBest loss: 0.037608\tAccuracy: 98.87%\n",
      "40\tValidation loss: 0.047607\tBest loss: 0.037608\tAccuracy: 98.87%\n",
      "41\tValidation loss: 0.051862\tBest loss: 0.037608\tAccuracy: 99.14%\n",
      "42\tValidation loss: 0.044218\tBest loss: 0.037608\tAccuracy: 99.14%\n",
      "43\tValidation loss: 0.043707\tBest loss: 0.037608\tAccuracy: 99.06%\n",
      "44\tValidation loss: 0.039602\tBest loss: 0.037608\tAccuracy: 99.06%\n",
      "45\tValidation loss: 0.048998\tBest loss: 0.037608\tAccuracy: 99.02%\n",
      "46\tValidation loss: 0.045562\tBest loss: 0.037608\tAccuracy: 99.14%\n",
      "47\tValidation loss: 0.042198\tBest loss: 0.037608\tAccuracy: 99.10%\n",
      "48\tValidation loss: 0.027679\tBest loss: 0.027679\tAccuracy: 99.10%\n",
      "49\tValidation loss: 0.033783\tBest loss: 0.027679\tAccuracy: 98.94%\n",
      "50\tValidation loss: 0.032935\tBest loss: 0.027679\tAccuracy: 99.41%\n",
      "51\tValidation loss: 0.042930\tBest loss: 0.027679\tAccuracy: 98.98%\n",
      "52\tValidation loss: 0.045454\tBest loss: 0.027679\tAccuracy: 99.06%\n",
      "53\tValidation loss: 0.047336\tBest loss: 0.027679\tAccuracy: 98.91%\n",
      "54\tValidation loss: 0.036523\tBest loss: 0.027679\tAccuracy: 99.14%\n",
      "55\tValidation loss: 0.064401\tBest loss: 0.027679\tAccuracy: 98.94%\n",
      "56\tValidation loss: 0.047686\tBest loss: 0.027679\tAccuracy: 98.83%\n",
      "57\tValidation loss: 0.049083\tBest loss: 0.027679\tAccuracy: 98.98%\n",
      "58\tValidation loss: 0.057310\tBest loss: 0.027679\tAccuracy: 99.10%\n",
      "59\tValidation loss: 0.043757\tBest loss: 0.027679\tAccuracy: 99.14%\n",
      "60\tValidation loss: 0.058742\tBest loss: 0.027679\tAccuracy: 99.02%\n",
      "61\tValidation loss: 0.055049\tBest loss: 0.027679\tAccuracy: 99.06%\n",
      "62\tValidation loss: 0.039837\tBest loss: 0.027679\tAccuracy: 99.18%\n",
      "63\tValidation loss: 0.057108\tBest loss: 0.027679\tAccuracy: 99.06%\n",
      "64\tValidation loss: 0.043212\tBest loss: 0.027679\tAccuracy: 98.98%\n",
      "65\tValidation loss: 0.046874\tBest loss: 0.027679\tAccuracy: 99.18%\n",
      "66\tValidation loss: 0.052819\tBest loss: 0.027679\tAccuracy: 99.10%\n",
      "67\tValidation loss: 0.045977\tBest loss: 0.027679\tAccuracy: 99.14%\n",
      "68\tValidation loss: 0.053290\tBest loss: 0.027679\tAccuracy: 99.10%\n",
      "69\tValidation loss: 0.052941\tBest loss: 0.027679\tAccuracy: 99.06%\n",
      "Early stopping!\n",
      "[CV]  activation=<function relu at 0x7fd9e8a660d0>, n_neurons=70, learning_rate=0.01, batch_norm_momentum=0.99, batch_size=50, total= 2.7min\n",
      "[CV] activation=<function relu at 0x7fd9e8a660d0>, n_neurons=70, learning_rate=0.01, batch_norm_momentum=0.99, batch_size=50 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  2.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.144984\tBest loss: 0.144984\tAccuracy: 96.40%\n",
      "1\tValidation loss: 0.067873\tBest loss: 0.067873\tAccuracy: 98.44%\n",
      "2\tValidation loss: 0.091854\tBest loss: 0.067873\tAccuracy: 97.30%\n",
      "3\tValidation loss: 0.074647\tBest loss: 0.067873\tAccuracy: 98.05%\n",
      "4\tValidation loss: 0.053722\tBest loss: 0.053722\tAccuracy: 98.48%\n",
      "5\tValidation loss: 0.049216\tBest loss: 0.049216\tAccuracy: 98.44%\n",
      "6\tValidation loss: 0.057619\tBest loss: 0.049216\tAccuracy: 98.48%\n",
      "7\tValidation loss: 0.045842\tBest loss: 0.045842\tAccuracy: 98.75%\n",
      "8\tValidation loss: 0.042398\tBest loss: 0.042398\tAccuracy: 98.63%\n",
      "9\tValidation loss: 0.052629\tBest loss: 0.042398\tAccuracy: 98.63%\n",
      "10\tValidation loss: 0.056892\tBest loss: 0.042398\tAccuracy: 98.63%\n",
      "11\tValidation loss: 0.051838\tBest loss: 0.042398\tAccuracy: 98.75%\n",
      "12\tValidation loss: 0.042647\tBest loss: 0.042398\tAccuracy: 98.67%\n",
      "13\tValidation loss: 0.061297\tBest loss: 0.042398\tAccuracy: 98.59%\n",
      "14\tValidation loss: 0.049706\tBest loss: 0.042398\tAccuracy: 98.87%\n",
      "15\tValidation loss: 0.061934\tBest loss: 0.042398\tAccuracy: 98.79%\n",
      "16\tValidation loss: 0.049027\tBest loss: 0.042398\tAccuracy: 98.87%\n",
      "17\tValidation loss: 0.052187\tBest loss: 0.042398\tAccuracy: 98.79%\n",
      "18\tValidation loss: 0.052031\tBest loss: 0.042398\tAccuracy: 98.94%\n",
      "[...and much later...]\n",
      "13\tValidation loss: 0.043686\tBest loss: 0.040332\tAccuracy: 99.02%\n",
      "14\tValidation loss: 0.046940\tBest loss: 0.040332\tAccuracy: 99.18%\n",
      "15\tValidation loss: 0.045355\tBest loss: 0.040332\tAccuracy: 99.14%\n",
      "16\tValidation loss: 0.084697\tBest loss: 0.040332\tAccuracy: 98.87%\n",
      "17\tValidation loss: 0.123538\tBest loss: 0.040332\tAccuracy: 97.81%\n",
      "18\tValidation loss: 0.296928\tBest loss: 0.040332\tAccuracy: 97.50%\n",
      "19\tValidation loss: 0.053660\tBest loss: 0.040332\tAccuracy: 98.91%\n",
      "20\tValidation loss: 0.045684\tBest loss: 0.040332\tAccuracy: 98.94%\n",
      "21\tValidation loss: 0.051971\tBest loss: 0.040332\tAccuracy: 99.14%\n",
      "22\tValidation loss: 0.071830\tBest loss: 0.040332\tAccuracy: 99.06%\n",
      "23\tValidation loss: 0.069619\tBest loss: 0.040332\tAccuracy: 98.79%\n",
      "24\tValidation loss: 0.086642\tBest loss: 0.040332\tAccuracy: 98.71%\n",
      "25\tValidation loss: 0.072563\tBest loss: 0.040332\tAccuracy: 98.83%\n",
      "26\tValidation loss: 0.058974\tBest loss: 0.040332\tAccuracy: 99.06%\n",
      "27\tValidation loss: 0.048388\tBest loss: 0.040332\tAccuracy: 98.98%\n",
      "28\tValidation loss: 0.054847\tBest loss: 0.040332\tAccuracy: 99.06%\n",
      "29\tValidation loss: 0.077242\tBest loss: 0.040332\tAccuracy: 98.91%\n",
      "30\tValidation loss: 0.556978\tBest loss: 0.040332\tAccuracy: 95.54%\n",
      "Early stopping!\n",
      "[CV]  activation=<function elu at 0x7fd9e8a620d0>, n_neurons=140, learning_rate=0.05, batch_norm_momentum=0.99, batch_size=50, total= 1.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed: 355.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.076371\tBest loss: 0.076371\tAccuracy: 97.85%\n",
      "1\tValidation loss: 0.049312\tBest loss: 0.049312\tAccuracy: 98.63%\n",
      "2\tValidation loss: 0.033071\tBest loss: 0.033071\tAccuracy: 98.94%\n",
      "3\tValidation loss: 0.027357\tBest loss: 0.027357\tAccuracy: 99.10%\n",
      "4\tValidation loss: 0.028748\tBest loss: 0.027357\tAccuracy: 99.26%\n",
      "5\tValidation loss: 0.036602\tBest loss: 0.027357\tAccuracy: 98.94%\n",
      "6\tValidation loss: 0.048089\tBest loss: 0.027357\tAccuracy: 98.94%\n",
      "7\tValidation loss: 0.030332\tBest loss: 0.027357\tAccuracy: 99.30%\n",
      "8\tValidation loss: 0.029336\tBest loss: 0.027357\tAccuracy: 99.22%\n",
      "9\tValidation loss: 0.033328\tBest loss: 0.027357\tAccuracy: 99.26%\n",
      "10\tValidation loss: 0.041745\tBest loss: 0.027357\tAccuracy: 98.98%\n",
      "11\tValidation loss: 0.048739\tBest loss: 0.027357\tAccuracy: 98.75%\n",
      "12\tValidation loss: 0.049520\tBest loss: 0.027357\tAccuracy: 98.94%\n",
      "13\tValidation loss: 0.034222\tBest loss: 0.027357\tAccuracy: 99.18%\n",
      "14\tValidation loss: 0.040270\tBest loss: 0.027357\tAccuracy: 99.34%\n",
      "15\tValidation loss: 0.033074\tBest loss: 0.027357\tAccuracy: 99.37%\n",
      "16\tValidation loss: 0.035130\tBest loss: 0.027357\tAccuracy: 99.06%\n",
      "17\tValidation loss: 0.031875\tBest loss: 0.027357\tAccuracy: 99.18%\n",
      "18\tValidation loss: 0.034898\tBest loss: 0.027357\tAccuracy: 99.37%\n",
      "19\tValidation loss: 0.019222\tBest loss: 0.019222\tAccuracy: 99.53%\n",
      "20\tValidation loss: 0.043814\tBest loss: 0.019222\tAccuracy: 99.37%\n",
      "21\tValidation loss: 0.028773\tBest loss: 0.019222\tAccuracy: 99.34%\n",
      "22\tValidation loss: 0.024850\tBest loss: 0.019222\tAccuracy: 99.45%\n",
      "23\tValidation loss: 0.021789\tBest loss: 0.019222\tAccuracy: 99.45%\n",
      "24\tValidation loss: 0.028846\tBest loss: 0.019222\tAccuracy: 99.37%\n",
      "25\tValidation loss: 0.064211\tBest loss: 0.019222\tAccuracy: 98.98%\n",
      "26\tValidation loss: 0.024425\tBest loss: 0.019222\tAccuracy: 99.49%\n",
      "27\tValidation loss: 0.035453\tBest loss: 0.019222\tAccuracy: 99.22%\n",
      "28\tValidation loss: 0.023940\tBest loss: 0.019222\tAccuracy: 99.37%\n",
      "29\tValidation loss: 0.041495\tBest loss: 0.019222\tAccuracy: 99.18%\n",
      "30\tValidation loss: 0.028030\tBest loss: 0.019222\tAccuracy: 99.37%\n",
      "31\tValidation loss: 0.028003\tBest loss: 0.019222\tAccuracy: 99.49%\n",
      "32\tValidation loss: 0.026579\tBest loss: 0.019222\tAccuracy: 99.45%\n",
      "33\tValidation loss: 0.037838\tBest loss: 0.019222\tAccuracy: 98.91%\n",
      "34\tValidation loss: 0.026082\tBest loss: 0.019222\tAccuracy: 99.49%\n",
      "35\tValidation loss: 0.031529\tBest loss: 0.019222\tAccuracy: 99.34%\n",
      "36\tValidation loss: 0.028220\tBest loss: 0.019222\tAccuracy: 99.18%\n",
      "37\tValidation loss: 0.038546\tBest loss: 0.019222\tAccuracy: 99.10%\n",
      "38\tValidation loss: 0.041586\tBest loss: 0.019222\tAccuracy: 98.75%\n",
      "39\tValidation loss: 0.038835\tBest loss: 0.019222\tAccuracy: 99.41%\n",
      "40\tValidation loss: 0.042555\tBest loss: 0.019222\tAccuracy: 99.14%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=DNNClassifier(activation=<function elu at 0x7fd9e8a620d0>,\n",
       "       batch_norm_momentum=None, batch_size=20, dropout_rate=None,\n",
       "       initializer=<function variance_scaling_initializer.<locals>._initializer at 0x7fd9d5e628c8>,\n",
       "       learning_rate=0.01, n_hidden_layers=5, n_neurons=100,\n",
       "       optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "       random_state=42),\n",
       "          fit_params={'y_valid': array([0, 4, ..., 1, 2], dtype=uint8), 'X_valid': array([[ 0.,  0., ...,  0.,  0.],\n",
       "       [ 0.,  0., ...,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0., ...,  0.,  0.],\n",
       "       [ 0.,  0., ...,  0.,  0.]], dtype=float32), 'n_epochs': 1000},\n",
       "          iid=True, n_iter=50, n_jobs=1,\n",
       "          param_distributions={'batch_norm_momentum': [0.9, 0.95, 0.98, 0.99, 0.999], 'n_neurons': [10, 30, 50, 70, 90, 100, 120, 140, 160], 'learning_rate': [0.01, 0.02, 0.05, 0.1], 'activation': [<function relu at 0x7fd9e8a660d0>, <function elu at 0x7fd9e8a620d0>, <function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fd9d19e3bf8>, <function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fd9d19e3a60>], 'batch_size': [10, 50, 100, 500]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_neurons\": [10, 30, 50, 70, 90, 100, 120, 140, 160],\n",
    "    \"batch_size\": [10, 50, 100, 500],\n",
    "    \"learning_rate\": [0.01, 0.02, 0.05, 0.1],\n",
    "    \"activation\": [tf.nn.relu, tf.nn.elu, leaky_relu(alpha=0.01), leaky_relu(alpha=0.1)],\n",
    "    # you could also try exploring different numbers of hidden layers, different optimizers, etc.\n",
    "    #\"n_hidden_layers\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    #\"optimizer_class\": [tf.train.AdamOptimizer, partial(tf.train.MomentumOptimizer, momentum=0.95)],\n",
    "    \"batch_norm_momentum\": [0.9, 0.95, 0.98, 0.99, 0.999],\n",
    "}\n",
    "\n",
    "rnd_search_bn = RandomizedSearchCV(DNNClassifier(random_state=42), param_distribs, n_iter=50,\n",
    "                                   fit_params={\"X_valid\": X_valid1, \"y_valid\": y_valid1, \"n_epochs\": 1000},\n",
    "                                   random_state=42, verbose=2)\n",
    "rnd_search_bn.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': <function tensorflow.python.ops.gen_nn_ops.relu>,\n",
       " 'batch_norm_momentum': 0.98,\n",
       " 'batch_size': 100,\n",
       " 'learning_rate': 0.01,\n",
       " 'n_neurons': 160}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_bn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99396769799571905"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rnd_search_bn.predict(X_test1)\n",
    "accuracy_score(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly better than earlier: 99.4% vs 99.3%. Let's see if dropout can do better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Exercise: is the model overfitting the training set? Try adding dropout to every layer and try again. Does it help?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go back to the best model we trained earlier and see how it performs on the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99914401883158566"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dnn_clf.predict(X_train1)\n",
    "accuracy_score(y_train1, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model performs significantly better on the training set than on the test set (99.91% vs 99.32%), which means it is overfitting the training set. A bit of regularization may help. Let's try adding dropout with a 50% dropout rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.162759\tBest loss: 0.162759\tAccuracy: 95.15%\n",
      "1\tValidation loss: 0.120510\tBest loss: 0.120510\tAccuracy: 96.64%\n",
      "2\tValidation loss: 0.110715\tBest loss: 0.110715\tAccuracy: 96.91%\n",
      "3\tValidation loss: 0.104193\tBest loss: 0.104193\tAccuracy: 97.22%\n",
      "4\tValidation loss: 0.103560\tBest loss: 0.103560\tAccuracy: 97.81%\n",
      "5\tValidation loss: 0.087045\tBest loss: 0.087045\tAccuracy: 97.89%\n",
      "6\tValidation loss: 0.087227\tBest loss: 0.087045\tAccuracy: 97.65%\n",
      "7\tValidation loss: 0.079840\tBest loss: 0.079840\tAccuracy: 98.16%\n",
      "8\tValidation loss: 0.083102\tBest loss: 0.079840\tAccuracy: 97.50%\n",
      "9\tValidation loss: 0.076794\tBest loss: 0.076794\tAccuracy: 98.01%\n",
      "10\tValidation loss: 0.074914\tBest loss: 0.074914\tAccuracy: 97.93%\n",
      "11\tValidation loss: 0.073794\tBest loss: 0.073794\tAccuracy: 98.12%\n",
      "12\tValidation loss: 0.079777\tBest loss: 0.073794\tAccuracy: 97.89%\n",
      "13\tValidation loss: 0.080277\tBest loss: 0.073794\tAccuracy: 97.54%\n",
      "14\tValidation loss: 0.072409\tBest loss: 0.072409\tAccuracy: 98.08%\n",
      "15\tValidation loss: 0.071988\tBest loss: 0.071988\tAccuracy: 98.12%\n",
      "16\tValidation loss: 0.074609\tBest loss: 0.071988\tAccuracy: 97.93%\n",
      "17\tValidation loss: 0.069488\tBest loss: 0.069488\tAccuracy: 98.28%\n",
      "18\tValidation loss: 0.080863\tBest loss: 0.069488\tAccuracy: 98.40%\n",
      "19\tValidation loss: 0.074966\tBest loss: 0.069488\tAccuracy: 98.20%\n",
      "20\tValidation loss: 0.071082\tBest loss: 0.069488\tAccuracy: 98.12%\n",
      "21\tValidation loss: 0.070138\tBest loss: 0.069488\tAccuracy: 98.20%\n",
      "22\tValidation loss: 0.066032\tBest loss: 0.066032\tAccuracy: 98.28%\n",
      "23\tValidation loss: 0.061130\tBest loss: 0.061130\tAccuracy: 98.36%\n",
      "24\tValidation loss: 0.067107\tBest loss: 0.061130\tAccuracy: 98.16%\n",
      "25\tValidation loss: 0.071372\tBest loss: 0.061130\tAccuracy: 98.16%\n",
      "26\tValidation loss: 0.068535\tBest loss: 0.061130\tAccuracy: 98.36%\n",
      "27\tValidation loss: 0.065336\tBest loss: 0.061130\tAccuracy: 98.48%\n",
      "28\tValidation loss: 0.066783\tBest loss: 0.061130\tAccuracy: 98.40%\n",
      "29\tValidation loss: 0.092769\tBest loss: 0.061130\tAccuracy: 97.77%\n",
      "30\tValidation loss: 0.075746\tBest loss: 0.061130\tAccuracy: 98.01%\n",
      "31\tValidation loss: 0.084024\tBest loss: 0.061130\tAccuracy: 97.81%\n",
      "32\tValidation loss: 0.116428\tBest loss: 0.061130\tAccuracy: 98.44%\n",
      "33\tValidation loss: 0.079498\tBest loss: 0.061130\tAccuracy: 97.89%\n",
      "34\tValidation loss: 0.078189\tBest loss: 0.061130\tAccuracy: 97.97%\n",
      "35\tValidation loss: 0.083723\tBest loss: 0.061130\tAccuracy: 97.81%\n",
      "36\tValidation loss: 0.088210\tBest loss: 0.061130\tAccuracy: 97.19%\n",
      "37\tValidation loss: 0.080040\tBest loss: 0.061130\tAccuracy: 97.93%\n",
      "38\tValidation loss: 0.086932\tBest loss: 0.061130\tAccuracy: 97.89%\n",
      "39\tValidation loss: 0.240580\tBest loss: 0.061130\tAccuracy: 91.67%\n",
      "40\tValidation loss: 0.166662\tBest loss: 0.061130\tAccuracy: 94.29%\n",
      "41\tValidation loss: 0.125562\tBest loss: 0.061130\tAccuracy: 97.15%\n",
      "42\tValidation loss: 0.124890\tBest loss: 0.061130\tAccuracy: 95.82%\n",
      "43\tValidation loss: 0.127020\tBest loss: 0.061130\tAccuracy: 96.76%\n",
      "44\tValidation loss: 0.121540\tBest loss: 0.061130\tAccuracy: 96.05%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(activation=<function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fd9b2368d08>,\n",
       "       batch_norm_momentum=None, batch_size=500, dropout_rate=0.5,\n",
       "       initializer=<function variance_scaling_initializer.<locals>._initializer at 0x7fd9d5e628c8>,\n",
       "       learning_rate=0.01, n_hidden_layers=5, n_neurons=90,\n",
       "       optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "       random_state=42)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_clf_dropout = DNNClassifier(activation=leaky_relu(alpha=0.1), batch_size=500, learning_rate=0.01,\n",
    "                                n_neurons=90, random_state=42,\n",
    "                                dropout_rate=0.5)\n",
    "dnn_clf_dropout.fit(X_train1, y_train1, n_epochs=1000, X_valid=X_valid1, y_valid=y_valid1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best params are reached during epoch 23. Dropout somewhat slowed down convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98657326328079398"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dnn_clf_dropout.predict(X_test1)\n",
    "accuracy_score(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are out of luck, dropout does not seem to help either. Let's try tuning the hyperparameters, perhaps we can squeeze a bit more performance out of this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "[CV] dropout_rate=0.5, n_neurons=70, learning_rate=0.01, activation=<function relu at 0x7fd9e8a660d0>, batch_size=100 \n",
      "0\tValidation loss: 0.355079\tBest loss: 0.355079\tAccuracy: 91.44%\n",
      "1\tValidation loss: 0.280624\tBest loss: 0.280624\tAccuracy: 94.10%\n",
      "2\tValidation loss: 0.279819\tBest loss: 0.279819\tAccuracy: 92.77%\n",
      "3\tValidation loss: 0.223614\tBest loss: 0.223614\tAccuracy: 94.10%\n",
      "4\tValidation loss: 0.199802\tBest loss: 0.199802\tAccuracy: 95.11%\n",
      "5\tValidation loss: 0.214481\tBest loss: 0.199802\tAccuracy: 95.47%\n",
      "6\tValidation loss: 0.216195\tBest loss: 0.199802\tAccuracy: 95.78%\n",
      "7\tValidation loss: 0.209172\tBest loss: 0.199802\tAccuracy: 94.80%\n",
      "8\tValidation loss: 0.182841\tBest loss: 0.182841\tAccuracy: 95.70%\n",
      "9\tValidation loss: 0.214252\tBest loss: 0.182841\tAccuracy: 95.82%\n",
      "10\tValidation loss: 0.198762\tBest loss: 0.182841\tAccuracy: 95.62%\n",
      "11\tValidation loss: 0.186415\tBest loss: 0.182841\tAccuracy: 95.82%\n",
      "12\tValidation loss: 0.222924\tBest loss: 0.182841\tAccuracy: 96.05%\n",
      "13\tValidation loss: 0.199636\tBest loss: 0.182841\tAccuracy: 95.97%\n",
      "14\tValidation loss: 0.214436\tBest loss: 0.182841\tAccuracy: 95.97%\n",
      "15\tValidation loss: 0.213507\tBest loss: 0.182841\tAccuracy: 95.47%\n",
      "16\tValidation loss: 0.191497\tBest loss: 0.182841\tAccuracy: 95.78%\n",
      "17\tValidation loss: 0.179503\tBest loss: 0.179503\tAccuracy: 95.93%\n",
      "18\tValidation loss: 0.210343\tBest loss: 0.179503\tAccuracy: 95.74%\n",
      "19\tValidation loss: 0.212626\tBest loss: 0.179503\tAccuracy: 95.27%\n",
      "20\tValidation loss: 0.187110\tBest loss: 0.179503\tAccuracy: 96.09%\n",
      "21\tValidation loss: 0.175171\tBest loss: 0.175171\tAccuracy: 95.78%\n",
      "22\tValidation loss: 0.217172\tBest loss: 0.175171\tAccuracy: 95.66%\n",
      "23\tValidation loss: 0.181060\tBest loss: 0.175171\tAccuracy: 96.44%\n",
      "24\tValidation loss: 0.163630\tBest loss: 0.163630\tAccuracy: 95.93%\n",
      "25\tValidation loss: 0.225873\tBest loss: 0.163630\tAccuracy: 95.58%\n",
      "26\tValidation loss: 0.204975\tBest loss: 0.163630\tAccuracy: 95.66%\n",
      "27\tValidation loss: 0.183588\tBest loss: 0.163630\tAccuracy: 95.97%\n",
      "28\tValidation loss: 0.231080\tBest loss: 0.163630\tAccuracy: 95.11%\n",
      "29\tValidation loss: 0.204342\tBest loss: 0.163630\tAccuracy: 95.74%\n",
      "30\tValidation loss: 0.183963\tBest loss: 0.163630\tAccuracy: 95.93%\n",
      "31\tValidation loss: 0.200975\tBest loss: 0.163630\tAccuracy: 95.23%\n",
      "32\tValidation loss: 0.211165\tBest loss: 0.163630\tAccuracy: 95.23%\n",
      "33\tValidation loss: 0.217777\tBest loss: 0.163630\tAccuracy: 95.07%\n",
      "34\tValidation loss: 0.193184\tBest loss: 0.163630\tAccuracy: 95.39%\n",
      "35\tValidation loss: 0.203809\tBest loss: 0.163630\tAccuracy: 95.58%\n",
      "36\tValidation loss: 0.221673\tBest loss: 0.163630\tAccuracy: 94.57%\n",
      "37\tValidation loss: 0.215750\tBest loss: 0.163630\tAccuracy: 95.39%\n",
      "38\tValidation loss: 0.189653\tBest loss: 0.163630\tAccuracy: 96.09%\n",
      "39\tValidation loss: 0.191333\tBest loss: 0.163630\tAccuracy: 95.19%\n",
      "40\tValidation loss: 0.207714\tBest loss: 0.163630\tAccuracy: 96.01%\n",
      "41\tValidation loss: 0.174490\tBest loss: 0.163630\tAccuracy: 95.39%\n",
      "42\tValidation loss: 0.177445\tBest loss: 0.163630\tAccuracy: 95.82%\n",
      "43\tValidation loss: 0.166708\tBest loss: 0.163630\tAccuracy: 96.09%\n",
      "44\tValidation loss: 0.190829\tBest loss: 0.163630\tAccuracy: 95.70%\n",
      "45\tValidation loss: 0.225985\tBest loss: 0.163630\tAccuracy: 96.25%\n",
      "Early stopping!\n",
      "[CV]  dropout_rate=0.5, n_neurons=70, learning_rate=0.01, activation=<function relu at 0x7fd9e8a660d0>, batch_size=100, total=  39.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   39.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] dropout_rate=0.5, n_neurons=70, learning_rate=0.01, activation=<function relu at 0x7fd9e8a660d0>, batch_size=100 \n",
      "0\tValidation loss: 0.748480\tBest loss: 0.748480\tAccuracy: 57.70%\n",
      "1\tValidation loss: 0.516088\tBest loss: 0.516088\tAccuracy: 78.50%\n",
      "2\tValidation loss: 0.448866\tBest loss: 0.448866\tAccuracy: 78.89%\n",
      "3\tValidation loss: 0.435606\tBest loss: 0.435606\tAccuracy: 78.54%\n",
      "4\tValidation loss: 0.435243\tBest loss: 0.435243\tAccuracy: 79.40%\n",
      "5\tValidation loss: 0.450605\tBest loss: 0.435243\tAccuracy: 78.42%\n",
      "6\tValidation loss: 0.430706\tBest loss: 0.430706\tAccuracy: 78.62%\n",
      "7\tValidation loss: 0.449289\tBest loss: 0.430706\tAccuracy: 78.30%\n",
      "8\tValidation loss: 0.413226\tBest loss: 0.413226\tAccuracy: 79.05%\n",
      "9\tValidation loss: 0.436053\tBest loss: 0.413226\tAccuracy: 78.46%\n",
      "10\tValidation loss: 0.459932\tBest loss: 0.413226\tAccuracy: 79.24%\n",
      "11\tValidation loss: 0.424138\tBest loss: 0.413226\tAccuracy: 79.24%\n",
      "12\tValidation loss: 0.409538\tBest loss: 0.409538\tAccuracy: 79.55%\n",
      "13\tValidation loss: 0.416324\tBest loss: 0.409538\tAccuracy: 75.41%\n",
      "14\tValidation loss: 0.440273\tBest loss: 0.409538\tAccuracy: 78.46%\n",
      "15\tValidation loss: 0.435736\tBest loss: 0.409538\tAccuracy: 79.05%\n",
      "16\tValidation loss: 0.428412\tBest loss: 0.409538\tAccuracy: 79.20%\n",
      "17\tValidation loss: 0.450156\tBest loss: 0.409538\tAccuracy: 80.02%\n",
      "18\tValidation loss: 0.421057\tBest loss: 0.409538\tAccuracy: 79.24%\n",
      "19\tValidation loss: 0.442284\tBest loss: 0.409538\tAccuracy: 79.01%\n",
      "20\tValidation loss: 0.426907\tBest loss: 0.409538\tAccuracy: 79.16%\n",
      "21\tValidation loss: 0.439567\tBest loss: 0.409538\tAccuracy: 79.05%\n",
      "22\tValidation loss: 0.452601\tBest loss: 0.409538\tAccuracy: 79.67%\n",
      "23\tValidation loss: 0.424887\tBest loss: 0.409538\tAccuracy: 79.09%\n",
      "24\tValidation loss: 0.441096\tBest loss: 0.409538\tAccuracy: 78.97%\n",
      "25\tValidation loss: 0.417390\tBest loss: 0.409538\tAccuracy: 78.89%\n",
      "26\tValidation loss: 0.418550\tBest loss: 0.409538\tAccuracy: 79.05%\n",
      "27\tValidation loss: 0.426065\tBest loss: 0.409538\tAccuracy: 78.66%\n",
      "28\tValidation loss: 0.413968\tBest loss: 0.409538\tAccuracy: 79.36%\n",
      "29\tValidation loss: 0.425434\tBest loss: 0.409538\tAccuracy: 79.24%\n",
      "30\tValidation loss: 0.455391\tBest loss: 0.409538\tAccuracy: 74.71%\n",
      "31\tValidation loss: 0.429498\tBest loss: 0.409538\tAccuracy: 79.20%\n",
      "32\tValidation loss: 0.427383\tBest loss: 0.409538\tAccuracy: 79.52%\n",
      "33\tValidation loss: 0.422621\tBest loss: 0.409538\tAccuracy: 78.62%\n",
      "Early stopping!\n",
      "[CV]  dropout_rate=0.5, n_neurons=70, learning_rate=0.01, activation=<function relu at 0x7fd9e8a660d0>, batch_size=100, total=  27.4s\n",
      "[CV] dropout_rate=0.5, n_neurons=70, learning_rate=0.01, activation=<function relu at 0x7fd9e8a660d0>, batch_size=100 \n",
      "0\tValidation loss: 0.497714\tBest loss: 0.497714\tAccuracy: 86.71%\n",
      "1\tValidation loss: 0.248258\tBest loss: 0.248258\tAccuracy: 93.51%\n",
      "2\tValidation loss: 0.279785\tBest loss: 0.248258\tAccuracy: 93.71%\n",
      "3\tValidation loss: 0.248663\tBest loss: 0.248258\tAccuracy: 94.61%\n",
      "4\tValidation loss: 0.269139\tBest loss: 0.248258\tAccuracy: 94.76%\n",
      "5\tValidation loss: 0.188808\tBest loss: 0.188808\tAccuracy: 95.39%\n",
      "6\tValidation loss: 0.196049\tBest loss: 0.188808\tAccuracy: 95.58%\n",
      "7\tValidation loss: 0.204966\tBest loss: 0.188808\tAccuracy: 95.15%\n",
      "8\tValidation loss: 0.238414\tBest loss: 0.188808\tAccuracy: 94.61%\n",
      "9\tValidation loss: 0.192095\tBest loss: 0.188808\tAccuracy: 95.97%\n",
      "[...and much later...]\n",
      "19\tValidation loss: 1.939112\tBest loss: 1.619874\tAccuracy: 22.01%\n",
      "20\tValidation loss: 1.825761\tBest loss: 1.619874\tAccuracy: 19.27%\n",
      "21\tValidation loss: 1.732937\tBest loss: 1.619874\tAccuracy: 22.01%\n",
      "22\tValidation loss: 1.832995\tBest loss: 1.619874\tAccuracy: 20.91%\n",
      "23\tValidation loss: 1.659557\tBest loss: 1.619874\tAccuracy: 20.91%\n",
      "24\tValidation loss: 1.828380\tBest loss: 1.619874\tAccuracy: 18.73%\n",
      "25\tValidation loss: 1.719589\tBest loss: 1.619874\tAccuracy: 22.01%\n",
      "26\tValidation loss: 1.842429\tBest loss: 1.619874\tAccuracy: 18.73%\n",
      "27\tValidation loss: 1.717596\tBest loss: 1.619874\tAccuracy: 19.27%\n",
      "28\tValidation loss: 1.863441\tBest loss: 1.619874\tAccuracy: 19.08%\n",
      "29\tValidation loss: 1.952335\tBest loss: 1.619874\tAccuracy: 19.08%\n",
      "30\tValidation loss: 1.853776\tBest loss: 1.619874\tAccuracy: 20.91%\n",
      "31\tValidation loss: 1.894134\tBest loss: 1.619874\tAccuracy: 22.01%\n",
      "32\tValidation loss: 1.711688\tBest loss: 1.619874\tAccuracy: 19.08%\n",
      "33\tValidation loss: 1.651240\tBest loss: 1.619874\tAccuracy: 18.73%\n",
      "34\tValidation loss: 1.760639\tBest loss: 1.619874\tAccuracy: 20.91%\n",
      "35\tValidation loss: 1.667938\tBest loss: 1.619874\tAccuracy: 22.01%\n",
      "36\tValidation loss: 1.641116\tBest loss: 1.619874\tAccuracy: 20.91%\n",
      "37\tValidation loss: 1.694960\tBest loss: 1.619874\tAccuracy: 19.08%\n",
      "38\tValidation loss: 1.816517\tBest loss: 1.619874\tAccuracy: 18.73%\n",
      "39\tValidation loss: 1.647246\tBest loss: 1.619874\tAccuracy: 18.73%\n",
      "Early stopping!\n",
      "[CV]  dropout_rate=0.5, n_neurons=140, learning_rate=0.05, activation=<function elu at 0x7fd9e8a620d0>, batch_size=100, total= 1.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 150 out of 150 | elapsed: 130.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.165751\tBest loss: 0.165751\tAccuracy: 95.47%\n",
      "1\tValidation loss: 0.111834\tBest loss: 0.111834\tAccuracy: 96.99%\n",
      "2\tValidation loss: 0.102867\tBest loss: 0.102867\tAccuracy: 96.83%\n",
      "3\tValidation loss: 0.089197\tBest loss: 0.089197\tAccuracy: 97.85%\n",
      "4\tValidation loss: 0.093953\tBest loss: 0.089197\tAccuracy: 97.77%\n",
      "5\tValidation loss: 0.079498\tBest loss: 0.079498\tAccuracy: 98.08%\n",
      "6\tValidation loss: 0.081214\tBest loss: 0.079498\tAccuracy: 98.01%\n",
      "7\tValidation loss: 0.086096\tBest loss: 0.079498\tAccuracy: 97.77%\n",
      "8\tValidation loss: 0.074422\tBest loss: 0.074422\tAccuracy: 97.73%\n",
      "9\tValidation loss: 0.079650\tBest loss: 0.074422\tAccuracy: 97.89%\n",
      "10\tValidation loss: 0.077278\tBest loss: 0.074422\tAccuracy: 97.77%\n",
      "11\tValidation loss: 0.077608\tBest loss: 0.074422\tAccuracy: 98.24%\n",
      "12\tValidation loss: 0.074337\tBest loss: 0.074337\tAccuracy: 98.05%\n",
      "13\tValidation loss: 0.066028\tBest loss: 0.066028\tAccuracy: 98.28%\n",
      "14\tValidation loss: 0.072845\tBest loss: 0.066028\tAccuracy: 98.16%\n",
      "15\tValidation loss: 0.066652\tBest loss: 0.066028\tAccuracy: 98.05%\n",
      "16\tValidation loss: 0.065729\tBest loss: 0.065729\tAccuracy: 98.16%\n",
      "17\tValidation loss: 0.061191\tBest loss: 0.061191\tAccuracy: 98.51%\n",
      "18\tValidation loss: 0.062528\tBest loss: 0.061191\tAccuracy: 98.44%\n",
      "19\tValidation loss: 0.065407\tBest loss: 0.061191\tAccuracy: 98.36%\n",
      "20\tValidation loss: 0.065273\tBest loss: 0.061191\tAccuracy: 98.44%\n",
      "21\tValidation loss: 0.061035\tBest loss: 0.061035\tAccuracy: 98.40%\n",
      "22\tValidation loss: 0.056312\tBest loss: 0.056312\tAccuracy: 98.59%\n",
      "23\tValidation loss: 0.069074\tBest loss: 0.056312\tAccuracy: 98.40%\n",
      "24\tValidation loss: 0.057482\tBest loss: 0.056312\tAccuracy: 98.51%\n",
      "25\tValidation loss: 0.068342\tBest loss: 0.056312\tAccuracy: 98.44%\n",
      "26\tValidation loss: 0.063494\tBest loss: 0.056312\tAccuracy: 98.48%\n",
      "27\tValidation loss: 0.057257\tBest loss: 0.056312\tAccuracy: 98.51%\n",
      "28\tValidation loss: 0.058659\tBest loss: 0.056312\tAccuracy: 98.59%\n",
      "29\tValidation loss: 0.059009\tBest loss: 0.056312\tAccuracy: 98.48%\n",
      "30\tValidation loss: 0.058227\tBest loss: 0.056312\tAccuracy: 98.55%\n",
      "31\tValidation loss: 0.062198\tBest loss: 0.056312\tAccuracy: 98.44%\n",
      "32\tValidation loss: 0.058043\tBest loss: 0.056312\tAccuracy: 98.40%\n",
      "33\tValidation loss: 0.055970\tBest loss: 0.055970\tAccuracy: 98.51%\n",
      "34\tValidation loss: 0.060111\tBest loss: 0.055970\tAccuracy: 98.67%\n",
      "35\tValidation loss: 0.058786\tBest loss: 0.055970\tAccuracy: 98.44%\n",
      "36\tValidation loss: 0.059944\tBest loss: 0.055970\tAccuracy: 98.32%\n",
      "37\tValidation loss: 0.058087\tBest loss: 0.055970\tAccuracy: 98.63%\n",
      "38\tValidation loss: 0.063003\tBest loss: 0.055970\tAccuracy: 98.36%\n",
      "39\tValidation loss: 0.052073\tBest loss: 0.052073\tAccuracy: 98.67%\n",
      "40\tValidation loss: 0.058115\tBest loss: 0.052073\tAccuracy: 98.40%\n",
      "41\tValidation loss: 0.059997\tBest loss: 0.052073\tAccuracy: 98.63%\n",
      "42\tValidation loss: 0.052416\tBest loss: 0.052073\tAccuracy: 98.75%\n",
      "43\tValidation loss: 0.053840\tBest loss: 0.052073\tAccuracy: 98.59%\n",
      "44\tValidation loss: 0.054563\tBest loss: 0.052073\tAccuracy: 98.67%\n",
      "45\tValidation loss: 0.049410\tBest loss: 0.049410\tAccuracy: 98.55%\n",
      "46\tValidation loss: 0.057060\tBest loss: 0.049410\tAccuracy: 98.24%\n",
      "47\tValidation loss: 0.062434\tBest loss: 0.049410\tAccuracy: 98.48%\n",
      "48\tValidation loss: 0.054523\tBest loss: 0.049410\tAccuracy: 98.59%\n",
      "49\tValidation loss: 0.052774\tBest loss: 0.049410\tAccuracy: 98.36%\n",
      "50\tValidation loss: 0.056562\tBest loss: 0.049410\tAccuracy: 98.32%\n",
      "51\tValidation loss: 0.060280\tBest loss: 0.049410\tAccuracy: 98.51%\n",
      "52\tValidation loss: 0.055685\tBest loss: 0.049410\tAccuracy: 98.55%\n",
      "53\tValidation loss: 0.056077\tBest loss: 0.049410\tAccuracy: 98.44%\n",
      "54\tValidation loss: 0.057951\tBest loss: 0.049410\tAccuracy: 98.44%\n",
      "55\tValidation loss: 0.056315\tBest loss: 0.049410\tAccuracy: 98.75%\n",
      "56\tValidation loss: 0.055744\tBest loss: 0.049410\tAccuracy: 98.55%\n",
      "57\tValidation loss: 0.054228\tBest loss: 0.049410\tAccuracy: 98.48%\n",
      "58\tValidation loss: 0.057836\tBest loss: 0.049410\tAccuracy: 98.71%\n",
      "59\tValidation loss: 0.053361\tBest loss: 0.049410\tAccuracy: 98.71%\n",
      "60\tValidation loss: 0.056389\tBest loss: 0.049410\tAccuracy: 98.48%\n",
      "61\tValidation loss: 0.061350\tBest loss: 0.049410\tAccuracy: 98.48%\n",
      "62\tValidation loss: 0.052135\tBest loss: 0.049410\tAccuracy: 98.67%\n",
      "63\tValidation loss: 0.053853\tBest loss: 0.049410\tAccuracy: 98.48%\n",
      "64\tValidation loss: 0.056641\tBest loss: 0.049410\tAccuracy: 98.71%\n",
      "65\tValidation loss: 0.052790\tBest loss: 0.049410\tAccuracy: 98.63%\n",
      "66\tValidation loss: 0.053514\tBest loss: 0.049410\tAccuracy: 98.44%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=None, error_score='raise',\n",
       "          estimator=DNNClassifier(activation=<function elu at 0x7fd9e8a620d0>,\n",
       "       batch_norm_momentum=None, batch_size=20, dropout_rate=None,\n",
       "       initializer=<function variance_scaling_initializer.<locals>._initializer at 0x7fd9d5e628c8>,\n",
       "       learning_rate=0.01, n_hidden_layers=5, n_neurons=100,\n",
       "       optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "       random_state=42),\n",
       "          fit_params={'y_valid': array([0, 4, ..., 1, 2], dtype=uint8), 'X_valid': array([[ 0.,  0., ...,  0.,  0.],\n",
       "       [ 0.,  0., ...,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0., ...,  0.,  0.],\n",
       "       [ 0.,  0., ...,  0.,  0.]], dtype=float32), 'n_epochs': 1000},\n",
       "          iid=True, n_iter=50, n_jobs=1,\n",
       "          param_distributions={'dropout_rate': [0.2, 0.3, 0.4, 0.5, 0.6], 'n_neurons': [10, 30, 50, 70, 90, 100, 120, 140, 160], 'learning_rate': [0.01, 0.02, 0.05, 0.1], 'activation': [<function relu at 0x7fd9e8a660d0>, <function elu at 0x7fd9e8a620d0>, <function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fd9b2368950>, <function leaky_relu.<locals>.parametrized_leaky_relu at 0x7fd9b23687b8>], 'batch_size': [10, 50, 100, 500]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score=True, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_neurons\": [10, 30, 50, 70, 90, 100, 120, 140, 160],\n",
    "    \"batch_size\": [10, 50, 100, 500],\n",
    "    \"learning_rate\": [0.01, 0.02, 0.05, 0.1],\n",
    "    \"activation\": [tf.nn.relu, tf.nn.elu, leaky_relu(alpha=0.01), leaky_relu(alpha=0.1)],\n",
    "    # you could also try exploring different numbers of hidden layers, different optimizers, etc.\n",
    "    #\"n_hidden_layers\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    #\"optimizer_class\": [tf.train.AdamOptimizer, partial(tf.train.MomentumOptimizer, momentum=0.95)],\n",
    "    \"dropout_rate\": [0.2, 0.3, 0.4, 0.5, 0.6],\n",
    "}\n",
    "\n",
    "rnd_search_dropout = RandomizedSearchCV(DNNClassifier(random_state=42), param_distribs, n_iter=50,\n",
    "                                        fit_params={\"X_valid\": X_valid1, \"y_valid\": y_valid1, \"n_epochs\": 1000},\n",
    "                                        random_state=42, verbose=2)\n",
    "rnd_search_dropout.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': <function __main__.leaky_relu.<locals>.parametrized_leaky_relu>,\n",
       " 'batch_size': 500,\n",
       " 'dropout_rate': 0.4,\n",
       " 'learning_rate': 0.01,\n",
       " 'n_neurons': 50}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_dropout.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98812998637867289"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rnd_search_dropout.predict(X_test1)\n",
    "accuracy_score(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh well, dropout did not improve the model. Better luck next time! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But that's okay, we have ourselves a nice DNN that achieves 99.40% accuracy on the test set using Batch Normalization, or 99.32% without BN. Let's see if some of this expertise on digits 0 to 4 can be transferred to the task of classifying digits 5 to 9. For the sake of simplicity we will reuse the DNN without BN, since it is almost as good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 9. Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Exercise: create a new DNN that reuses all the pretrained hidden layers of the previous model, freezes them, and replaces the softmax output layer with a new one._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the best model's graph and get a handle on all the important operations we will need. Note that instead of creating a new softmax output layer, we will just reuse the existing one (since it has the same number of outputs as the existing one). We will reinitialize its parameters before training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "restore_saver = tf.train.import_meta_graph(\"./my_best_mnist_model_0_to_4.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "loss = tf.get_default_graph().get_tensor_by_name(\"loss:0\")\n",
    "Y_proba = tf.get_default_graph().get_tensor_by_name(\"Y_proba:0\")\n",
    "logits = Y_proba.op.inputs[0]\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name(\"accuracy:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To freeze the lower layers, we will exclude their variables from the optimizer's list of trainable variables, keeping only the output layer's trainable variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam2\")\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "five_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Exercise: train this new DNN on digits 5 to 9, using only 100 images per digit, and time how long it takes. Despite this small number of examples, can you achieve high precision?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the training, validation and test sets. We need to subtract 5 from the labels because TensorFlow expects integers from 0 to `n_classes-1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train2_full = mnist.train.images[mnist.train.labels >= 5]\n",
    "y_train2_full = mnist.train.labels[mnist.train.labels >= 5] - 5\n",
    "X_valid2_full = mnist.validation.images[mnist.validation.labels >= 5]\n",
    "y_valid2_full = mnist.validation.labels[mnist.validation.labels >= 5] - 5\n",
    "X_test2 = mnist.test.images[mnist.test.labels >= 5]\n",
    "y_test2 = mnist.test.labels[mnist.test.labels >= 5] - 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, for the purpose of this exercise, we want to keep only 100 instances per class in the training set (and let's keep only 30 instances per class in the validation set). Let's create a small function to do that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_n_instances_per_class(X, y, n=100):\n",
    "    Xs, ys = [], []\n",
    "    for label in np.unique(y):\n",
    "        idx = (y == label)\n",
    "        Xc = X[idx][:n]\n",
    "        yc = y[idx][:n]\n",
    "        Xs.append(Xc)\n",
    "        ys.append(yc)\n",
    "    return np.concatenate(Xs), np.concatenate(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train2, y_train2 = sample_n_instances_per_class(X_train2_full, y_train2_full, n=100)\n",
    "X_valid2, y_valid2 = sample_n_instances_per_class(X_valid2_full, y_valid2_full, n=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train the model. This is the same training code as earlier, using early stopping, except for the initialization: we first initialize all the variables, then we restore the best model trained earlier (on digits 0 to 4), and finally we reinitialize the output layer variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_best_mnist_model_0_to_4\n",
      "0\tValidation loss: 0.967851\tBest loss: 0.967851\tAccuracy: 67.33%\n",
      "1\tValidation loss: 0.861747\tBest loss: 0.861747\tAccuracy: 71.33%\n",
      "2\tValidation loss: 0.777535\tBest loss: 0.777535\tAccuracy: 72.00%\n",
      "3\tValidation loss: 0.699915\tBest loss: 0.699915\tAccuracy: 75.33%\n",
      "4\tValidation loss: 0.786714\tBest loss: 0.699915\tAccuracy: 78.00%\n",
      "5\tValidation loss: 0.735406\tBest loss: 0.699915\tAccuracy: 76.67%\n",
      "6\tValidation loss: 0.732264\tBest loss: 0.699915\tAccuracy: 78.00%\n",
      "7\tValidation loss: 0.691741\tBest loss: 0.691741\tAccuracy: 76.00%\n",
      "8\tValidation loss: 0.672757\tBest loss: 0.672757\tAccuracy: 80.00%\n",
      "9\tValidation loss: 0.666520\tBest loss: 0.666520\tAccuracy: 80.00%\n",
      "10\tValidation loss: 0.639375\tBest loss: 0.639375\tAccuracy: 81.33%\n",
      "11\tValidation loss: 0.645089\tBest loss: 0.639375\tAccuracy: 82.00%\n",
      "12\tValidation loss: 0.646768\tBest loss: 0.639375\tAccuracy: 80.00%\n",
      "13\tValidation loss: 0.623784\tBest loss: 0.623784\tAccuracy: 82.67%\n",
      "14\tValidation loss: 0.663026\tBest loss: 0.623784\tAccuracy: 80.00%\n",
      "15\tValidation loss: 0.704513\tBest loss: 0.623784\tAccuracy: 79.33%\n",
      "16\tValidation loss: 0.684003\tBest loss: 0.623784\tAccuracy: 79.33%\n",
      "17\tValidation loss: 0.658575\tBest loss: 0.623784\tAccuracy: 82.67%\n",
      "18\tValidation loss: 0.669875\tBest loss: 0.623784\tAccuracy: 79.33%\n",
      "19\tValidation loss: 0.664581\tBest loss: 0.623784\tAccuracy: 78.67%\n",
      "20\tValidation loss: 0.653490\tBest loss: 0.623784\tAccuracy: 80.00%\n",
      "21\tValidation loss: 0.707304\tBest loss: 0.623784\tAccuracy: 79.33%\n",
      "22\tValidation loss: 0.706012\tBest loss: 0.623784\tAccuracy: 80.67%\n",
      "23\tValidation loss: 0.681227\tBest loss: 0.623784\tAccuracy: 78.67%\n",
      "24\tValidation loss: 0.786823\tBest loss: 0.623784\tAccuracy: 78.00%\n",
      "25\tValidation loss: 0.686110\tBest loss: 0.623784\tAccuracy: 79.33%\n",
      "26\tValidation loss: 0.675166\tBest loss: 0.623784\tAccuracy: 82.67%\n",
      "27\tValidation loss: 0.667711\tBest loss: 0.623784\tAccuracy: 82.67%\n",
      "28\tValidation loss: 0.612220\tBest loss: 0.612220\tAccuracy: 83.33%\n",
      "29\tValidation loss: 0.701196\tBest loss: 0.612220\tAccuracy: 78.00%\n",
      "30\tValidation loss: 0.687806\tBest loss: 0.612220\tAccuracy: 81.33%\n",
      "31\tValidation loss: 0.776596\tBest loss: 0.612220\tAccuracy: 79.33%\n",
      "32\tValidation loss: 0.674172\tBest loss: 0.612220\tAccuracy: 80.00%\n",
      "33\tValidation loss: 0.719044\tBest loss: 0.612220\tAccuracy: 83.33%\n",
      "34\tValidation loss: 0.856403\tBest loss: 0.612220\tAccuracy: 74.00%\n",
      "35\tValidation loss: 0.744627\tBest loss: 0.612220\tAccuracy: 80.00%\n",
      "36\tValidation loss: 0.779348\tBest loss: 0.612220\tAccuracy: 78.00%\n",
      "37\tValidation loss: 0.763777\tBest loss: 0.612220\tAccuracy: 78.00%\n",
      "38\tValidation loss: 0.727376\tBest loss: 0.612220\tAccuracy: 78.00%\n",
      "39\tValidation loss: 0.823514\tBest loss: 0.612220\tAccuracy: 78.00%\n",
      "40\tValidation loss: 0.725053\tBest loss: 0.612220\tAccuracy: 80.67%\n",
      "41\tValidation loss: 0.678497\tBest loss: 0.612220\tAccuracy: 80.67%\n",
      "42\tValidation loss: 0.709977\tBest loss: 0.612220\tAccuracy: 80.67%\n",
      "43\tValidation loss: 0.737200\tBest loss: 0.612220\tAccuracy: 77.33%\n",
      "44\tValidation loss: 0.757937\tBest loss: 0.612220\tAccuracy: 77.33%\n",
      "45\tValidation loss: 0.732024\tBest loss: 0.612220\tAccuracy: 80.00%\n",
      "46\tValidation loss: 0.756428\tBest loss: 0.612220\tAccuracy: 80.67%\n",
      "47\tValidation loss: 0.757610\tBest loss: 0.612220\tAccuracy: 78.67%\n",
      "48\tValidation loss: 0.844137\tBest loss: 0.612220\tAccuracy: 80.00%\n",
      "Early stopping!\n",
      "Total training time: 2.3s\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_five_frozen\n",
      "Final test accuracy: 76.30%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_best_mnist_model_0_to_4\")\n",
    "    for var in output_layer_vars:\n",
    "        var.initializer.run()\n",
    "\n",
    "    t0 = time.time()\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = five_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(\"Total training time: {:.1f}s\".format(t1 - t0))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    five_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well that's not a great accuracy, is it? Of course with such a tiny training set, and with only one layer to tweak, we should not expect miracles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Exercise: try caching the frozen layers, and train the model again: how much faster is it now?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by getting a handle on the output of the last frozen layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden5_out = tf.get_default_graph().get_tensor_by_name(\"hidden5_out:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train the model using roughly the same code as earlier. The difference is that we compute the output of the top frozen layer at the beginning (both for the training set and the validation set), and we cache it. This makes training roughly 1.5 to 3 times faster in this example (this may vary greatly, depending on your system): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_best_mnist_model_0_to_4\n",
      "0\tValidation loss: 1.109053\tBest loss: 1.109053\tAccuracy: 60.67%\n",
      "1\tValidation loss: 0.813156\tBest loss: 0.813156\tAccuracy: 72.00%\n",
      "2\tValidation loss: 0.755930\tBest loss: 0.755930\tAccuracy: 76.67%\n",
      "3\tValidation loss: 0.744004\tBest loss: 0.744004\tAccuracy: 74.67%\n",
      "4\tValidation loss: 0.685080\tBest loss: 0.685080\tAccuracy: 78.00%\n",
      "5\tValidation loss: 0.702316\tBest loss: 0.685080\tAccuracy: 78.00%\n",
      "6\tValidation loss: 0.646487\tBest loss: 0.646487\tAccuracy: 80.00%\n",
      "7\tValidation loss: 0.686437\tBest loss: 0.646487\tAccuracy: 79.33%\n",
      "8\tValidation loss: 0.750047\tBest loss: 0.646487\tAccuracy: 79.33%\n",
      "9\tValidation loss: 0.688554\tBest loss: 0.646487\tAccuracy: 79.33%\n",
      "10\tValidation loss: 0.785184\tBest loss: 0.646487\tAccuracy: 78.67%\n",
      "11\tValidation loss: 0.634506\tBest loss: 0.634506\tAccuracy: 80.67%\n",
      "12\tValidation loss: 0.656797\tBest loss: 0.634506\tAccuracy: 81.33%\n",
      "13\tValidation loss: 0.645497\tBest loss: 0.634506\tAccuracy: 81.33%\n",
      "14\tValidation loss: 0.618038\tBest loss: 0.618038\tAccuracy: 83.33%\n",
      "15\tValidation loss: 0.641752\tBest loss: 0.618038\tAccuracy: 78.67%\n",
      "16\tValidation loss: 0.645671\tBest loss: 0.618038\tAccuracy: 80.67%\n",
      "17\tValidation loss: 0.654640\tBest loss: 0.618038\tAccuracy: 82.00%\n",
      "18\tValidation loss: 0.670569\tBest loss: 0.618038\tAccuracy: 79.33%\n",
      "19\tValidation loss: 0.670985\tBest loss: 0.618038\tAccuracy: 82.00%\n",
      "20\tValidation loss: 0.659538\tBest loss: 0.618038\tAccuracy: 82.67%\n",
      "21\tValidation loss: 0.622648\tBest loss: 0.618038\tAccuracy: 83.33%\n",
      "22\tValidation loss: 0.736155\tBest loss: 0.618038\tAccuracy: 79.33%\n",
      "23\tValidation loss: 0.739367\tBest loss: 0.618038\tAccuracy: 76.67%\n",
      "24\tValidation loss: 0.699710\tBest loss: 0.618038\tAccuracy: 78.00%\n",
      "25\tValidation loss: 0.709630\tBest loss: 0.618038\tAccuracy: 81.33%\n",
      "26\tValidation loss: 0.692474\tBest loss: 0.618038\tAccuracy: 79.33%\n",
      "27\tValidation loss: 0.807931\tBest loss: 0.618038\tAccuracy: 77.33%\n",
      "28\tValidation loss: 0.676134\tBest loss: 0.618038\tAccuracy: 82.00%\n",
      "29\tValidation loss: 0.738905\tBest loss: 0.618038\tAccuracy: 79.33%\n",
      "30\tValidation loss: 0.664826\tBest loss: 0.618038\tAccuracy: 81.33%\n",
      "31\tValidation loss: 0.694714\tBest loss: 0.618038\tAccuracy: 80.00%\n",
      "32\tValidation loss: 0.739238\tBest loss: 0.618038\tAccuracy: 83.33%\n",
      "33\tValidation loss: 0.697210\tBest loss: 0.618038\tAccuracy: 80.00%\n",
      "34\tValidation loss: 0.817373\tBest loss: 0.618038\tAccuracy: 79.33%\n",
      "Early stopping!\n",
      "Total training time: 0.9s\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_five_frozen\n",
      "Final test accuracy: 76.51%\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_best_mnist_model_0_to_4\")\n",
    "    for var in output_layer_vars:\n",
    "        var.initializer.run()\n",
    "\n",
    "    t0 = time.time()\n",
    "    \n",
    "    hidden5_train = hidden5_out.eval(feed_dict={X: X_train2, y: y_train2})\n",
    "    hidden5_valid = hidden5_out.eval(feed_dict={X: X_valid2, y: y_valid2})\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            h5_batch, y_batch = hidden5_train[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={hidden5_out: h5_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={hidden5_out: hidden5_valid, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = five_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(\"Total training time: {:.1f}s\".format(t1 - t0))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    five_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_five_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Exercise: try again reusing just four hidden layers instead of five. Can you achieve a higher precision?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the best model again, but this time we will create a new softmax output layer on top of the 4th hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_outputs = 5\n",
    "\n",
    "restore_saver = tf.train.import_meta_graph(\"./my_best_mnist_model_0_to_4.meta\")\n",
    "\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "hidden4_out = tf.get_default_graph().get_tensor_by_name(\"hidden4_out:0\")\n",
    "logits = tf.layers.dense(hidden4_out, n_outputs, kernel_initializer=he_init, name=\"new_logits\")\n",
    "Y_proba = tf.nn.softmax(logits)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's create the training operation. We want to freeze all the layers except for the new output layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"new_logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam2\")\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer_vars)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "four_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And once again we train the model with the same code as earlier. Note: we could of course write a function once and use it multiple times, rather than copying almost the same training code over and over again, but as we keep tweaking the code slightly, the function would need multiple arguments and `if` statements, and it would have to be at the beginning of the notebook, where it would not make much sense to readers. In short it would be very confusing, so we're better off with copy & paste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_best_mnist_model_0_to_4\n",
      "0\tValidation loss: 0.923460\tBest loss: 0.923460\tAccuracy: 69.33%\n",
      "1\tValidation loss: 0.796192\tBest loss: 0.796192\tAccuracy: 77.33%\n",
      "2\tValidation loss: 0.812068\tBest loss: 0.796192\tAccuracy: 78.67%\n",
      "3\tValidation loss: 0.697938\tBest loss: 0.697938\tAccuracy: 80.67%\n",
      "4\tValidation loss: 0.877122\tBest loss: 0.697938\tAccuracy: 74.67%\n",
      "5\tValidation loss: 0.708524\tBest loss: 0.697938\tAccuracy: 81.33%\n",
      "6\tValidation loss: 0.689500\tBest loss: 0.689500\tAccuracy: 84.00%\n",
      "7\tValidation loss: 0.758315\tBest loss: 0.689500\tAccuracy: 81.33%\n",
      "8\tValidation loss: 0.711138\tBest loss: 0.689500\tAccuracy: 78.67%\n",
      "9\tValidation loss: 0.687304\tBest loss: 0.687304\tAccuracy: 81.33%\n",
      "10\tValidation loss: 0.639222\tBest loss: 0.639222\tAccuracy: 81.33%\n",
      "11\tValidation loss: 0.716750\tBest loss: 0.639222\tAccuracy: 82.67%\n",
      "12\tValidation loss: 0.693442\tBest loss: 0.639222\tAccuracy: 80.67%\n",
      "13\tValidation loss: 0.727682\tBest loss: 0.639222\tAccuracy: 84.00%\n",
      "14\tValidation loss: 0.637289\tBest loss: 0.637289\tAccuracy: 84.67%\n",
      "15\tValidation loss: 0.741304\tBest loss: 0.637289\tAccuracy: 83.33%\n",
      "16\tValidation loss: 0.651895\tBest loss: 0.637289\tAccuracy: 82.67%\n",
      "17\tValidation loss: 0.641192\tBest loss: 0.637289\tAccuracy: 80.67%\n",
      "18\tValidation loss: 0.690386\tBest loss: 0.637289\tAccuracy: 80.67%\n",
      "19\tValidation loss: 0.648541\tBest loss: 0.637289\tAccuracy: 82.67%\n",
      "20\tValidation loss: 0.779663\tBest loss: 0.637289\tAccuracy: 83.33%\n",
      "21\tValidation loss: 0.768834\tBest loss: 0.637289\tAccuracy: 82.67%\n",
      "22\tValidation loss: 0.706279\tBest loss: 0.637289\tAccuracy: 82.67%\n",
      "23\tValidation loss: 0.745840\tBest loss: 0.637289\tAccuracy: 82.00%\n",
      "24\tValidation loss: 0.740068\tBest loss: 0.637289\tAccuracy: 83.33%\n",
      "25\tValidation loss: 0.604927\tBest loss: 0.604927\tAccuracy: 84.67%\n",
      "26\tValidation loss: 0.635410\tBest loss: 0.604927\tAccuracy: 82.00%\n",
      "27\tValidation loss: 0.776003\tBest loss: 0.604927\tAccuracy: 82.67%\n",
      "28\tValidation loss: 0.621502\tBest loss: 0.604927\tAccuracy: 82.00%\n",
      "29\tValidation loss: 0.695963\tBest loss: 0.604927\tAccuracy: 83.33%\n",
      "30\tValidation loss: 0.668194\tBest loss: 0.604927\tAccuracy: 84.67%\n",
      "31\tValidation loss: 0.768975\tBest loss: 0.604927\tAccuracy: 82.67%\n",
      "32\tValidation loss: 0.594731\tBest loss: 0.594731\tAccuracy: 84.00%\n",
      "33\tValidation loss: 0.665088\tBest loss: 0.594731\tAccuracy: 84.00%\n",
      "34\tValidation loss: 0.716284\tBest loss: 0.594731\tAccuracy: 81.33%\n",
      "35\tValidation loss: 0.782680\tBest loss: 0.594731\tAccuracy: 84.00%\n",
      "36\tValidation loss: 0.816441\tBest loss: 0.594731\tAccuracy: 84.00%\n",
      "37\tValidation loss: 0.749341\tBest loss: 0.594731\tAccuracy: 84.00%\n",
      "38\tValidation loss: 0.728754\tBest loss: 0.594731\tAccuracy: 82.00%\n",
      "39\tValidation loss: 0.838166\tBest loss: 0.594731\tAccuracy: 84.00%\n",
      "40\tValidation loss: 0.714871\tBest loss: 0.594731\tAccuracy: 84.00%\n",
      "41\tValidation loss: 0.765463\tBest loss: 0.594731\tAccuracy: 84.67%\n",
      "42\tValidation loss: 0.744043\tBest loss: 0.594731\tAccuracy: 82.00%\n",
      "43\tValidation loss: 0.726922\tBest loss: 0.594731\tAccuracy: 83.33%\n",
      "44\tValidation loss: 0.641118\tBest loss: 0.594731\tAccuracy: 82.67%\n",
      "45\tValidation loss: 0.657861\tBest loss: 0.594731\tAccuracy: 84.00%\n",
      "46\tValidation loss: 0.803642\tBest loss: 0.594731\tAccuracy: 86.00%\n",
      "47\tValidation loss: 0.754644\tBest loss: 0.594731\tAccuracy: 84.67%\n",
      "48\tValidation loss: 0.865141\tBest loss: 0.594731\tAccuracy: 84.00%\n",
      "49\tValidation loss: 0.709169\tBest loss: 0.594731\tAccuracy: 84.67%\n",
      "50\tValidation loss: 0.723139\tBest loss: 0.594731\tAccuracy: 84.00%\n",
      "51\tValidation loss: 0.745109\tBest loss: 0.594731\tAccuracy: 84.67%\n",
      "52\tValidation loss: 0.803908\tBest loss: 0.594731\tAccuracy: 82.67%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_four_frozen\n",
      "Final test accuracy: 80.17%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_best_mnist_model_0_to_4\")\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = four_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_four_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    four_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_four_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not fantastic, but much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Exercise: now unfreeze the top two hidden layers and continue training: can you get the model to perform even better?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "unfrozen_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"hidden[34]|new_logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam3\")\n",
    "training_op = optimizer.minimize(loss, var_list=unfrozen_vars)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "two_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_four_frozen\n",
      "0\tValidation loss: 0.880485\tBest loss: 0.880485\tAccuracy: 86.00%\n",
      "1\tValidation loss: 1.388974\tBest loss: 0.880485\tAccuracy: 81.33%\n",
      "2\tValidation loss: 0.741543\tBest loss: 0.741543\tAccuracy: 86.67%\n",
      "3\tValidation loss: 1.030772\tBest loss: 0.741543\tAccuracy: 84.00%\n",
      "4\tValidation loss: 0.699438\tBest loss: 0.699438\tAccuracy: 87.33%\n",
      "5\tValidation loss: 0.743930\tBest loss: 0.699438\tAccuracy: 89.33%\n",
      "6\tValidation loss: 1.711346\tBest loss: 0.699438\tAccuracy: 82.67%\n",
      "7\tValidation loss: 1.437762\tBest loss: 0.699438\tAccuracy: 82.00%\n",
      "8\tValidation loss: 0.829231\tBest loss: 0.699438\tAccuracy: 86.67%\n",
      "9\tValidation loss: 1.033920\tBest loss: 0.699438\tAccuracy: 86.67%\n",
      "10\tValidation loss: 1.055709\tBest loss: 0.699438\tAccuracy: 87.33%\n",
      "11\tValidation loss: 0.971796\tBest loss: 0.699438\tAccuracy: 88.00%\n",
      "12\tValidation loss: 0.801815\tBest loss: 0.699438\tAccuracy: 86.00%\n",
      "13\tValidation loss: 0.726146\tBest loss: 0.699438\tAccuracy: 89.33%\n",
      "14\tValidation loss: 0.757217\tBest loss: 0.699438\tAccuracy: 88.67%\n",
      "15\tValidation loss: 0.791842\tBest loss: 0.699438\tAccuracy: 90.00%\n",
      "16\tValidation loss: 0.732507\tBest loss: 0.699438\tAccuracy: 90.67%\n",
      "17\tValidation loss: 0.737297\tBest loss: 0.699438\tAccuracy: 90.67%\n",
      "18\tValidation loss: 0.746715\tBest loss: 0.699438\tAccuracy: 90.00%\n",
      "19\tValidation loss: 0.747751\tBest loss: 0.699438\tAccuracy: 90.00%\n",
      "20\tValidation loss: 0.749325\tBest loss: 0.699438\tAccuracy: 90.00%\n",
      "21\tValidation loss: 0.751899\tBest loss: 0.699438\tAccuracy: 90.00%\n",
      "22\tValidation loss: 0.754314\tBest loss: 0.699438\tAccuracy: 90.00%\n",
      "23\tValidation loss: 0.757840\tBest loss: 0.699438\tAccuracy: 90.00%\n",
      "24\tValidation loss: 0.761543\tBest loss: 0.699438\tAccuracy: 90.00%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_two_frozen\n",
      "Final test accuracy: 84.37%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    four_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_four_frozen\")\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = two_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_two_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    two_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_two_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what accuracy we can get by unfreezing all layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam4\")\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "no_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_two_frozen\n",
      "0\tValidation loss: 0.846005\tBest loss: 0.846005\tAccuracy: 83.33%\n",
      "1\tValidation loss: 0.694439\tBest loss: 0.694439\tAccuracy: 91.33%\n",
      "2\tValidation loss: 1.201433\tBest loss: 0.694439\tAccuracy: 85.33%\n",
      "3\tValidation loss: 1.975297\tBest loss: 0.694439\tAccuracy: 85.33%\n",
      "4\tValidation loss: 0.692805\tBest loss: 0.692805\tAccuracy: 95.33%\n",
      "5\tValidation loss: 1.090217\tBest loss: 0.692805\tAccuracy: 91.33%\n",
      "6\tValidation loss: 1.924300\tBest loss: 0.692805\tAccuracy: 90.67%\n",
      "7\tValidation loss: 4.019310\tBest loss: 0.692805\tAccuracy: 87.33%\n",
      "8\tValidation loss: 4.150792\tBest loss: 0.692805\tAccuracy: 78.00%\n",
      "9\tValidation loss: 4.522708\tBest loss: 0.692805\tAccuracy: 75.33%\n",
      "10\tValidation loss: 1.163385\tBest loss: 0.692805\tAccuracy: 90.00%\n",
      "11\tValidation loss: 0.655868\tBest loss: 0.655868\tAccuracy: 92.67%\n",
      "12\tValidation loss: 0.943888\tBest loss: 0.655868\tAccuracy: 92.67%\n",
      "13\tValidation loss: 0.529996\tBest loss: 0.529996\tAccuracy: 92.67%\n",
      "14\tValidation loss: 0.610578\tBest loss: 0.529996\tAccuracy: 94.67%\n",
      "15\tValidation loss: 3.899716\tBest loss: 0.529996\tAccuracy: 88.00%\n",
      "16\tValidation loss: 18.285717\tBest loss: 0.529996\tAccuracy: 86.67%\n",
      "17\tValidation loss: 23.169626\tBest loss: 0.529996\tAccuracy: 78.00%\n",
      "18\tValidation loss: 17.309252\tBest loss: 0.529996\tAccuracy: 90.00%\n",
      "19\tValidation loss: 44.261902\tBest loss: 0.529996\tAccuracy: 80.00%\n",
      "20\tValidation loss: 52.460327\tBest loss: 0.529996\tAccuracy: 80.00%\n",
      "21\tValidation loss: 26.318949\tBest loss: 0.529996\tAccuracy: 83.33%\n",
      "22\tValidation loss: 32.857723\tBest loss: 0.529996\tAccuracy: 90.67%\n",
      "23\tValidation loss: 53.359497\tBest loss: 0.529996\tAccuracy: 88.00%\n",
      "24\tValidation loss: 57.823742\tBest loss: 0.529996\tAccuracy: 88.00%\n",
      "25\tValidation loss: 37.154972\tBest loss: 0.529996\tAccuracy: 92.67%\n",
      "26\tValidation loss: 41.386772\tBest loss: 0.529996\tAccuracy: 90.00%\n",
      "27\tValidation loss: 43.486767\tBest loss: 0.529996\tAccuracy: 90.00%\n",
      "28\tValidation loss: 42.776855\tBest loss: 0.529996\tAccuracy: 88.67%\n",
      "29\tValidation loss: 43.368839\tBest loss: 0.529996\tAccuracy: 90.67%\n",
      "30\tValidation loss: 43.440975\tBest loss: 0.529996\tAccuracy: 90.00%\n",
      "31\tValidation loss: 42.889927\tBest loss: 0.529996\tAccuracy: 91.33%\n",
      "32\tValidation loss: 42.806690\tBest loss: 0.529996\tAccuracy: 90.67%\n",
      "33\tValidation loss: 42.784145\tBest loss: 0.529996\tAccuracy: 90.67%\n",
      "Early stopping!\n",
      "INFO:tensorflow:Restoring parameters from ./my_mnist_model_5_to_9_no_frozen\n",
      "Final test accuracy: 90.60%\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 20\n",
    "\n",
    "max_checks_without_progress = 20\n",
    "checks_without_progress = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    two_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_two_frozen\")\n",
    "        \n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            save_path = no_frozen_saver.save(sess, \"./my_mnist_model_5_to_9_no_frozen\")\n",
    "            best_loss = loss_val\n",
    "            checks_without_progress = 0\n",
    "        else:\n",
    "            checks_without_progress += 1\n",
    "            if checks_without_progress > max_checks_without_progress:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "        print(\"{}\\tValidation loss: {:.6f}\\tBest loss: {:.6f}\\tAccuracy: {:.2f}%\".format(\n",
    "            epoch, loss_val, best_loss, acc_val * 100))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    no_frozen_saver.restore(sess, \"./my_mnist_model_5_to_9_no_frozen\")\n",
    "    acc_test = accuracy.eval(feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"Final test accuracy: {:.2f}%\".format(acc_test * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare that to a DNN trained from scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tValidation loss: 0.803557\tBest loss: 0.803557\tAccuracy: 71.33%\n",
      "1\tValidation loss: 0.966741\tBest loss: 0.803557\tAccuracy: 85.33%\n",
      "2\tValidation loss: 1.158972\tBest loss: 0.803557\tAccuracy: 78.00%\n",
      "3\tValidation loss: 0.615960\tBest loss: 0.615960\tAccuracy: 88.00%\n",
      "4\tValidation loss: 0.612626\tBest loss: 0.612626\tAccuracy: 92.00%\n",
      "5\tValidation loss: 0.686420\tBest loss: 0.612626\tAccuracy: 89.33%\n",
      "6\tValidation loss: 0.805281\tBest loss: 0.612626\tAccuracy: 89.33%\n",
      "7\tValidation loss: 0.753108\tBest loss: 0.612626\tAccuracy: 88.67%\n",
      "8\tValidation loss: 1.051471\tBest loss: 0.612626\tAccuracy: 86.00%\n",
      "9\tValidation loss: 0.487089\tBest loss: 0.487089\tAccuracy: 93.33%\n",
      "10\tValidation loss: 1.191093\tBest loss: 0.487089\tAccuracy: 85.33%\n",
      "11\tValidation loss: 0.878905\tBest loss: 0.487089\tAccuracy: 88.67%\n",
      "12\tValidation loss: 0.768841\tBest loss: 0.487089\tAccuracy: 91.33%\n",
      "13\tValidation loss: 1.153907\tBest loss: 0.487089\tAccuracy: 90.67%\n",
      "14\tValidation loss: 0.985427\tBest loss: 0.487089\tAccuracy: 89.33%\n",
      "15\tValidation loss: 1.221879\tBest loss: 0.487089\tAccuracy: 85.33%\n",
      "16\tValidation loss: 0.961743\tBest loss: 0.487089\tAccuracy: 88.67%\n",
      "17\tValidation loss: 3.116057\tBest loss: 0.487089\tAccuracy: 84.00%\n",
      "18\tValidation loss: 0.686387\tBest loss: 0.487089\tAccuracy: 84.00%\n",
      "19\tValidation loss: 0.929801\tBest loss: 0.487089\tAccuracy: 88.00%\n",
      "20\tValidation loss: 1.137579\tBest loss: 0.487089\tAccuracy: 92.00%\n",
      "21\tValidation loss: 0.987261\tBest loss: 0.487089\tAccuracy: 91.33%\n",
      "22\tValidation loss: 2.030677\tBest loss: 0.487089\tAccuracy: 91.33%\n",
      "23\tValidation loss: 1.094184\tBest loss: 0.487089\tAccuracy: 92.00%\n",
      "24\tValidation loss: 1.332256\tBest loss: 0.487089\tAccuracy: 82.67%\n",
      "25\tValidation loss: 1.128633\tBest loss: 0.487089\tAccuracy: 85.33%\n",
      "26\tValidation loss: 0.866569\tBest loss: 0.487089\tAccuracy: 90.67%\n",
      "27\tValidation loss: 1.088500\tBest loss: 0.487089\tAccuracy: 89.33%\n",
      "28\tValidation loss: 1.146113\tBest loss: 0.487089\tAccuracy: 89.33%\n",
      "29\tValidation loss: 1.163180\tBest loss: 0.487089\tAccuracy: 89.33%\n",
      "30\tValidation loss: 1.154797\tBest loss: 0.487089\tAccuracy: 89.33%\n",
      "Early stopping!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DNNClassifier(activation=<function elu at 0x7fd9e8a620d0>,\n",
       "       batch_norm_momentum=None, batch_size=20, dropout_rate=None,\n",
       "       initializer=<function variance_scaling_initializer.<locals>._initializer at 0x7fd9d5e628c8>,\n",
       "       learning_rate=0.01, n_hidden_layers=4, n_neurons=100,\n",
       "       optimizer_class=<class 'tensorflow.python.training.adam.AdamOptimizer'>,\n",
       "       random_state=42)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_clf_5_to_9 = DNNClassifier(n_hidden_layers=4, random_state=42)\n",
    "dnn_clf_5_to_9.fit(X_train2, y_train2, n_epochs=1000, X_valid=X_valid2, y_valid=y_valid2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90413495165603786"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = dnn_clf_5_to_9.predict(X_test2)\n",
    "accuracy_score(y_test2, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meh. How disappointing! ;) Transfer learning did not help much (if at all) in this task. At least we tried... Fortunately, the next exercise will get better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Pretraining on an auxiliary task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will build a DNN that compares two MNIST digit images and predicts whether they represent the same digit or not. Then you will reuse the lower layers of this network to train an MNIST classifier using very little training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.\n",
    "Exercise: _Start by building two DNNs (let's call them DNN A and B), both similar to the one you built earlier but without the output layer: each DNN should have five hidden layers of 100 neurons each, He initialization, and ELU activation. Next, add one more hidden layer with 10 units on top of both DNNs. You should use TensorFlow's `concat()` function with `axis=1` to concatenate the outputs of both DNNs along the horizontal axis, then feed the result to the hidden layer. Finally, add an output layer with a single neuron using the logistic activation function._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**! There was an error in the book for this exercise: there was no instruction to add a top hidden layer. Without it, the neural network generally fails to start learning. If you have the latest version of the book, this error has been fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could have two input placeholders, `X1` and `X2`, one for the images that should be fed to the first DNN, and the other for the images that should be fed to the second DNN. It would work fine. However, another option is to have a single input placeholder to hold both sets of images (each row will hold a pair of images), and use `tf.unstack()` to split this tensor into two separate tensors, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28 # MNIST\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, 2, n_inputs), name=\"X\")\n",
    "X1, X2 = tf.unstack(X, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need the labels placeholder. Each label will be 0 if the images represent different digits, or 1 if they represent the same digit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.int32, shape=[None, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's feed these inputs through two separate DNNs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dnn1 = dnn(X1, name=\"DNN_A\")\n",
    "dnn2 = dnn(X2, name=\"DNN_B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's concatenate their outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dnn_outputs = tf.concat([dnn1, dnn2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each DNN outputs 100 activations (per instance), so the shape is `[None, 100]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(100)])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(100)])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course the concatenated outputs have a shape of `[None, 200]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(200)])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets add an extra hidden layer with just 10 neurons, and the output layer, with a single neuron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden = tf.layers.dense(dnn_outputs, units=10, activation=tf.nn.elu, kernel_initializer=he_init)\n",
    "logits = tf.layers.dense(hidden, units=1, kernel_initializer=he_init)\n",
    "y_proba = tf.nn.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole network predicts `1` if `y_proba >= 0.5` (i.e. the network predicts that the images represent the same digit), or `0` otherwise. We compute instead `logits >= 0`, which is equivalent but faster to compute: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = tf.cast(tf.greater_equal(logits, 0), tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's add the cost function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_as_float = tf.cast(y, tf.float32)\n",
    "xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_as_float, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can now create the training operation using an optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "momentum = 0.95\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate, momentum, use_nesterov=True)\n",
    "training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will want to measure our classifier's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_correct = tf.equal(y_pred, y)\n",
    "accuracy = tf.reduce_mean(tf.cast(y_pred_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the usual `init` and `saver`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.\n",
    "_Exercise: split the MNIST training set in two sets: split #1 should containing 55,000 images, and split #2 should contain contain 5,000 images. Create a function that generates a training batch where each instance is a pair of MNIST images picked from split #1. Half of the training instances should be pairs of images that belong to the same class, while the other half should be images from different classes. For each pair, the training label should be 0 if the images are from the same class, or 1 if they are from different classes._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST dataset returned by TensorFlow's `input_data()` function is already split into 3 parts: a training set (55,000 instances), a validation set (5,000 instances) and a test set (10,000 instances). Let's use the first set to generate the training set composed image pairs, and we will use the second set for the second phase of the exercise (to train a regular MNIST classifier). We will use the third set as the test set for both phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train1 = mnist.train.images\n",
    "y_train1 = mnist.train.labels\n",
    "\n",
    "X_train2 = mnist.validation.images\n",
    "y_train2 = mnist.validation.labels\n",
    "\n",
    "X_test = mnist.test.images\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a function that generates pairs of images: 50% representing the same digit, and 50% representing different digits. There are many ways to implement this. In this implementation, we first decide how many \"same\" pairs (i.e. pairs of images representing the same digit) we will generate, and how many \"different\" pairs (i.e. pairs of images representing different digits). We could just use `batch_size // 2` but we want to handle the case where it is odd (granted, that might be overkill!). Then we generate random pairs and we pick the right number of \"same\" pairs, then we generate the right number of \"different\" pairs. Finally we shuffle the batch and return it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_batch(images, labels, batch_size):\n",
    "    size1 = batch_size // 2\n",
    "    size2 = batch_size - size1\n",
    "    if size1 != size2 and np.random.rand() > 0.5:\n",
    "        size1, size2 = size2, size1\n",
    "    X = []\n",
    "    y = []\n",
    "    while len(X) < size1:\n",
    "        rnd_idx1, rnd_idx2 = np.random.randint(0, len(images), 2)\n",
    "        if rnd_idx1 != rnd_idx2 and labels[rnd_idx1] == labels[rnd_idx2]:\n",
    "            X.append(np.array([images[rnd_idx1], images[rnd_idx2]]))\n",
    "            y.append([1])\n",
    "    while len(X) < batch_size:\n",
    "        rnd_idx1, rnd_idx2 = np.random.randint(0, len(images), 2)\n",
    "        if labels[rnd_idx1] != labels[rnd_idx2]:\n",
    "            X.append(np.array([images[rnd_idx1], images[rnd_idx2]]))\n",
    "            y.append([0])\n",
    "    rnd_indices = np.random.permutation(batch_size)\n",
    "    return np.array(X)[rnd_indices], np.array(y)[rnd_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it to generate a small batch of 5 image pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "X_batch, y_batch = generate_batch(X_train1, y_train1, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in `X_batch` contains a pair of images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 2, 784), dtype('float32'))"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch.shape, X_batch.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at these pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANcAAAGiCAYAAAB05VNzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHMhJREFUeJzt3XuYjOf5B/AvwVrEaZ1WnHKywgahJQ4ROUjlUOJSQSon\n6pKKYxEShEaLRCMajbSNK1a1KhHiEIegQSIOdQySjSRKVC52s85UVkR/f+T33HtPZ4aZ2bnnnZ35\nfv7J93pnd+bJrttze9/nfd5i//3vf0FE0Vfc6wEQJSoWF5ERFheRERYXkREWF5ERFheRERYXkREW\nF5ERFheRkRJeDyAILhsJX7EIv48/6/CF9LPmzEVkhMVFZITFRWSExUVkhMVFZITFRWSExUVkhMVF\nZITFRWSExUVkhMVFZITFRWSExUVkhMVFZITFRWQkXu/ninvDhg2TPHXqVMmdOnUCACxevDjmYypK\nNm3aJHnZsmWSf/e73wEA8vPz5VixYgW3T1WqVEnyuHHjAAD9+/eXYyVKxM8fac5cREZYXERGisXp\ngxjialAnT54EADz66KNybPXq1ZJ1C5OSkgIA2Lhxoxy75ZZbrIcIFIHb/F988UXJkydPlnzq1Cm/\nr9V/LnVbGMiQIUMkv/TSS4UZYqh4mz+Rl1hcREbi59RKnJk3b57kgQMHAgDy8vLkWOPGjSW7M4QA\n8Nvf/hYAcP78eeshFhnr168HUHAmEPBtBStWrCi5atWqAIBRo0bJsbNnz0r+wx/+INm143//+9/l\n2IkTJySPHz9ecp06dSIef6Q4cxEZ4QkNZe/evZJvvfVWyf/5z38AAE2aNJFjy5cvl3zu3DnJ3bp1\nAwD885//lGMlS5aM/mD9xdUJjezsbMnt27cH4Dvz9+zZU/Lw4cMlN23aNOTPcCea9Gw2Z84cyevW\nrZOcnp4e8vuGgCc0iLzE4iIykvQnNL799lvJI0aMkOxaQW369OmSdZvx4YcfSr506RKAmLWCcWvG\njBmSXTvoTlYAwAsvvCD5mmuuiegz3FKnzz77TI59+eWXknNyciRHuS0MCWcuIiMsLiIjSd8Wzp49\nW/LKlSsDfs2sWbMAAG3btg34esOGDSW/+uqrAIDTp0/LsfLlyxd6nEXB559/LllfJ3RmzpwpOdJW\nUHOr4vV1rnjCmYvICIuLyEjStoWHDx8GUNBaAL6rrzt27OiX9UVmvcJbX6x077thwwY51rp16yiN\nOr7pi+nHjx/3e71WrVqF/owzZ85I1jdcOrp1z8jIKPTnFQZnLiIjSTtzHTx4EACQm5sb8PWPPvpI\n8s033wzAd/nOle4xIhurVq2SvGXLFgBA9erV5diUKVMkp6amxm5gAXDmIjLC4iIykrRtYZkyZQAA\n9evXl2P6Oo17HSjYcUjfj9SoUSPJLVq0kOxalLp160Z5xPFPL2/S//9fffVVod5XnyjRvwNH/w71\n78JrnLmIjLC4iIwkbVvYrFkzAMCePXvk2NatWyXrtibQUh19nUtzLWQ0lvcUNfo6VoMGDSS7trBv\n375yTJ/10xt9OhcuXJDstk4AfG9CdeL1OiJnLiIjLC4iI0nbFjr6psZw2gu9vEnvQxJs5XyyGTNm\njOQ1a9YAALZv3y7H0tLSJA8ePFhy2bJlAQDvv/++HNu8eXPAz6hZsyYAoE+fPlEYcfRx5iIywt2f\nwrB//37Jbdq0kaz34HO7HtWrVy9m4/p/cbX7k7ZgwQIAvicmPvnkE8kXL170H1QI21mPHDkSADBx\n4sSojDMM3P2JyEssLiIjSX9CIxy6/dCr6R988EHJHrSDca9r164+/wUKWkXA93449/SYb775Ro65\nzT//l7tWGa84cxEZYXERGeHZwhC4tkRvLKmvj+kH3WVmZsZuYL7i9mxhJPS1q6ysLMn6d+Cuf0Vj\n+4Aw8WwhkZd4QiMEbutlvfW1fkqHh7NVwnJ7RQK+17luuukmyR7MWGHhzEVkhMVFZIRtYRD6KSf6\nQXcOW0Eb+uF1TkpKiuSnn346lsMpFM5cREZYXERG2BYGsXDhQsl6KwDn/vvvj+Vwkoa790urXLmy\n5A4dOsRyOIXCmYvICIuLyAiXPwVRrVo1yW6PeL2jkd6FqFy5crEbWHAJsfypQoUKAHyfZuJu5wcK\nniLjMS5/IvIST2go+m/LQLee62d2xclslRR+9KMfeT2EiHDmIjLC4iIywrZQ0XvlBbq13O02RPba\nt28vuaj+3DlzERlhcREZ4XWuxJEQ17mKCF7nIvISi4vICIuLyAiLi8gIi4vICIuLyAiLi8gIi4vI\nCIuLyAiLi8gIV8VTkbJt2zbJ7qGDjz76qBzz4PnIQXHmIjLCmYvinr63rm/fvpJ//OMfAwBycnJi\nPqZQcOYiMsLiIjLC+7miYMyYMZKrVKkCABgyZEish5Gw93O5ExcAkJqaKnnu3LkAgPz8fDlWunTp\nWAyJ93MReYnFRWSEZwsjdPr0acmzZ8+WPHz4cC+Gk3Dee+89yStWrJD84YcfSnbPSo5RKxg2zlxE\nRlhcREbYFkbo+PHjkvWTN/STUChygwcPltykSRPJLVq08GI4EeHMRWSEM1eEAj3KFQAyMjJiPJLE\nMn/+fADAvn375NjRo0e9Gk6hcOYiMsLiIjLCtjBC06dP93oICcn9XPWJoerVq3s1nELhzEVkhMVF\nZIRtYRjOnTsneefOnZKbNm0quV69erEcUkI4duyY5M2bNwPwfRBhUcWZi8gIZ64wrF27VnJeXp7k\nPn36eDGchDF+/HjJlSpVAgBkZmZ6NJro4cxFZITFRWSEbWEY3n77bckpKSmSn3jiCS+GU6Tphc/z\n5s2TPHnyZABAxYoVYz6maOPMRWSExUVkhG1hGN566y3J6enpkrkSPnxZWVmS9XWuxo0b+31tbm6u\n5PPnz0suW7YsgIIdt+INZy4iIywuIiNsC0Mwc+ZMAL4tCS8cF86GDRskt2zZUnLDhg0BAK+99poc\nGzVqlGS965Y7ozhhwgQ5NmDAgOgPNkKcuYiMcOYKgds2uVSpUnLsZz/7mVfDKbIOHDggeenSpZIn\nTZokuUuXLgCA3bt3yzE9i2kHDx4EAAwdOlSO1a1bV/JPf/rTwg24kDhzERlhcREZYVsYxK5duyS7\nf3y7lgXg/oSR0NtSX7x4UXK7du0ku6fu6AfaPfzwwwHfzz0Ub/To0XJM7yHpNc5cREZYXERG2BYG\nsWjRIsnfffcdAKBnz55eDSch6GVMml4+5rarHjFiRMTvFy84cxEZ4cwVhH4OVNWqVQEAN998s1fD\nSQjbtm2TXKNGDcn6+mE4/vrXv/p9f+fOnSMcXfRx5iIywuIiMsK2UFm1apXkdevWSe7Xrx8A4Prr\nr4/1kBJK5cqVJestqkuWLBnye+zYsUOyWzb17LPPyrGaNWsWZohRxZmLyAiLi8gI20Jl48aNki9d\nuiSZK+Cjo1WrVpLnzJkj+dSpU5LT0tL8vm/ixImS9VYLd9xxBwBg7NixUR1ntHDmIjLC4iIywrZQ\n+de//iW5du3aknU7Q5G7+uqrAx7v1q2b5HvuuQeA71NO1q9fL7l3796Sn3/+eQBAiRLx+ceYMxeR\nkfgs+RjKzs6WrLer1puipKamxnRMiapHjx6S9+3bJ1nvYeieJHP33XfLsSVLlkj+yU9+YjjC6OLM\nRWSExUVkJOnbwvfee0+y3pewQoUKXgwnoekTD3qvQZ0TCWcuIiMsLiIjSd8WNmvWzOshUILizEVk\nhMVFZKSY24QxzsTloOJcsQi/jz/r8IX0s+bMRWSExUVkhMVFZITFRWSExUVkhMVFZITFRWSExUVk\nhMVFZITFRWSExUVkhMVFZITFRWSExUVkhMVFZITFRWSExUVkhMVFZITFRWSExUVkJOn3LQxm9uzZ\nkj/++GO/119++WXJxYr571fSvHlzyfpZU8GeUUWRu++++ySvWLFC8uDBgyVPmzYtpmMCOHMRmWFx\nERlhWxjE8uXLJeuH4jm6FQzUFu7YsUPyzJkzJQ8dOjRaQ6QA9O/i008/9XAknLmIzLC4iIywLQxC\nP5Dt/vvvB+DbKmqbN2+W/O9//9vv9RtvvDHKoyMA2L17NwBg9erVHo8kMM5cREb4IIYInTlzRnK7\ndu0ku79Nte+//z4WQ0q6BzF0794dADB//vyAr+trW4MGDYrmR/NBDEReYnERGeEJjTDoVrB8+fKS\nA13neu6552IypmSj2+4lS5b4vV62bFnJHTp0iMmYguHMRWSExUVkhG1hCI4dOwYA6NKlixwLtvyp\nVatWAICRI0fGaHSJ79ChQ5L79OkjOT8/3+9rGzRoIPmmm26yHdgVcOYiMsLiIjLCtjAI1woCwMSJ\nEwEAH330UcCvrVKlit/XpqamGo4uuRw5ckTy9u3b/V7PzMyUvHjx4piMKRScuYiMcPlTEL1795as\nb/l39M8tJSVFcrVq1fy+duHChZL17f9RllDLn9auXSv57rvvlhzoz6teUN2xY0fbgf2Ay5+IvMTi\nIjLCExqKvhcrKyvrsl+r2xN9vSXQ/Vzr16+XbNgWJoRLly4BKDgxBARuBQGgdu3aAIC2bdvaDywC\nnLmIjLC4iIywLVTS0tIkt27dWvKmTZsu+32BVsWH8zoVeOmllwAA//jHPwK+rn9HCxYsAACUK1fO\nfmAR4MxFZITXuYL4/PPPJR8/fvyyXzt27FjJeutq5/Dhw5LT09OjMLqAiux1rj179ki+6667AAB5\neXly7Nprr5WsN6O57rrrYjC6gHidi8hLLC4iIzyhEUT9+vUv+7q+5V+3MIEYtoJF1tatWyW7fSGB\nwD/Lhx56SLKHrWDYOHMRGWFxERnh2cII6WVMO3fulFymTBkAwLx58+TYAw88EIshxf3ZwrNnz0q+\n4YYbJOfm5vp9rf6ZLVq0SHLx4nExH/BsIZGXWFxERni2MAzvvvuuZN0K6uVNrp2JUStYJJw/fx4A\n8Nhjj8mxQK2gptvGOGkFw1Y0R01UBHDmCoFbRDpw4MCAr+sNavr37x+TMRUl69atAwC88847V/za\nIUOGAADGjRtnOaSY4MxFZITFRWQk4dvCqVOnStYnHnr06AEgtKVJri3U2ypr7r0A3wfhJTN9wmLM\nmDGX/Vp9P1avXr0AABUqVLAZWAxx5iIywuIiMpKQy590Kzhs2DDJui10q97XrFkjx2rUqCH5N7/5\njeTnn3/e7zNq1aolWb/HlVbTG/J8+VNOTo7ke++9V/KuXbsu+336IXZF5Poglz8ReYnFRWQkIdtC\nvf/FnXfeKVk/LcPRbZxecqP3Hw8kOzs74Ht4yPO2sGvXrpKvdMH4ySeflDxt2jTJpUqVitZwLLEt\nJPJSQs5c2t69eyXrfywH2nZa/ywC7TX43HPPSY7D5Tmez1x6C+pA17YyMjIk65m/COLMReQlFheR\nkYRf/qQf6akf+fnss88CAGbOnBnw+2rWrCnZtTi/+MUvLIaYMIKd2KlTpw4A3+tZyYAzF5ERFheR\nkYQ/W5hEPD9bmER4tpDISywuIiMsLiIjLC4iIywuIiMsLiIjLC4iIywuIiMsLiIjLC4iIywuIiMs\nLiIjLC4iIywuIiMsLiIjLC4iIywuIiMsLiIjLC4iIywuIiMJv28hea9ly5YAgKNHj8ox/dAGvbX1\npk2bAAAnT56M0ejscOYiMsLiIjLCfQsTR9zuW3jrrbcCALZu3XrFry1e/Ie/78uWLSvH2rVrJ/me\ne+7x+56f//znkitVqhTxOMPAfQuJvMTiIjLCs4VkrlmzZgBCawsvXboEADhz5owce/fddyUvW7bM\n73vS0tIk9+zZM+JxRhtnLiIjLC4iI0nfFur2Qz8/WT+obdasWX7fd9ttt0nWD9grXbo0AKBfv35y\nrGLFitEZbBE1ZcoUAMDu3bvlmLtYHA2fffZZ1N4rmjhzERlJ+utcAwYMkPzaa6+F/H3651asmP9l\nj2rVqknW12l++ctfSq5SpQoA35mvEOL2Opc7kaGvUZ0+fTrg12ZkZAAAateuLceC/axHjhwJAGjd\nurUcc52DMV7nIvISi4vISNK3hZ9++qnkYG3hqlWrAABffvmlHLtSWxiM/r4KFSoAAGrVqiXHdOvU\nuXNnybq1DCJu28KHH34YAPDmm28GfL1p06aSFy9eDMD3ZxKH2BYSeYnFRWQk6dtC7dSpU5JHjx4t\necaMGX5f+8orr0jWLcz+/fsBAFlZWXLs2LFjko8cOSI5nHbSLQu6jLhtC6+0Kl7/rB555BHr4UQD\n20IiL7G4iIwk/fKnNWvWSB46dKhkfRbRtW/Dhw+XY126dJF8zTXX+L3vsGHDJH/99deS9RnHRLZ2\n7VrJBw4c8Htd/8zatGkTkzHFGmcuIiNJdULjwoULkjds2AAAeOCBB+RYfn6+ZLc0CQCeeuopAL5L\nl6pWrWoxxMKIqxMaDRs2lLxv3z6/1ytXriz57bfflnzLLbdc9n2vvvpqyeGcEIoyntAg8hKLi8hI\nUrWF69atk3zXXXf98EFBljFNmzZN8sCBAy2GE21Fqi0Mh/4d6RNFY8eOBQCUL1++UO8fAbaFRF5i\ncREZSaq28IsvvpDsbrDTS5N0W1iiRMElwPr16/u91549eyyGWBhx1RbqM6t/+tOf/F5v3769ZN2u\nB3KlOxAaNWok2d3BAADp6emhDDUSbAuJvJRUM5deKeHuG/rggw/k2CeffCL5m2++kZybm+v3XnrT\nGfcPa6Bga2V9m3+MxNXMdfHiRcnuZ63vVUtJSZGsry8GohdRv/7665L1dUtHb4O9dOlSybfffnso\nww4VZy4iL7G4iIwkVVsYjoMHD0p2e+z1799fjul7v/Q/sps0aQIA2LFjh/EI/cRVW6i57aibN28u\nxyI92aDvh5s8eTIAYM6cOXJM/17c7wIAFi1aBACoU6dORJ/7P9gWEnmJxUVkhG1hGE6cOCF59erV\nkvV9Xq5t6datmxybO3duDEYXv22hu82/V69eckxvxlpY+gzik08+GfBr3O5Z+j6zQmBbSOQlFheR\nkaS/zT8c+nm7HTt2lLxlyxbJbjX9oUOH5Njhw4clx/lml6b0Llrdu3eXXNgbT/WNrcF07dq1UJ8R\nCc5cREYSauZy16H0cplAm8dEg17eE+iJHfoeI70IOJnp+7r0UqhBgwZJfuKJJ0J+v7y8PACB95UE\nfJ+Uoj8vVjhzERlhcREZSah+xa1qv+OOO+SY/ofspEmT/L5HP6pV+/bbbyXr7ZadV199VXKg+8CG\nDBkix2rUqHGloSe0QCcs9CNcdVuoV7I7ekX75s2bJbutw7dv3x7wc/VSJ71rVKxw5iIywuIiMpJQ\ny5/cbfz6Gkp2drbkVq1a+X2PvsU80ofY6fbjV7/6FQDfVidG4nb5U6AlYe5Og1CE86BBfZPq/Pnz\nJbdt2zbkzwsBlz8ReSmhZi7n5MmTkjdu3Ch5yZIlkt2t5+H8rZiZmSm5U6dOkh977DHJHuyh58Tt\nzOXk5ORI1g+y2Llzp+RAt+5f6XfUokULye73CphutcCZi8hLLC4iIwnZFiapuG8Lg3HbAAAF2yPo\n61krV66UrNvCZ555BoDvc9XS0tLMxqmwLSTyEouLyAjbwsRRZNvCIohtIZGXWFxERlhcREZYXERG\nWFxERlhcREZYXERGWFxERlhcREZYXERGWFxERlhcREZYXERGWFxERlhcREZYXERGWFxERlhcREZY\nXERGWFxERlhcREZYXERGWFxERhLqsa2F9dVXX0keMGCAZL3dstOvXz/JnTt3luyeGn/VVVdZDDFh\nfPfdd5L1I3J///vfAwAmTJggx/TemsOHD5d83333AQBatmwpx0qWLBn9wUaIMxeRERYXkZGk385a\nPwn+3nvvlZyXlxfR+73xxhsAgMcff7xQ44pAkdrOetasWZL79Onj93q5cuUk6z+j586d8/ta/bOe\nMmWKZMMnnnA7ayIvsbiIjCR9W3jjjTdK3r9/f6Hfr1KlSgCA5cuXyzF9NstQ3LeFkyZNkjx16lTJ\nx44dk/zyyy8DABo1aiTHjhw5Ilk/fzqQ6tWrS16/fr3k+vXrRzDioNgWEnmJxUVkJOkvIl+8eDGq\n73fixAkAwOTJk+XYO++8E9XPKGqys7MBFLR8gG8r2KNHD8lt2rQB4HuR3j0nGfB9JnLdunUBAKdO\nnZJjOTk5knNzcyVHuS0MCWcuIiNJP3M99dRTkt3Sm1BMmzZNsl6So5dQ0Q9mzJgBwPfaoVsmBgBN\nmzaVfNtttwEA8vPz5didd94pecSIEZIzMzMBAFu2bJFj3bp1k/zHP/7R7zP09TNrnLmIjLC4iIwk\nfVuoWzqdwzF9+nTJbAv9Bbp+6K4HAsCoUaMku5MUeknUmDFjLvv+uoWsWrWq5Llz50ru0qULAKBr\n166hDrvQOHMRGWFxERlJ+rYwHLr90Ge+Dh065MVwiowGDRoAAFauXCnH3nzzTcn16tWTvGLFCgBA\nRkZGyO9//fXXB3zf7t27S54/fz4AtoVECSEhZy79D+jKlStL1v+I3rt3LwDglVdekWNnz56VXLx4\nwd87bnGv+1sVAI4fPy754MGDURh1YtErMPQKCyfQbAWEN2MF0r59+6i9V2Fx5iIywuIiMpKQbaFb\nbgMACxYskFymTBnJX3/9NQDgzJkzJmPQi1GT0cKFCyV/8MEHfq+3aNFCcizat8WLFwMADhw4IMeu\nvfZa08/kzEVkhMVFZCSh2kJ37en999+XY7G+BuWW7+hrLMlCn0HVS8Kc8ePHS3766adjMSThrlF+\n//33MftMzlxERlhcREYSqi10Oy59/PHHno3h6NGjAICNGzfKsdatW3s1nJjSdxXs2bPH73V902Pp\n0qXNx6N3NvNilzPOXERGEmrmigfuH856SU+yzFya3kjmhhtuAABcd911no1B51jhzEVkhMVFZCSh\n2kK30rpEiYL/rUj3JdTbXH/xxRdhf79bdU9Aeno6AKBmzZrmn3X+/HnJ+qF6brlVtWrVzMfgcOYi\nMsLiIjKSUG1hu3btAPg+o3jbtm2X/Z7evXtLHjRokORSpUpJvnDhgt/3/fnPf5b8t7/9TfLu3bvD\nGHFycDeh6ptRrTbnXLZsmWT9u3/ooYcAAOXLlzf53EA4cxEZYXERGUmottBxO/1ES2pqqt8xvWe5\nfrhdhw4dABQsgwJ8z1rFYtlPvNm5cycAYNeuXXKsbdu2UXt/vWeK3vvfa5y5iIwk/WNbo81d09HP\nidJ76enHkbotCPQJmMaNG0f60Z4/tlU/bcRtHw0UzOIPPvigHMvKypIc6UmGc+fOAQD69u0rx+bN\nmydZX9Nyv4Pbb789os/6H3xsK5GXWFxERtgWRtkzzzwDAHjhhRfkWEpKiuQqVapIdjtQzZ49W449\n8sgjkX60522hNm7cOMkTJkzwe123iH/5y18kX+n6l17e5K5R6rZbP+XkrbfekhyldtBhW0jkJRYX\nkZGEvM7lJfcUet2q6L3kXSuY6PTD69xe8Xpp0qJFiyT36tVLcqdOnfzeSy8/e/HFFyW7n2taWpoc\nGzp0qOQot4Jh48xFZIQnNIxMmTJF8siRIwN+zVVXXQUAWLp0qRzr2LFjpB8ZVyc0NDfz6JlEXxO7\nEv1nVN+u71bDjB07Vo5Fc+XHZfCEBpGXWFxERtgWGjl16pTk0aNHS9ZPYHn88ccBAG+88UY0PjJu\n20JHX6N6/fXXJf/617+WfOLECb/vK1mypGS9YNotsWrevHlUxxkCtoVEXmJxERlhW5g44r4tTCBs\nC4m8xOIiMsLiIjLC4iIywuIiMsLiIjLC4iIyEq/3c8X+SWXJiz9rI5y5iIywuIiMsLiIjLC4iIyw\nuIiMsLiIjLC4iIywuIiMsLiIjLC4iIywuIiMsLiIjLC4iIywuIiMsLiIjLC4iIywuIiMsLiIjLC4\niIywuIiMsLiIjLC4iIywuIiMsLiIjLC4iIywuIiM/B8LRNiNqaw8LQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd9d2dda2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3, 3 * batch_size))\n",
    "plt.subplot(121)\n",
    "plt.imshow(X_batch[:,0].reshape(28 * batch_size, 28), cmap=\"binary\", interpolation=\"nearest\")\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(X_batch[:,1].reshape(28 * batch_size, 28), cmap=\"binary\", interpolation=\"nearest\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's look at the labels (0 means \"different\", 1 means \"same\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3.\n",
    "_Exercise: train the DNN on this training set. For each image pair, you can simultaneously feed the first image to DNN A and the second image to DNN B. The whole network will gradually learn to tell whether two images belong to the same class or not._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a test set composed of many pairs of images pulled from the MNIST test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test1, y_test1 = generate_batch(X_test, y_test, batch_size=len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, let's train the model. There's really nothing special about this step, except for the fact that we need a fairly large `batch_size`, otherwise the model fails to learn anything and ends up with an accuracy of 50%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train loss: 0.492426\n",
      "0 Test accuracy: 0.7861\n",
      "1 Train loss: 0.334813\n",
      "2 Train loss: 0.290434\n",
      "3 Train loss: 0.253434\n",
      "4 Train loss: 0.217843\n",
      "5 Train loss: 0.17127\n",
      "5 Test accuracy: 0.9185\n",
      "6 Train loss: 0.207128\n",
      "7 Train loss: 0.172275\n",
      "8 Train loss: 0.166783\n",
      "9 Train loss: 0.161094\n",
      "10 Train loss: 0.125131\n",
      "10 Test accuracy: 0.9425\n",
      "11 Train loss: 0.159824\n",
      "12 Train loss: 0.124752\n",
      "13 Train loss: 0.112234\n",
      "14 Train loss: 0.114502\n",
      "15 Train loss: 0.0950093\n",
      "15 Test accuracy: 0.9532\n",
      "16 Train loss: 0.119296\n",
      "17 Train loss: 0.0754429\n",
      "18 Train loss: 0.112295\n",
      "19 Train loss: 0.133708\n",
      "20 Train loss: 0.113547\n",
      "20 Test accuracy: 0.9596\n",
      "21 Train loss: 0.0674082\n",
      "22 Train loss: 0.0936297\n",
      "23 Train loss: 0.0986469\n",
      "24 Train loss: 0.111875\n",
      "25 Train loss: 0.0735623\n",
      "25 Test accuracy: 0.9675\n",
      "26 Train loss: 0.0790324\n",
      "27 Train loss: 0.0487644\n",
      "28 Train loss: 0.0869071\n",
      "29 Train loss: 0.0694422\n",
      "30 Train loss: 0.060089\n",
      "30 Test accuracy: 0.9663\n",
      "31 Train loss: 0.103902\n",
      "32 Train loss: 0.0535952\n",
      "33 Train loss: 0.0310679\n",
      "34 Train loss: 0.0536294\n",
      "35 Train loss: 0.046265\n",
      "35 Test accuracy: 0.9701\n",
      "36 Train loss: 0.0679821\n",
      "37 Train loss: 0.0326656\n",
      "38 Train loss: 0.0357479\n",
      "39 Train loss: 0.0333373\n",
      "40 Train loss: 0.0415115\n",
      "40 Test accuracy: 0.9719\n",
      "41 Train loss: 0.0577977\n",
      "42 Train loss: 0.0342781\n",
      "43 Train loss: 0.0439651\n",
      "44 Train loss: 0.0597254\n",
      "45 Train loss: 0.0588695\n",
      "45 Test accuracy: 0.9721\n",
      "46 Train loss: 0.0556821\n",
      "47 Train loss: 0.063956\n",
      "48 Train loss: 0.0301285\n",
      "49 Train loss: 0.0402678\n",
      "50 Train loss: 0.0489125\n",
      "50 Test accuracy: 0.9751\n",
      "51 Train loss: 0.0394528\n",
      "52 Train loss: 0.0233041\n",
      "53 Train loss: 0.064878\n",
      "54 Train loss: 0.0510189\n",
      "55 Train loss: 0.0312619\n",
      "55 Test accuracy: 0.9742\n",
      "56 Train loss: 0.0244156\n",
      "57 Train loss: 0.0409082\n",
      "58 Train loss: 0.0346896\n",
      "59 Train loss: 0.0455727\n",
      "60 Train loss: 0.0488268\n",
      "60 Test accuracy: 0.9751\n",
      "61 Train loss: 0.0154253\n",
      "62 Train loss: 0.0358874\n",
      "63 Train loss: 0.0290555\n",
      "64 Train loss: 0.0172143\n",
      "65 Train loss: 0.0377991\n",
      "65 Test accuracy: 0.9751\n",
      "66 Train loss: 0.0360786\n",
      "67 Train loss: 0.0240278\n",
      "68 Train loss: 0.0314243\n",
      "69 Train loss: 0.0412082\n",
      "70 Train loss: 0.0439106\n",
      "70 Test accuracy: 0.9763\n",
      "71 Train loss: 0.0169656\n",
      "72 Train loss: 0.0181306\n",
      "73 Train loss: 0.0214228\n",
      "74 Train loss: 0.0418301\n",
      "75 Train loss: 0.0378622\n",
      "75 Test accuracy: 0.9759\n",
      "76 Train loss: 0.0199817\n",
      "77 Train loss: 0.0145837\n",
      "78 Train loss: 0.0199176\n",
      "79 Train loss: 0.0226598\n",
      "80 Train loss: 0.0119815\n",
      "80 Test accuracy: 0.9779\n",
      "81 Train loss: 0.0177832\n",
      "82 Train loss: 0.00981572\n",
      "83 Train loss: 0.0279094\n",
      "84 Train loss: 0.0237818\n",
      "85 Train loss: 0.0157778\n",
      "85 Test accuracy: 0.978\n",
      "86 Train loss: 0.00950592\n",
      "87 Train loss: 0.0226222\n",
      "88 Train loss: 0.0226599\n",
      "89 Train loss: 0.0185005\n",
      "90 Train loss: 0.0118967\n",
      "90 Test accuracy: 0.976\n",
      "91 Train loss: 0.0209059\n",
      "92 Train loss: 0.0181153\n",
      "93 Train loss: 0.0131697\n",
      "94 Train loss: 0.017605\n",
      "95 Train loss: 0.0193861\n",
      "95 Test accuracy: 0.976\n",
      "96 Train loss: 0.0156532\n",
      "97 Train loss: 0.0136041\n",
      "98 Train loss: 0.00743028\n",
      "99 Train loss: 0.0267189\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 500\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples // batch_size):\n",
    "            X_batch, y_batch = generate_batch(X_train1, y_train1, batch_size)\n",
    "            loss_val, _ = sess.run([loss, training_op], feed_dict={X: X_batch, y: y_batch})\n",
    "        print(epoch, \"Train loss:\", loss_val)\n",
    "        if epoch % 5 == 0:\n",
    "            acc_test = accuracy.eval(feed_dict={X: X_test1, y: y_test1})\n",
    "            print(epoch, \"Test accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_digit_comparison_model.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right, we reach 97.6% accuracy on this digit comparison task. That's not too bad, this model knows a thing or two about comparing handwritten digits!\n",
    "\n",
    "Let's see if some of that knowledge can be useful for the regular MNIST classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4.\n",
    "_Exercise: now create a new DNN by reusing and freezing the hidden layers of DNN A and adding a softmax output layer on top with 10 neurons. Train this network on split #2 and see if you can achieve high performance despite having only 500 images per class._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the model, it is pretty straightforward. There are many ways to freeze the lower layers, as explained in the book. In this example, we chose to use the `tf.stop_gradient()` function. Note that we need one `Saver` to restore the pretrained DNN A, and another `Saver` to save the final model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "dnn_outputs = dnn(X, name=\"DNN_A\")\n",
    "frozen_outputs = tf.stop_gradient(dnn_outputs)\n",
    "\n",
    "logits = tf.layers.dense(dnn_outputs, n_outputs, kernel_initializer=he_init)\n",
    "Y_proba = tf.nn.softmax(logits)\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate, momentum, use_nesterov=True)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "dnn_A_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"DNN_A\")\n",
    "restore_saver = tf.train.Saver(var_list={var.op.name: var for var in dnn_A_vars})\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now on to training! We first initialize all variables (including the variables in the new output layer), then we restore the pretrained DNN A. Next, we just train the model on the small MNIST dataset (containing just 5,000 images):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_digit_comparison_model.ckpt\n",
      "0 Test accuracy: 0.9269\n",
      "10 Test accuracy: 0.9675\n",
      "20 Test accuracy: 0.9673\n",
      "30 Test accuracy: 0.9673\n",
      "40 Test accuracy: 0.9674\n",
      "50 Test accuracy: 0.9673\n",
      "60 Test accuracy: 0.9673\n",
      "70 Test accuracy: 0.9673\n",
      "80 Test accuracy: 0.9672\n",
      "90 Test accuracy: 0.9673\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./my_digit_comparison_model.ckpt\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 10 == 0:\n",
    "            acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "            print(epoch, \"Test accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_mnist_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, 96.7% accuracy, that's not the best MNIST model we have trained so far, but recall that we are only using a small training set (just 500 images per digit). Let's compare this result with the same DNN trained from scratch, without using transfer learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_inputs = 28 * 28  # MNIST\n",
    "n_outputs = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")\n",
    "\n",
    "dnn_outputs = dnn(X, name=\"DNN_A\")\n",
    "\n",
    "logits = tf.layers.dense(dnn_outputs, n_outputs, kernel_initializer=he_init)\n",
    "Y_proba = tf.nn.softmax(logits)\n",
    "\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate, momentum, use_nesterov=True)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "dnn_A_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"DNN_A\")\n",
    "restore_saver = tf.train.Saver(var_list={var.op.name: var for var in dnn_A_vars})\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Test accuracy: 0.8893\n",
      "10 Test accuracy: 0.9402\n",
      "20 Test accuracy: 0.9479\n",
      "30 Test accuracy: 0.9474\n",
      "40 Test accuracy: 0.9479\n",
      "50 Test accuracy: 0.9475\n",
      "60 Test accuracy: 0.9475\n",
      "70 Test accuracy: 0.9475\n",
      "80 Test accuracy: 0.9476\n",
      "90 Test accuracy: 0.9476\n",
      "100 Test accuracy: 0.9473\n",
      "110 Test accuracy: 0.9472\n",
      "120 Test accuracy: 0.9474\n",
      "130 Test accuracy: 0.9474\n",
      "140 Test accuracy: 0.9475\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 150\n",
    "batch_size = 50\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_indices in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_indices], y_train2[rnd_indices]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 10 == 0:\n",
    "            acc_test = accuracy.eval(feed_dict={X: X_test, y: y_test})\n",
    "            print(epoch, \"Test accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(sess, \"./my_mnist_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 94.8% accuracy... So transfer learning helped us reduce the error rate from 5.2% to 3.3% (that's over 36% error reduction). Moreover, the model using transfer learning reached over 96% accuracy in less than 10 epochs.\n",
    "\n",
    "Bottom line: transfer learning does not always work (as we saw in exercise 9), but when it does it can make a big difference. So try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "nav_menu": {
   "height": "360px",
   "width": "416px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
